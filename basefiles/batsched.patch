diff -burN '--exclude=.git*' ./batsched/.clang-format ./new_batsched/.clang-format
--- ./batsched/.clang-format	2023-07-01 09:20:31.850842135 -0400
+++ ./new_batsched/.clang-format	1969-12-31 19:00:00.000000000 -0500
@@ -1,105 +0,0 @@
-Language:        Cpp
-# BasedOnStyle:  WebKit
-AccessModifierOffset: -4
-AlignAfterOpenBracket: DontAlign
-AlignConsecutiveAssignments: false
-AlignConsecutiveDeclarations: false
-AlignEscapedNewlines: Right
-AlignOperands:   false
-AlignTrailingComments: false
-AllowAllParametersOfDeclarationOnNextLine: true
-AllowShortBlocksOnASingleLine: false
-AllowShortCaseLabelsOnASingleLine: false
-AllowShortFunctionsOnASingleLine: false
-AllowShortIfStatementsOnASingleLine: false
-AllowShortLoopsOnASingleLine: false
-AlwaysBreakAfterDefinitionReturnType: None
-AlwaysBreakAfterReturnType: None
-AlwaysBreakBeforeMultilineStrings: false
-AlwaysBreakTemplateDeclarations: false
-BinPackArguments: true
-BinPackParameters: true
-BraceWrapping:
-  AfterClass:      true
-  AfterControlStatement: true
-  AfterEnum:       true
-  AfterFunction:   true
-  AfterNamespace:  true
-  AfterObjCDeclaration: true
-  AfterStruct:     true
-  AfterUnion:      true
-  BeforeCatch:     true
-  BeforeElse:      true
-  IndentBraces:    false
-  SplitEmptyFunction: true
-  SplitEmptyRecord: true
-  SplitEmptyNamespace: true
-BreakBeforeBinaryOperators: All
-BreakBeforeBraces: Custom
-BreakBeforeInheritanceComma: false
-BreakBeforeTernaryOperators: true
-BreakConstructorInitializersBeforeComma: false
-BreakConstructorInitializers: BeforeComma
-BreakAfterJavaFieldAnnotations: false
-BreakStringLiterals: true
-ColumnLimit: 120
-CommentPragmas:  '^ IWYU pragma:'
-CompactNamespaces: false
-ConstructorInitializerAllOnOneLineOrOnePerLine: false
-ConstructorInitializerIndentWidth: 4
-ContinuationIndentWidth: 4
-Cpp11BracedListStyle: false
-DerivePointerAlignment: false
-DisableFormat:   false
-ExperimentalAutoDetectBinPacking: false
-FixNamespaceComments: false
-ForEachMacros:
-  - foreach
-  - Q_FOREACH
-  - BOOST_FOREACH
-IncludeCategories:
-  - Regex:           '^"(llvm|llvm-c|clang|clang-c)/'
-    Priority:        2
-  - Regex:           '^(<|"(gtest|gmock|isl|json)/)'
-    Priority:        3
-  - Regex:           '.*'
-    Priority:        1
-IncludeIsMainRegex: '(Test)?$'
-IndentCaseLabels: false
-IndentWidth:     4
-IndentWrappedFunctionNames: false
-JavaScriptQuotes: Leave
-JavaScriptWrapImports: true
-KeepEmptyLinesAtTheStartOfBlocks: true
-MacroBlockBegin: ''
-MacroBlockEnd:   ''
-MaxEmptyLinesToKeep: 1
-NamespaceIndentation: Inner
-ObjCBlockIndentWidth: 4
-ObjCSpaceAfterProperty: true
-ObjCSpaceBeforeProtocolList: true
-PenaltyBreakAssignment: 2
-PenaltyBreakBeforeFirstCallParameter: 19
-PenaltyBreakComment: 300
-PenaltyBreakFirstLessLess: 120
-PenaltyBreakString: 1000
-PenaltyExcessCharacter: 1000000
-PenaltyReturnTypeOnItsOwnLine: 60
-PointerAlignment: Right
-ReflowComments:  true
-SortIncludes:    true
-SortUsingDeclarations: true
-SpaceAfterCStyleCast: false
-SpaceAfterTemplateKeyword: true
-SpaceBeforeAssignmentOperators: true
-SpaceBeforeParens: ControlStatements
-SpaceInEmptyParentheses: false
-SpacesBeforeTrailingComments: 1
-SpacesInAngles:  false
-SpacesInContainerLiterals: true
-SpacesInCStyleCastParentheses: false
-SpacesInParentheses: false
-SpacesInSquareBrackets: false
-Standard:        Cpp11
-TabWidth:        8
-UseTab:          Never
diff -burN '--exclude=.git*' ./batsched/default.nix ./new_batsched/default.nix
--- ./batsched/default.nix	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/default.nix	2023-06-28 08:26:02.127166524 -0400
@@ -28,7 +28,7 @@
       mesonFlags = []
         ++ pkgs.lib.optional doCoverage [ "-Db_coverage=true" ];
       nativeBuildInputs = with kapack; [pkgs.meson pkgs.ninja pkgs.pkgconfig
-        pkgs.boost pkgs.gmp pkgs.rapidjson intervalset loguru redox pkgs.cppzmq pkgs.zeromq];
+        pkgs.boost pkgs.gmp pkgs.rapidjson intervalset loguru pkgs.cppzmq pkgs.zeromq];
       # Debug build, without any Nix stripping magic.
       mesonBuildType = "debug";
       hardeningDisable = [ "all" ];
@@ -36,112 +36,112 @@
       # Keep files generated by GCOV, so depending jobs can use them.
       postInstall = pkgs.lib.optionalString doCoverage ''
         mkdir -p $out/gcno
-        cp batsched@exe/*.gcno $out/gcno/
+        cp batsched.p/*.gcno $out/gcno/
       '';
     });
 
     # Batsched integration tests.
-    integration_tests = pkgs.stdenv.mkDerivation rec {
-      pname = "batsched-integration-tests";
-      version = toString builtins.currentTime; # Forces rebuild
-      src = pkgs.lib.sourceByRegex ./. [
-        "^test"
-        "^test/.*\.py"
-        "^test/platforms"
-        "^test/platforms/.*\.xml"
-        "^test/workloads"
-        "^test/workloads/.*\.json"
-      ];
-      buildInputs = with pkgs.python37Packages; [
-        batsim batsched batexpe pkgs.redis
-        pytest pytest_html pandas];
-      preBuild = pkgs.lib.optionalString doCoverage ''
-        mkdir -p gcda
-        export GCOV_PREFIX=$(realpath gcda)
-        export GCOV_PREFIX_STRIP=5
-      '';
-      buildPhase = ''
-        runHook preBuild
-        set +e
-        (cd test && pytest -ra --html=../report/pytest_report.html)
-        echo $? > ./pytest_returncode
-        set -e
-      '';
-      checkPhase = ''
-        pytest_return_code=$(cat ./pytest_returncode)
-        echo "pytest return code: $pytest_return_code"
-        if [ $pytest_return_code -ne 0 ] ; then
-          exit 1
-        fi
-      '';
-      inherit doCheck;
-      installPhase = ''
-        mkdir -p $out
-        mv ./report/* ./pytest_returncode $out/
-      '' + pkgs.lib.optionalString doCoverage ''
-        mv ./gcda $out/
-      '';
-    };
+    # integration_tests = pkgs.stdenv.mkDerivation rec {
+    #   pname = "batsched-integration-tests";
+    #   version = toString builtins.currentTime; # Forces rebuild
+    #   src = pkgs.lib.sourceByRegex ./. [
+    #     "^test"
+    #     "^test/.*\.py"
+    #     "^test/platforms"
+    #     "^test/platforms/.*\.xml"
+    #     "^test/workloads"
+    #     "^test/workloads/.*\.json"
+    #   ];
+    #   buildInputs = with pkgs.python37Packages; [
+    #     batsim batsched batexpe
+    #     pytest pytest_html pandas];
+    #   preBuild = pkgs.lib.optionalString doCoverage ''
+    #     mkdir -p gcda
+    #     export GCOV_PREFIX=$(realpath gcda)
+    #     export GCOV_PREFIX_STRIP=5
+    #   '';
+    #   buildPhase = ''
+    #     runHook preBuild
+    #     set +e
+    #     (cd test && pytest -ra --html=../report/pytest_report.html)
+    #     echo $? > ./pytest_returncode
+    #     set -e
+    #   '';
+    #   checkPhase = ''
+    #     pytest_return_code=$(cat ./pytest_returncode)
+    #     echo "pytest return code: $pytest_return_code"
+    #     if [ $pytest_return_code -ne 0 ] ; then
+    #       exit 1
+    #     fi
+    #   '';
+    #   inherit doCheck;
+    #   installPhase = ''
+    #     mkdir -p $out
+    #     mv ./report/* ./pytest_returncode $out/
+    #   '' + pkgs.lib.optionalString doCoverage ''
+    #     mv ./gcda $out/
+    #   '';
+    # };
     # Essentially the same as integration_tests, but with an up-to-date Batsim.
-    integration_tests_batlatest = integration_tests.overrideAttrs (attr: rec {
-      buildInputs = with pkgs.python37Packages; [
-        batsim-master batsched batexpe pkgs.redis
-        pytest pytest_html pandas];
-    });
+    # integration_tests_batlatest = integration_tests.overrideAttrs (attr: rec {
+    #   buildInputs = with pkgs.python37Packages; [
+    #     batsim-master batsched batexpe
+    #     pytest pytest_html pandas];
+    # });
 
     # Batsched doxygen documentation.
-    doxydoc = pkgs.stdenv.mkDerivation rec {
-      name = "batsim-doxygen-documentation";
-      src = pkgs.lib.sourceByRegex ./. [
-        "^src"
-        "^src/.*\.?pp"
-        "^doc"
-        "^doc/Doxyfile"
-        "^doc/doxygen_mainpage.md"
-      ];
-      buildInputs = [pkgs.doxygen];
-      buildPhase = "(cd doc && doxygen)";
-      installPhase = ''
-        mkdir -p $out
-        mv doc/doxygen_doc/html/* $out/
-      '';
-      checkPhase = ''
-        nb_warnings=$(cat doc/doxygen_warnings.log | wc -l)
-        if [[ $nb_warnings -gt 0 ]] ; then
-          echo "FAILURE: There are doxygen warnings!"
-          cat doc/doxygen_warnings.log
-          exit 1
-        fi
-      '';
-      doCheck = true;
-    };
+    # doxydoc = pkgs.stdenv.mkDerivation rec {
+    #   name = "batsim-doxygen-documentation";
+    #   src = pkgs.lib.sourceByRegex ./. [
+    #     "^src"
+    #     "^src/.*\.?pp"
+    #     "^doc"
+    #     "^doc/Doxyfile"
+    #     "^doc/doxygen_mainpage.md"
+    #   ];
+    #   buildInputs = [pkgs.doxygen];
+    #   buildPhase = "(cd doc && doxygen)";
+    #   installPhase = ''
+    #     mkdir -p $out
+    #     mv doc/doxygen_doc/html/* $out/
+    #   '';
+    #   checkPhase = ''
+    #     nb_warnings=$(cat doc/doxygen_warnings.log | wc -l)
+    #     if [[ $nb_warnings -gt 0 ]] ; then
+    #       echo "FAILURE: There are doxygen warnings!"
+    #       cat doc/doxygen_warnings.log
+    #       exit 1
+    #     fi
+    #   '';
+    #   doCheck = true;
+    # };
 
     # Dependencies not in nixpkgs as I write these lines.
-    pytest_metadata = buildPythonPackage {
-      name = "pytest-metadata-1.8.0";
-      doCheck = false;
-      propagatedBuildInputs = [
-        pythonPackages.pytest
-        pythonPackages.setuptools_scm
-      ];
-      src = builtins.fetchurl {
-        url = "https://files.pythonhosted.org/packages/12/38/eed3a1e00c765e4da61e4e833de41c3458cef5d18e819d09f0f160682993/pytest-metadata-1.8.0.tar.gz";
-        sha256 = "1fk6icip2x1nh4kzhbc8cnqrs77avpqvj7ny3xadfh6yhn9aaw90";
-      };
-    };
+    # pytest_metadata = buildPythonPackage {
+    #   name = "pytest-metadata-1.8.0";
+    #   doCheck = false;
+    #   propagatedBuildInputs = [
+    #     pythonPackages.pytest
+    #     pythonPackages.setuptools_scm
+    #   ];
+    #   src = builtins.fetchurl {
+    #     url = "https://files.pythonhosted.org/packages/12/38/eed3a1e00c765e4da61e4e833de41c3458cef5d18e819d09f0f160682993/pytest-metadata-1.8.0.tar.gz";
+    #     sha256 = "1fk6icip2x1nh4kzhbc8cnqrs77avpqvj7ny3xadfh6yhn9aaw90";
+    #   };
+    # };
 
-    pytest_html = buildPythonPackage {
-      name = "pytest-html-1.20.0";
-      doCheck = false;
-      propagatedBuildInputs = [
-        pythonPackages.pytest
-        pytest_metadata
-      ];
-      src = builtins.fetchurl {
-        url = "https://files.pythonhosted.org/packages/08/3e/63d998f26c7846d3dac6da152d1b93db3670538c5e2fe18b88690c1f52a7/pytest-html-1.20.0.tar.gz";
-        sha256 = "17jyn4czkihrs225nkpj0h113hc03y0cl07myb70jkaykpfmrim7";
-      };
-    };
+    # pytest_html = buildPythonPackage {
+    #   name = "pytest-html-1.20.0";
+    #   doCheck = false;
+    #   propagatedBuildInputs = [
+    #     pythonPackages.pytest
+    #     pytest_metadata
+    #   ];
+    #   src = builtins.fetchurl {
+    #     url = "https://files.pythonhosted.org/packages/08/3e/63d998f26c7846d3dac6da152d1b93db3670538c5e2fe18b88690c1f52a7/pytest-html-1.20.0.tar.gz";
+    #     sha256 = "17jyn4czkihrs225nkpj0h113hc03y0cl07myb70jkaykpfmrim7";
+    #   };
+    # };
   };
 in
   jobs
diff -burN '--exclude=.git*' ./batsched/meson.build ./new_batsched/meson.build
--- ./batsched/meson.build	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/meson.build	2023-06-28 08:26:02.127166524 -0400
@@ -1,11 +1,13 @@
 project('batsched', 'cpp',
     version: '1.4.0',
     license: 'free',
-    default_options: ['cpp_std=c++11'],
+    default_options: ['cpp_std=c++17'],
     meson_version: '>=0.40.0'
 )
 
 # Dependencies
+add_project_arguments(['-Wno-error'],language: 'cpp')
+add_project_link_arguments(['-lstdc++fs'], language : 'cpp')
 boost_dep = dependency('boost',
     modules : ['locale', 'regex', 'system']
 )
@@ -27,53 +29,74 @@
 ]
 
 # Source files
+#    'src/algo/conservative_bf.cpp',
+#    'src/algo/conservative_bf.hpp',
+#    'src/algo/crasher.cpp',
+#    'src/algo/crasher.hpp',
+    
+#    'src/algo/easy_bf_fast.cpp',
+#    'src/algo/easy_bf_fast.hpp',
+    
+#    'src/algo/easy_bf_plot_liquid_load_horizon.cpp',
+#    'src/algo/easy_bf_plot_liquid_load_horizon.hpp',
+#    'src/algo/energy_bf.cpp',
+#    'src/algo/energy_bf_dicho.cpp',
+#    'src/algo/energy_bf_dicho.hpp',
+#    'src/algo/energy_bf.hpp',
+#    'src/algo/energy_bf_idle_sleeper.cpp',
+#    'src/algo/energy_bf_idle_sleeper.hpp',
+#    'src/algo/energy_bf_machine_subpart_sleeper.cpp',
+#    'src/algo/energy_bf_machine_subpart_sleeper.hpp',
+#    'src/algo/energy_bf_monitoring_inertial_shutdown.cpp',
+#    'src/algo/energy_bf_monitoring_inertial_shutdown.hpp',
+#    'src/algo/energy_bf_monitoring_period.cpp',
+#    'src/algo/energy_bf_monitoring_period.hpp',
+#    'src/algo/energy_watcher.cpp',
+#    'src/algo/energy_watcher.hpp',
+#    'src/algo/fcfs_fast.cpp',
+#    'src/algo/fcfs_fast.hpp',
+#    'src/algo/filler.hpp',
+#    'src/algo/filler.cpp',
+#    'src/algo/killer2.cpp',
+#    'src/algo/killer2.hpp',
+#    'src/algo/killer.cpp',
+#    'src/algo/killer.hpp',
+#    'src/algo/random.cpp',
+#    'src/algo/random.hpp',
+#    'src/algo/rejecter.cpp',
+#    'src/algo/rejecter.hpp',
+#    'src/algo/sequencer.cpp',
+#    'src/algo/sequencer.hpp',
+#    'src/algo/sleeper.cpp',
+#    'src/algo/sleeper.hpp',
+#    'src/algo/submitter.cpp',
+#    'src/algo/submitter.hpp',
+#    'src/algo/wt_estimator.cpp',
+#    'src/algo/wt_estimator.hpp',
+#    'src/algo/easy_bf_fast2.cpp',
+#    'src/algo/easy_bf_fast2.hpp',
+#    'src/algo/easy_bf_fast2_holdback.cpp',
+#    'src/algo/easy_bf_fast2_holdback.hpp',
+#    'src/algo/fcfs_fast2.cpp',
+#    'src/algo/fcfs_fast2.hpp',
+#    'src/algo/conservative_bf.cpp',
+#    'src/algo/conservative_bf.hpp',
+#    'src/data_storage.cpp',
+#    'src/data_storage.hpp'
+
 src = [
-    'src/algo/conservative_bf.cpp',
-    'src/algo/conservative_bf.hpp',
-    'src/algo/crasher.cpp',
-    'src/algo/crasher.hpp',
     'src/algo/easy_bf.cpp',
-    'src/algo/easy_bf_fast.cpp',
-    'src/algo/easy_bf_fast.hpp',
     'src/algo/easy_bf.hpp',
-    'src/algo/easy_bf_plot_liquid_load_horizon.cpp',
-    'src/algo/easy_bf_plot_liquid_load_horizon.hpp',
-    'src/algo/energy_bf.cpp',
-    'src/algo/energy_bf_dicho.cpp',
-    'src/algo/energy_bf_dicho.hpp',
-    'src/algo/energy_bf.hpp',
-    'src/algo/energy_bf_idle_sleeper.cpp',
-    'src/algo/energy_bf_idle_sleeper.hpp',
-    'src/algo/energy_bf_machine_subpart_sleeper.cpp',
-    'src/algo/energy_bf_machine_subpart_sleeper.hpp',
-    'src/algo/energy_bf_monitoring_inertial_shutdown.cpp',
-    'src/algo/energy_bf_monitoring_inertial_shutdown.hpp',
-    'src/algo/energy_bf_monitoring_period.cpp',
-    'src/algo/energy_bf_monitoring_period.hpp',
-    'src/algo/energy_watcher.cpp',
-    'src/algo/energy_watcher.hpp',
-    'src/algo/fcfs_fast.cpp',
-    'src/algo/fcfs_fast.hpp',
-    'src/algo/fcfs.cpp',
-    'src/algo/fcfs.hpp',
-    'src/algo/filler.cpp',
-    'src/algo/filler.hpp',
-    'src/algo/killer2.cpp',
-    'src/algo/killer2.hpp',
-    'src/algo/killer.cpp',
-    'src/algo/killer.hpp',
-    'src/algo/random.cpp',
-    'src/algo/random.hpp',
-    'src/algo/rejecter.cpp',
-    'src/algo/rejecter.hpp',
-    'src/algo/sequencer.cpp',
-    'src/algo/sequencer.hpp',
-    'src/algo/sleeper.cpp',
-    'src/algo/sleeper.hpp',
-    'src/algo/submitter.cpp',
-    'src/algo/submitter.hpp',
-    'src/algo/wt_estimator.cpp',
-    'src/algo/wt_estimator.hpp',
+    'src/algo/easy_bf_fast2.cpp',
+    'src/algo/easy_bf_fast2.hpp',
+    'src/algo/easy_bf_fast2_holdback.cpp',
+    'src/algo/easy_bf_fast2_holdback.hpp',
+    'src/algo/fcfs_fast2.cpp',
+    'src/algo/fcfs_fast2.hpp',
+    'src/algo/conservative_bf.cpp',
+    'src/algo/conservative_bf.hpp',
+    'src/batsched_tools.cpp',
+    'src/batsched_tools.hpp',
     'src/data_storage.cpp',
     'src/data_storage.hpp',
     'src/decision.cpp',
@@ -87,6 +110,8 @@
     'src/locality.cpp',
     'src/locality.hpp',
     'src/main.cpp',
+    'src/machine.cpp',
+    'src/machine.hpp',
     'src/network.cpp',
     'src/network.hpp',
     'src/pempek_assert.cpp',
@@ -98,7 +123,16 @@
     'src/queueing_theory_waiting_time_estimator.cpp',
     'src/queueing_theory_waiting_time_estimator.hpp',
     'src/schedule.cpp',
-    'src/schedule.hpp'
+    'src/schedule.hpp',
+    'src/external/batsched_workload.hpp',
+    'src/external/batsched_workload.cpp',
+    'src/external/batsched_profile.hpp',
+    'src/external/batsched_profile.cpp',
+    'src/external/batsched_job.hpp',
+    'src/external/batsched_job.cpp'
+    
+    
+    
 ]
 include_dir = include_directories('src')
 
diff -burN '--exclude=.git*' ./batsched/release.nix ./new_batsched/release.nix
--- ./batsched/release.nix	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/release.nix	2023-06-28 08:26:02.127166524 -0400
@@ -28,7 +28,7 @@
       mesonFlags = []
         ++ pkgs.lib.optional doCoverage [ "-Db_coverage=true" ];
       nativeBuildInputs = with kapack; [pkgs.meson pkgs.ninja pkgs.pkgconfig
-        pkgs.boost pkgs.gmp pkgs.rapidjson intervalset loguru redox pkgs.cppzmq pkgs.zeromq];
+        pkgs.boost pkgs.gmp pkgs.rapidjson intervalset loguru pkgs.cppzmq pkgs.zeromq];
       # Debug build, without any Nix stripping magic.
       mesonBuildType = "debug";
       hardeningDisable = [ "all" ];
@@ -36,112 +36,112 @@
       # Keep files generated by GCOV, so depending jobs can use them.
       postInstall = pkgs.lib.optionalString doCoverage ''
         mkdir -p $out/gcno
-        cp batsched@exe/*.gcno $out/gcno/
+        cp batsched.p/*.gcno $out/gcno/
       '';
     });
 
     # Batsched integration tests.
-    integration_tests = pkgs.stdenv.mkDerivation rec {
-      pname = "batsched-integration-tests";
-      version = toString builtins.currentTime; # Forces rebuild
-      src = pkgs.lib.sourceByRegex ./. [
-        "^test"
-        "^test/.*\.py"
-        "^test/platforms"
-        "^test/platforms/.*\.xml"
-        "^test/workloads"
-        "^test/workloads/.*\.json"
-      ];
-      buildInputs = with pkgs.python37Packages; [
-        batsim batsched batexpe pkgs.redis
-        pytest pytest_html pandas];
-      preBuild = pkgs.lib.optionalString doCoverage ''
-        mkdir -p gcda
-        export GCOV_PREFIX=$(realpath gcda)
-        export GCOV_PREFIX_STRIP=5
-      '';
-      buildPhase = ''
-        runHook preBuild
-        set +e
-        (cd test && pytest -ra --html=../report/pytest_report.html)
-        echo $? > ./pytest_returncode
-        set -e
-      '';
-      checkPhase = ''
-        pytest_return_code=$(cat ./pytest_returncode)
-        echo "pytest return code: $pytest_return_code"
-        if [ $pytest_return_code -ne 0 ] ; then
-          exit 1
-        fi
-      '';
-      inherit doCheck;
-      installPhase = ''
-        mkdir -p $out
-        mv ./report/* ./pytest_returncode $out/
-      '' + pkgs.lib.optionalString doCoverage ''
-        mv ./gcda $out/
-      '';
-    };
+    # integration_tests = pkgs.stdenv.mkDerivation rec {
+    #   pname = "batsched-integration-tests";
+    #   version = toString builtins.currentTime; # Forces rebuild
+    #   src = pkgs.lib.sourceByRegex ./. [
+    #     "^test"
+    #     "^test/.*\.py"
+    #     "^test/platforms"
+    #     "^test/platforms/.*\.xml"
+    #     "^test/workloads"
+    #     "^test/workloads/.*\.json"
+    #   ];
+    #   buildInputs = with pkgs.python37Packages; [
+    #     batsim batsched batexpe
+    #     pytest pytest_html pandas];
+    #   preBuild = pkgs.lib.optionalString doCoverage ''
+    #     mkdir -p gcda
+    #     export GCOV_PREFIX=$(realpath gcda)
+    #     export GCOV_PREFIX_STRIP=5
+    #   '';
+    #   buildPhase = ''
+    #     runHook preBuild
+    #     set +e
+    #     (cd test && pytest -ra --html=../report/pytest_report.html)
+    #     echo $? > ./pytest_returncode
+    #     set -e
+    #   '';
+    #   checkPhase = ''
+    #     pytest_return_code=$(cat ./pytest_returncode)
+    #     echo "pytest return code: $pytest_return_code"
+    #     if [ $pytest_return_code -ne 0 ] ; then
+    #       exit 1
+    #     fi
+    #   '';
+    #   inherit doCheck;
+    #   installPhase = ''
+    #     mkdir -p $out
+    #     mv ./report/* ./pytest_returncode $out/
+    #   '' + pkgs.lib.optionalString doCoverage ''
+    #     mv ./gcda $out/
+    #   '';
+    # };
     # Essentially the same as integration_tests, but with an up-to-date Batsim.
-    integration_tests_batlatest = integration_tests.overrideAttrs (attr: rec {
-      buildInputs = with pkgs.python37Packages; [
-        batsim-master batsched batexpe pkgs.redis
-        pytest pytest_html pandas];
-    });
+    # integration_tests_batlatest = integration_tests.overrideAttrs (attr: rec {
+    #   buildInputs = with pkgs.python37Packages; [
+    #     batsim-master batsched batexpe
+    #     pytest pytest_html pandas];
+    # });
 
     # Batsched doxygen documentation.
-    doxydoc = pkgs.stdenv.mkDerivation rec {
-      name = "batsim-doxygen-documentation";
-      src = pkgs.lib.sourceByRegex ./. [
-        "^src"
-        "^src/.*\.?pp"
-        "^doc"
-        "^doc/Doxyfile"
-        "^doc/doxygen_mainpage.md"
-      ];
-      buildInputs = [pkgs.doxygen];
-      buildPhase = "(cd doc && doxygen)";
-      installPhase = ''
-        mkdir -p $out
-        mv doc/doxygen_doc/html/* $out/
-      '';
-      checkPhase = ''
-        nb_warnings=$(cat doc/doxygen_warnings.log | wc -l)
-        if [[ $nb_warnings -gt 0 ]] ; then
-          echo "FAILURE: There are doxygen warnings!"
-          cat doc/doxygen_warnings.log
-          exit 1
-        fi
-      '';
-      doCheck = true;
-    };
+    # doxydoc = pkgs.stdenv.mkDerivation rec {
+    #   name = "batsim-doxygen-documentation";
+    #   src = pkgs.lib.sourceByRegex ./. [
+    #     "^src"
+    #     "^src/.*\.?pp"
+    #     "^doc"
+    #     "^doc/Doxyfile"
+    #     "^doc/doxygen_mainpage.md"
+    #   ];
+    #   buildInputs = [pkgs.doxygen];
+    #   buildPhase = "(cd doc && doxygen)";
+    #   installPhase = ''
+    #     mkdir -p $out
+    #     mv doc/doxygen_doc/html/* $out/
+    #   '';
+    #   checkPhase = ''
+    #     nb_warnings=$(cat doc/doxygen_warnings.log | wc -l)
+    #     if [[ $nb_warnings -gt 0 ]] ; then
+    #       echo "FAILURE: There are doxygen warnings!"
+    #       cat doc/doxygen_warnings.log
+    #       exit 1
+    #     fi
+    #   '';
+    #   doCheck = true;
+    # };
 
     # Dependencies not in nixpkgs as I write these lines.
-    pytest_metadata = buildPythonPackage {
-      name = "pytest-metadata-1.8.0";
-      doCheck = false;
-      propagatedBuildInputs = [
-        pythonPackages.pytest
-        pythonPackages.setuptools_scm
-      ];
-      src = builtins.fetchurl {
-        url = "https://files.pythonhosted.org/packages/12/38/eed3a1e00c765e4da61e4e833de41c3458cef5d18e819d09f0f160682993/pytest-metadata-1.8.0.tar.gz";
-        sha256 = "1fk6icip2x1nh4kzhbc8cnqrs77avpqvj7ny3xadfh6yhn9aaw90";
-      };
-    };
+    # pytest_metadata = buildPythonPackage {
+    #   name = "pytest-metadata-1.8.0";
+    #   doCheck = false;
+    #   propagatedBuildInputs = [
+    #     pythonPackages.pytest
+    #     pythonPackages.setuptools_scm
+    #   ];
+    #   src = builtins.fetchurl {
+    #     url = "https://files.pythonhosted.org/packages/12/38/eed3a1e00c765e4da61e4e833de41c3458cef5d18e819d09f0f160682993/pytest-metadata-1.8.0.tar.gz";
+    #     sha256 = "1fk6icip2x1nh4kzhbc8cnqrs77avpqvj7ny3xadfh6yhn9aaw90";
+    #   };
+    # };
 
-    pytest_html = buildPythonPackage {
-      name = "pytest-html-1.20.0";
-      doCheck = false;
-      propagatedBuildInputs = [
-        pythonPackages.pytest
-        pytest_metadata
-      ];
-      src = builtins.fetchurl {
-        url = "https://files.pythonhosted.org/packages/08/3e/63d998f26c7846d3dac6da152d1b93db3670538c5e2fe18b88690c1f52a7/pytest-html-1.20.0.tar.gz";
-        sha256 = "17jyn4czkihrs225nkpj0h113hc03y0cl07myb70jkaykpfmrim7";
-      };
-    };
+    # pytest_html = buildPythonPackage {
+    #   name = "pytest-html-1.20.0";
+    #   doCheck = false;
+    #   propagatedBuildInputs = [
+    #     pythonPackages.pytest
+    #     pytest_metadata
+    #   ];
+    #   src = builtins.fetchurl {
+    #     url = "https://files.pythonhosted.org/packages/08/3e/63d998f26c7846d3dac6da152d1b93db3670538c5e2fe18b88690c1f52a7/pytest-html-1.20.0.tar.gz";
+    #     sha256 = "17jyn4czkihrs225nkpj0h113hc03y0cl07myb70jkaykpfmrim7";
+    #   };
+    # };
   };
 in
   jobs
diff -burN '--exclude=.git*' ./batsched/src/algo/conservative_bf.cpp ./new_batsched/src/algo/conservative_bf.cpp
--- ./batsched/src/algo/conservative_bf.cpp	2023-07-01 09:20:31.850842135 -0400
+++ ./new_batsched/src/algo/conservative_bf.cpp	2023-06-28 08:26:02.133833308 -0400
@@ -3,7 +3,10 @@
 #include <loguru.hpp>
 
 #include "../pempek_assert.hpp"
-
+#include "../batsched_tools.hpp"
+#include <chrono>
+#include <ctime>
+#define B_LOG_INSTANCE _myBLOG
 using namespace std;
 
 ConservativeBackfilling::ConservativeBackfilling(Workload *workload, SchedulingDecision *decision,
@@ -23,37 +26,413 @@
                 "Invalid options: 'dump_prefix' should be a string");
         _dump_prefix = (*variant_options)["dump_prefix"].GetString();
     }
+    //initialize reservation queue
+    SortableJobOrder * order = new FCFSOrder;
+    _reservation_queue = new Queue(order);
+    
 }
 
 ConservativeBackfilling::~ConservativeBackfilling()
 {
 }
 
-void ConservativeBackfilling::on_simulation_start(double date, const rapidjson::Value & batsim_config)
+void ConservativeBackfilling::on_simulation_start(double date, const rapidjson::Value & batsim_event)
 {
+    const rapidjson::Value & batsim_config = batsim_event["config"];
+    LOG_F(INFO,"ON simulation start");
+    _output_svg=batsim_config["output-svg"].GetString();
+    _svg_frame_start = batsim_config["svg-frame-start"].GetInt64();
+    _svg_frame_end = batsim_config["svg-frame-end"].GetInt64();
+    _svg_output_start = batsim_config["svg-output-start"].GetInt64();
+    _svg_output_end = batsim_config["svg-output-end"].GetInt64();
+    LOG_F(INFO,"output svg %s",_output_svg.c_str());
+    
+    _output_folder=batsim_config["output-folder"].GetString();
+    
+    _output_folder.replace(_output_folder.rfind("/out"), std::string("/out").size(), "");
+    
+    LOG_F(INFO,"output folder %s",_output_folder.c_str());
+    
+    Schedule::convert_policy(batsim_config["reschedule-policy"].GetString(),_reschedule_policy);
+    Schedule::convert_policy(batsim_config["impact-policy"].GetString(),_impact_policy);
+
     _schedule = Schedule(_nb_machines, date);
+    _schedule.set_output_svg(_output_svg);
+    _schedule.set_svg_frame_and_output_start_and_end(_svg_frame_start,_svg_frame_end,_svg_output_start,_svg_output_end);
+    _schedule.set_svg_prefix(_output_folder + "/svg/");
+    _schedule.set_policies(_reschedule_policy,_impact_policy);
+   
+    unsigned seed = 0;
+    if (_workload->_seed_failures)
+        seed = std::chrono::system_clock::now().time_since_epoch().count();
+    generator.seed(seed);
+    generator2.seed(seed);
+    if (_workload->_fixed_failures != -1.0)
+     {
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        double number = _myWorkloads->_fixed_failures;
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);  
+     }
+    if (_workload->_SMTBF != -1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_SMTBF);
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_SMTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+    }
+    else if (_workload->_MTBF!=-1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_MTBF);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_MTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+    }
+    _recently_under_repair_machines = IntervalSet::empty_interval_set();
+    
     (void) batsim_config;
 }
 
+
 void ConservativeBackfilling::on_simulation_end(double date)
 {
     (void) date;
 }
+void ConservativeBackfilling::set_workloads(myBatsched::Workloads *w){
+    _myWorkloads = w;
+    _checkpointing_on = w->_checkpointing_on;
+    
+}
+void ConservativeBackfilling::set_machines(Machines *m){
+    _machines = m;
+}
+void ConservativeBackfilling::on_machine_down_for_repair(batsched_tools::KILL_TYPES forWhat,double date){
+    (void) date;
+    auto sort_original_submit_pair = [](const std::pair<const Job *,IntervalSet> j1,const std::pair<const Job *,IntervalSet> j2)->bool{
+            if (j1.first->submission_times[0] == j2.first->submission_times[0])
+                return j1.first->id < j2.first->id;
+            else
+                return j1.first->submission_times[0] < j2.first->submission_times[0];
+    };
+   
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = (*_machines)[number]->id;
+    
+    if (_output_svg == "all")
+            _schedule.output_to_svg("On Machine Down For Repairs  Machine #:  "+std::to_string((*_machines)[number]->id));
+    
+    IntervalSet added = IntervalSet::empty_interval_set() ;
+    if (_schedule.get_reservations_running_on_machines(machine).empty())
+        added = _schedule.add_repair_machines(machine);
+    LOG_F(INFO,"here");
+    //if the machine is already down for repairs ignore it.
+    //LOG_F(INFO,"repair_machines.size(): %d    nb_avail: %d  avail:%d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+    //BLOG_F(b_log::FAILURES,"Machine Repair: %d",number);
+    if (!added.is_empty())
+    {
+        LOG_F(INFO,"here");
+        _schedule.add_svg_highlight_machines(machine);
+        //ok the machine is not down for repairs already so it WAS added
+        //the failure/repair will not be happening on a machine that has a reservation on it either
+        //it will be going down for repairs now
+         LOG_F(INFO,"here");
+        double repair_time = (*_machines)[number]->repair_time;
+         LOG_F(INFO,"here");
+        //call me back when the repair is done
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::REPAIR_DONE,number,date+repair_time,date);
+        LOG_F(INFO,"here");
+        if (_schedule.get_number_of_running_jobs() > 0 )
+        {
+            //there are possibly some running jobs to kill
+             LOG_F(INFO,"here");
+            std::vector<std::string> jobs_to_kill;
+            _schedule.get_jobs_running_on_machines(machine,jobs_to_kill);
+              
+              std::string jobs_to_kill_str = !(jobs_to_kill.empty())? std::accumulate( /* otherwise, accumulate */
+    ++jobs_to_kill.begin(), jobs_to_kill.end(), /* the range 2nd to after-last */
+    *jobs_to_kill.begin(), /* and start accumulating with the first item */
+    [](auto& a, auto& b) { return a + "," + b; }) : "";
+              
+            LOG_F(INFO,"jobs to kill %s",jobs_to_kill_str.c_str());
+
+            if (!jobs_to_kill.empty()){
+                _recently_under_repair_machines+=machine;
+                std::vector<batsched_tools::Job_Message *> msgs;
+                for (auto job_id : jobs_to_kill){
+                    auto msg = new batsched_tools::Job_Message;
+                    msg->id = job_id;
+                    msg->forWhat = forWhat;
+                    msgs.push_back(msg);
+                }
+                _killed_jobs=true;
+                _decision->add_kill_job(msgs,date);
+                for (auto job_id:jobs_to_kill)
+                    _schedule.remove_job_if_exists((*_workload)[job_id]);
+            }
+            else{
+                    //ok there are no jobs to kill
+                    //lets reschedule
+                    if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::AFFECTED)
+                    {
+                        std::map<const Job*,IntervalSet> jobs_affected;
+                        _schedule.get_jobs_affected_on_machines(machine, jobs_affected);
+                        std::vector<std::pair<const Job *,IntervalSet>> jobs_affectedV;
+                        for (auto job_interval_pair : jobs_affected)
+                        {
+                            jobs_affectedV.push_back(job_interval_pair);
+                            _schedule.remove_job(job_interval_pair.first);
+                        }
+                        std::sort(jobs_affectedV.begin(),jobs_affectedV.end(),sort_original_submit_pair);
+                        
+                        for (auto job_interval_pair : jobs_affectedV)
+                        {
+                        Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job_interval_pair.first,_selector,false);
+                        if (!(alloc.used_machines.is_empty()) && alloc.started_in_first_slice)
+                            {
+                                _decision->add_execute_job(job_interval_pair.first->id, alloc.used_machines, date);
+                                _queue->remove_job(job_interval_pair.first);
+                            }
+                            
+                        }
+
+                        
+                    }
+                    else if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::ALL)
+                    {
+                        //lets reschedule everything
+                        int scheduled = 0;
+                        for (auto job_it = _queue->begin(); job_it != _queue->end(); )
+                        {
+                            if (_workload->_queue_depth != -1 && scheduled >= _workload->_queue_depth)
+                                break;
+                            
+                            const Job * job = (*job_it)->job;
+                            _schedule.remove_job_if_exists(job);
+                    //            if (_dump_provisional_schedules)
+                    //                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+                            LOG_F(INFO,"DEBUG line 375");
+                            Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job, _selector,false);   
+                    //            if (_dump_provisional_schedules)
+                    //                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+                            if(!alloc.used_machines.is_empty())
+                            {
+                                scheduled++;
+                                if (alloc.started_in_first_slice)
+                                {
+                                    _decision->add_execute_job(job->id, alloc.used_machines, date);
+                                    job_it = _queue->remove_job(job_it);
+                                    scheduled--;
+                                }
+                                else
+                                    ++job_it;
+                            }
+                            else
+                                ++job_it;
+                        }
+                        
+                    }
+                    if (_output_svg == "all")
+                        _schedule.output_to_svg("Finished Machine Down For Repairs, Machine #: "+std::to_string(number));
+
+                }
+        }
+    }
+    else{
+        //if (!added.is_empty())
+        //  _schedule.remove_repair_machines(machine);
+        //_schedule.remove_svg_highlight_machines(machine);
+        if (_output_svg == "all")
+            _schedule.output_to_svg("Finished Machine Down For Repairs, NO REPAIR  Machine #:  "+std::to_string(number));
+    
+    }
+    
+        
+  
+    
+}
+
+
+void ConservativeBackfilling::on_machine_instant_down_up(batsched_tools::KILL_TYPES forWhat,double date){
+    (void) date;
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    _schedule.add_svg_highlight_machines(machine);
+    if (_output_svg == "all")
+            _schedule.output_to_svg("On Machine Instant Down Up  Machine #: "+std::to_string(number));
+    
+    //BLOG_F(b_log::FAILURES,"Machine Instant Down Up: %d",number);
+    LOG_F(INFO,"instant down up machine number %d",number);
+    //if there are no running jobs, then there are none to kill
+    if (_schedule.get_number_of_running_jobs() > 0){
+        //ok so there are running jobs
+        LOG_F(INFO,"instant down up");
+        std::vector<std::string> jobs_to_kill;
+        _schedule.get_jobs_running_on_machines(machine,jobs_to_kill);
+         LOG_F(INFO,"instant down up");
+        
+        LOG_F(INFO,"instant down up");
+        if (!jobs_to_kill.empty())
+        {
+            _killed_jobs = true;
+            std::vector<batsched_tools::Job_Message *> msgs;
+            for (auto job_id : jobs_to_kill){
+                auto msg = new batsched_tools::Job_Message;
+                msg->id = job_id;
+                msg->forWhat = forWhat;
+                msgs.push_back(msg);
+            }
+            _decision->add_kill_job(msgs,date);
+            std::string jobs_to_kill_string;
+            //remove jobs to kill from schedule and add to our log string
+             LOG_F(INFO,"instant down up");
+            for (auto job_id:jobs_to_kill)
+            {
+                jobs_to_kill_string += ", " + job_id;
+                _schedule.remove_job_if_exists((*_workload)[job_id]);
+
+            }
+             LOG_F(INFO,"instant down up");
+            //BLOG_F(b_log::FAILURES,"Killing Jobs: %s",jobs_to_kill_string.c_str());
+    
+        }
+            	
+	}
+    _schedule.remove_svg_highlight_machines(machine);
+    if (_output_svg == "all")
+            _schedule.output_to_svg("END On Machine Instant Down Up  Machine #: "+std::to_string(number));
+    
+}
+void ConservativeBackfilling::on_requested_call(double date,int id,batsched_tools::call_me_later_types forWhat)
+{
+        if (_output_svg != "none")
+            _schedule.set_now((Rational)date);
+        switch (forWhat){
+            
+            case batsched_tools::call_me_later_types::SMTBF:
+                        {
+                            //Log the failure
+                            //BLOG_F(b_log::FAILURES,"FAILURE SMTBF");
+                            if (_schedule.get_number_of_running_jobs() > 0 || !_queue->is_empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = distribution->operator()(generator);
+                                    if (_workload->_repair_time == 0.0)
+                                        _on_machine_instant_down_ups.push_back(batsched_tools::KILL_TYPES::SMTBF);                                        
+                                    else
+                                        _on_machine_down_for_repairs.push_back(batsched_tools::KILL_TYPES::SMTBF);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+                                }
+                        }
+                        break;
+            /* TODO
+            case batsched_tools::call_me_later_types::MTBF:
+                        {
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                            {
+                                double number = distribution->operator()(generator);
+                                on_myKillJob_notify_event(date);
+                                _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+
+                            }
+                        
+                            
+                        }
+                        break;
+            */
+            case batsched_tools::call_me_later_types::FIXED_FAILURE:
+                        {
+                            //BLOG_F(b_log::FAILURES,"FAILURE FIXED_FAILURE");
+                            LOG_F(INFO,"DEBUG");
+                            if (_schedule.get_number_of_running_jobs() > 0 || !_queue->is_empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    LOG_F(INFO,"DEBUG");
+                                    double number = _workload->_fixed_failures;
+                                    if (_workload->_repair_time == 0.0)
+                                        _on_machine_instant_down_ups.push_back(batsched_tools::KILL_TYPES::FIXED_FAILURE);//defer to after make_decisions
+                                    else
+                                        _on_machine_down_for_repairs.push_back(batsched_tools::KILL_TYPES::FIXED_FAILURE);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);
+                                }
+                        }
+                        break;
+            
+            case batsched_tools::call_me_later_types::REPAIR_DONE:
+                        {
+                            //BLOG_F(b_log::FAILURES,"REPAIR_DONE");
+                            //a repair is done, all that needs to happen is add the machines to available
+                            //and remove them from repair machines and add one to the number of available
+                            if (_output_svg == "all")
+                                _schedule.output_to_svg("top Repair Done  Machine #: "+std::to_string(id));
+                            IntervalSet machine = id;
+                            _schedule.remove_repair_machines(machine);
+                            _schedule.remove_svg_highlight_machines(machine);
+                             if (_output_svg == "all")
+                                _schedule.output_to_svg("bottom Repair Done  Machine #: "+std::to_string(id));
+                            _need_to_compress = true;
+                           //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d avail: %d  running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+                        }
+                        break;
+            
+            case batsched_tools::call_me_later_types::RESERVATION_START:
+                        {
+                            _start_a_reservation = true;
+                            //SortableJobOrder::UpdateInformation update_info(date);
+                            //make_decisions(date,&update_info,nullptr);
 
+                        }
+                        break;
+        }
+    
+
+}
 void ConservativeBackfilling::make_decisions(double date,
                                              SortableJobOrder::UpdateInformation *update_info,
                                              SortableJobOrder::CompareInformation *compare_info)
 {
+    
+    if (_output_svg != "none")
+        _schedule.set_now((Rational)date);
+    LOG_F(INFO,"make decisions");
+    //define a sort function for sorting jobs based on original submit times
+    auto sort_original_submit = [](const Job * j1,const Job * j2)->bool{
+            if (j1->submission_times[0] == j2->submission_times[0])
+                return j1->id < j2->id;
+            else
+                return j1->submission_times[0] < j2->submission_times[0];
+    };
+    
     // Let's remove finished jobs from the schedule
+    // not including killed jobs
+    time_t start = time(NULL);
     for (const string & ended_job_id : _jobs_ended_recently)
-        _schedule.remove_job((*_workload)[ended_job_id]);
+    {
+        _schedule.remove_job_if_exists((*_workload)[ended_job_id]);
+    }
+    time_t end = time(NULL);
 
+    
+    LOG_F(INFO,"after jobs ended");
     // Let's handle recently released jobs
     std::vector<std::string> recently_queued_jobs;
+    std::vector<std::string> recently_released_reservations;
     for (const string & new_job_id : _jobs_released_recently)
     {
+        
+        LOG_F(INFO,"jobs released");
         const Job * new_job = (*_workload)[new_job_id];
+        LOG_F(INFO,"job %s has purpose %s  and walltime: %g",new_job->id.c_str(),new_job->purpose.c_str(),(double)new_job->walltime);
 
+        if (new_job->purpose!="reservation")
+        {
         if (new_job->nb_requested_resources > _nb_machines)
         {
             _decision->add_reject_job(new_job_id, date);
@@ -70,31 +449,284 @@
             recently_queued_jobs.push_back(new_job_id);
         }
     }
+        else
+        {
+            _reservation_queue->append_job(new_job,update_info);
+            recently_released_reservations.push_back(new_job_id);
+        }
+    }
+    
+    //before we update the first slice make sure we have jobs in the schedule other than reservations
+
+    //int schedule_size = _schedule.size() - _schedule.nb_reservations_size();
+    //if (!_killed_jobs && _jobs_killed_recently.empty() && _reservation_queue->is_empty && schedule_size > 0 && _no_more_static_job_to_submit_received)
+    
+    //if we have a reservation that needs to be run, first make sure 
 
     // Let's update the schedule's present
+    
     _schedule.update_first_slice(date);
+    //check if the first slice has a reservation to run
+    if (_start_a_reservation)
+    {
+        Schedule::JobAlloc alloc;
+        std::vector<const Job *> jobs_removed;
+        LOG_F(INFO,"line 322");
+        if(_schedule.remove_reservations_if_ready(jobs_removed))
+        {
+            LOG_F(INFO,"DEBUG line 323");
+                for(const Job * job : jobs_removed)
+                {
+                    LOG_F(INFO,"DEBUG line 326");
+                    alloc = _schedule.add_current_reservation(job,_selector);
+                    LOG_F(INFO,"DEBUG line 328");
+                    _reservation_queue->remove_job(job);
+                    _decision->add_execute_job(alloc.job->id,alloc.used_machines,date);
+                    
+                }
+            //only set this to false if we  remove and execute some reservations
+            //keep true in case it comes back around after a job completes
+            _start_a_reservation = false;
+        }
+        
+    }
 
+    
+    if (_output_svg == "short")
+        _schedule.output_to_svg("make_decisions");
     // Queue sorting
     _queue->sort_queue(update_info, compare_info);
+    //LOG_F(INFO,"queue: %s",_queue->to_string().c_str());
+    _reservation_queue->sort_queue(update_info,compare_info);
+    for ( auto job_message_pair : _jobs_killed_recently)
+    {
+        batsched_tools::id_separation separation = batsched_tools::tools::separate_id(job_message_pair.first);
+        LOG_F(INFO,"next_resubmit_string %s",separation.next_resubmit_string.c_str());
+        _resubmitted_jobs[separation.next_resubmit_string]=job_message_pair.second->forWhat;
+    }
+    
+   
+    
+    //take care of killed jobs and reschedule jobs
+    //lifecycle of killed job:
+    //make_decisions() kill job -> make_decisions() submit job -> make_decisions() add jobs to schedule in correct order
+    // it is the third invocation that this function should run 
+    
+    handle_killed_jobs(recently_queued_jobs,date);
 
-    // If no resources have been released, we can just insert the new jobs into the schedule
-    if (_jobs_ended_recently.empty())
+   // LOG_F(ERROR,"handle_killed_jobs time: %d",end-start);
+    auto compare_reservations = [this](const std::string j1,const std::string j2)->bool{
+            
+            Job * job1= (*_workload)[j1];
+            Job * job2= (*_workload)[j2];
+            if (job1->future_allocations.is_empty() && job2->future_allocations.is_empty())
+                return j1 < j2;
+            else if (job1->future_allocations.is_empty())
+                return false;  // j1 has no allocation so it must be set up after j2
+            else if (job2->future_allocations.is_empty())
+                return true;
+            else
+                return j1 < j2;
+
+    };
+LOG_F(INFO,"here");
+    //sort reservations with jobs that have allocations coming first 
+    if (!recently_released_reservations.empty())           
     {
-        for (const string & new_job_id : recently_queued_jobs)
+        LOG_F(INFO,"here size: %d",recently_released_reservations.size());
+        for(std::string resv:recently_released_reservations)
+            LOG_F(INFO,"resv: %s",resv.c_str());
+        std::sort(recently_released_reservations.begin(),recently_released_reservations.end(),compare_reservations);
+        handle_reservations(recently_released_reservations,recently_queued_jobs,date);
+    }
+    LOG_F(INFO,"here");
+    //insert reservations into schedule whether jobs have finished or not
+    
+    LOG_F(INFO,"here");
+    
+    for(batsched_tools::KILL_TYPES forWhat : _on_machine_instant_down_ups)
+    {
+        on_machine_instant_down_up(forWhat,date);
+    }
+    
+    //LOG_F(ERROR,"on_machine_instant_down_up time: %d",end-start);
+    _on_machine_instant_down_ups.clear();
+    for(batsched_tools::KILL_TYPES forWhat : _on_machine_down_for_repairs)
+    {
+        on_machine_down_for_repair(forWhat,date);
+    }
+    _on_machine_down_for_repairs.clear();
+    LOG_F(INFO,"here");
+    
+    _decision->handle_resubmission(_jobs_killed_recently,_workload,date);
+    //end=time(NULL);
+    //LOG_F(ERROR,"resubmission time: %d",end-start);
+    //start=time(NULL);
+
+    handle_schedule(recently_queued_jobs,date);
+   //end=time(NULL);
+   //LOG_F(ERROR,"handle_schedule time: %d",end-start);
+
+
+LOG_F(INFO,"here");
+
+
+    // And now let's see if we can estimate some waiting times
+    
+    for (const std::string & job_id : _jobs_whose_waiting_time_estimation_has_been_requested_recently)
         {
+        const Job * new_job = (*_workload)[job_id];
+        double answer = _schedule.query_wait(new_job->nb_requested_resources, new_job->walltime, _selector);
+            _decision->add_answer_estimate_waiting_time(job_id, answer, date);
+    }
+
+    if (_dump_provisional_schedules)
+        _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+    /*
+    
+    //LOG_F(INFO,"res_queue %s",_reservation_queue->to_string().c_str());
+    */
+
+   //this is what normally has to happen to end the simulation
+    if (!_killed_jobs && _jobs_killed_recently.empty() && _queue->is_empty() && _reservation_queue->is_empty() && _schedule.size() == 0 &&
+             _need_to_send_finished_submitting_jobs && _no_more_static_job_to_submit_received && !(date<1.0) )
+    {
+      //  LOG_F(INFO,"finished_submitting_jobs sent");
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        if (_output_svg == "all" || _output_svg == "short")
+            _schedule.output_to_svg("Simulation Finished");
+        _schedule.set_output_svg("none");
+        _output_svg = "none";
+        _need_to_send_finished_submitting_jobs = false;
+    }
+    LOG_F(INFO,"here");
+    //LOG_F(INFO,"!killed= %d  jkr = %d  qie = %d rqie = %d ss = %d ntsfsj = %d nmsjtsr = %d",
+    //!_killed_jobs,_jobs_killed_recently.empty(), _queue->is_empty(), _reservation_queue->is_empty() , _schedule.size(),
+    //         _need_to_send_finished_submitting_jobs , _no_more_static_job_to_submit_received);
+    //if there are jobs that can't run then we need to start rejecting them at this point
+    if (!_killed_jobs && _jobs_killed_recently.empty() && _reservation_queue->is_empty() && _schedule.size() == 0 &&
+             _need_to_send_finished_submitting_jobs && _no_more_static_job_to_submit_received && !(date<1.0) )
+    {
+      //  LOG_F(INFO,"here");
+        bool able=false; //this will stay false unless there is a job that can run
+        auto previous_to_end = _schedule.end();
+        previous_to_end--;
+        for (auto itr = _queue->begin();itr!=_queue->end();++itr)
+        {
+        //     LOG_F(INFO,"here");
+            
+            if ((*itr)->job->nb_requested_resources <= previous_to_end->available_machines.size())
+                able=true;
+          //   LOG_F(INFO,"here");
+        }
+        if (!able)
+        {
+            // LOG_F(INFO,"here");
+            //ok we are not able to run things, start rejecting the jobs
+            for ( auto itr = _queue->begin();itr!=_queue->end();++itr)
+            {
+              //   LOG_F(INFO,"here");
+              //  LOG_F(INFO,"Rejecting job %s",(*itr)->job->id.c_str());
+                _decision->add_reject_job((*itr)->job->id,date);
+                itr=_queue->remove_job(itr);
+                // LOG_F(INFO,"here");
+            }
+        }
+        
+    }
+
+    _decision->add_generic_notification("queue_size",std::to_string(_queue->nb_jobs()),date);
+    _decision->add_generic_notification("schedule_size",std::to_string(_schedule.size()),date);
+    _decision->add_generic_notification("number_running_jobs",std::to_string(_schedule.get_number_of_running_jobs()),date);
+    _decision->add_generic_notification("utilization",std::to_string(_schedule.get_utilization()),date);
+    _decision->add_generic_notification("utilization_no_resv",std::to_string(_schedule.get_utilization_no_resv()),date);
+}
+
+
+
+
+
+
+
+void ConservativeBackfilling::handle_schedule(std::vector<std::string> & recently_queued_jobs,double date)
+{
+
+auto sort_original_submit = [](const Job * j1,const Job * j2)->bool{
+            if (j1->submission_times[0] == j2->submission_times[0])
+                return j1->id < j2->id;
+            else
+                return j1->submission_times[0] < j2->submission_times[0];
+    };
+// If no resources have been released, we can just insert the new jobs into the schedule
+    if (_jobs_ended_recently.empty() && !_killed_jobs)
+    {
+        //if there were some saved queued jobs from killing jobs take care of them
+    
+        if (recently_queued_jobs.empty() && !_saved_recently_queued_jobs.empty())
+        {
+            
+            int scheduled = _schedule.nb_jobs_size() - _schedule.get_number_of_running_jobs();
+            if(_output_svg == "all")
+                _schedule.output_to_svg("CONSERVATIVE_BF saved queued ADDING");
+            for (const string & new_job_id : _saved_recently_queued_jobs)
+            {
+                if (_workload->_queue_depth != -1 && scheduled >=_workload->_queue_depth)
+                    break;
+                
             const Job * new_job = (*_workload)[new_job_id];
-            Schedule::JobAlloc alloc = _schedule.add_job_first_fit(new_job, _selector);
+                //LOG_F(INFO,"DEBUG line 321");
+                    
+                Schedule::JobAlloc alloc = _schedule.add_job_first_fit(new_job, _selector,false);
 
             // If the job should start now, let's say it to the resource manager
+                if (!alloc.used_machines.is_empty())
+                {
+                    scheduled++;
+                
             if (alloc.started_in_first_slice)
             {
                 _decision->add_execute_job(new_job->id, alloc.used_machines, date);
                 _queue->remove_job(new_job);
+                        scheduled--;
+                    }
             }
         }
+            if(_output_svg == "all")
+                _schedule.output_to_svg("CONSERVATIVE_BF saved queued ADDING DONE");
+            _saved_recently_queued_jobs.clear();
     }
     else
     {
+            int scheduled = _schedule.nb_jobs_size() - _schedule.get_number_of_running_jobs();
+            if(_output_svg == "all")
+                _schedule.output_to_svg("CONSERVATIVE_BF recent queued ADDING");
+            for (const string & new_job_id : recently_queued_jobs)
+            {
+                if (_workload->_queue_depth != -1 && scheduled >=_workload->_queue_depth)
+                    break;
+                const Job * new_job = (*_workload)[new_job_id];
+                //LOG_F(INFO,"DEBUG line 337");
+                    
+                Schedule::JobAlloc alloc = _schedule.add_job_first_fit(new_job, _selector,false);
+
+                // If the job should start now, let's say it to the resource manager
+                 if (!alloc.used_machines.is_empty())
+                {
+                    scheduled++;
+                    if (alloc.started_in_first_slice)
+                    {
+                        _decision->add_execute_job(new_job->id, alloc.used_machines, date);
+                        _queue->remove_job(new_job);
+                        scheduled--;
+                    }
+                }
+            }
+            if(_output_svg == "all")
+                _schedule.output_to_svg("CONSERVATIVE_BF recent queued ADDING DONE");
+        }
+    }
+    if ((!_jobs_ended_recently.empty() || _need_to_compress) && !_killed_jobs)
+    {
         // Since some resources have been freed,
         // Let's compress the schedule following conservative backfilling rules:
         // For each non running job j
@@ -102,36 +734,625 @@
         //   Add j into the schedule
         //   If j should be executed now
         //     Take the decision to run j now
+        if (_output_svg == "all")
+            _schedule.output_to_svg("CONSERVATIVE_BF  " + std::string( _need_to_compress? "needed":"") + " compress");
+        int scheduled = 0;
         for (auto job_it = _queue->begin(); job_it != _queue->end(); )
         {
-            const Job * job = (*job_it)->job;
+            if (_workload->_queue_depth != -1 && scheduled >= _workload->_queue_depth)
+                break;
 
+            const Job * job = (*job_it)->job;
             _schedule.remove_job_if_exists(job);
-//            if (_dump_provisional_schedules)
-//                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
-            Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job, _selector);
-//            if (_dump_provisional_schedules)
-//                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+    //            if (_dump_provisional_schedules)
+    //                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+            //LOG_F(INFO,"DEBUG line 375");
+            Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job, _selector,false);   
+    //            if (_dump_provisional_schedules)
+    //                _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+            if (!alloc.used_machines.is_empty())
+            {
+                scheduled++;
+                if (alloc.started_in_first_slice)
+                {
+                    _decision->add_execute_job(job->id, alloc.used_machines, date);
+                    job_it = _queue->remove_job(job_it);
+                    scheduled--;
+                }
+                else
+                    ++job_it;
+            }
+            else
+                ++job_it;
+        }
+        if (_output_svg == "all")
+            _schedule.output_to_svg("CONSERVATIVE_BF  " + std::string(_need_to_compress? "needed":"") + "compress, DONE");
+        _need_to_compress = false;
+    }
+}
+
+
+
+
+
+
+
+
+
+
+
+void ConservativeBackfilling::handle_killed_jobs(std::vector<std::string> & recently_queued_jobs, double date)
+{
+    auto sort_original_submit = [](const Job * j1,const Job * j2)->bool{
+            if (j1->submission_times[0] == j2->submission_times[0])
+                return j1->id < j2->id;
+            else
+                return j1->submission_times[0] < j2->submission_times[0];
+    };
+    auto sort_original_submit_pair = [](const std::pair<const Job *,batsched_tools::KILL_TYPES> j1,const std::pair<const Job *,batsched_tools::KILL_TYPES> j2)->bool{
+            if (j1.first->submission_times[0] == j2.first->submission_times[0])
+                return j1.first->id < j2.first->id;
+            else
+                return j1.first->submission_times[0] < j2.first->submission_times[0];
+    };
+    //LOG_F(INFO,"killed_jobs %d",_killed_jobs);
+    LOG_F(INFO,"line 385 _resubmitted_jobs.size %d",_resubmitted_jobs.size());
+            std::string resub_jobs_str;
+            for( auto mypair : _resubmitted_jobs)
+            {
+                resub_jobs_str += mypair.first +",";
+            }
+    //        LOG_F(INFO,"line 811 resub_jobs: %s",resub_jobs_str.c_str());
+    LOG_F(INFO,"here");
+    if (_killed_jobs && !_resubmitted_jobs.empty())
+    {
+      //  LOG_F(INFO,"killed_jobs !_jobs_release empty");
+        if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::AFFECTED)
+        {
+            //first we take care of sorting out resubmitted jobs from the
+            //regular submitted jobs, since we will be handling the resubmitted jobs                      
+            std::vector<std::string> recently_queued_jobs2;
+            //go through recently_queued_jobs and get all the resubmitted ones
+            for (std::string job_id : recently_queued_jobs)
+            {
+                //check if it's a resubmitted job
+                if (job_id.find("#") != std::string::npos)
+                {
+
+                   auto forWhat = _resubmitted_jobs.at(job_id);
+                   _resubmitted_jobs.erase(job_id);
+                   _resubmitted_jobs_released.push_back(std::make_pair((*_workload)[job_id],forWhat));
+
+                }
+                else
+                    recently_queued_jobs2.push_back(job_id); // it's a normal job, push it back
+            }
+            //set the recently_queued_jobs to a vector without the resubmitted jobs
+            recently_queued_jobs = recently_queued_jobs2;
+
+            //have all the resubmitted_jobs come back?
+            if (_resubmitted_jobs.empty())
+            {
+                // _resubmitted_jobs_released should now contain all the resubmitted jobs
+                //add the killed_jobs(resubmitted jobs) first
+
+                //first sort all the resubmitted jobs based on their original submit date
+                std::sort(_resubmitted_jobs_released.begin(),_resubmitted_jobs_released.end(),sort_original_submit_pair);
+                //now get all jobs to reschedule that weren't killed
+                std::vector<const Job *> all_jobs_to_reschedule;
+                for(auto reservation : _saved_reservations)
+                {
+                
+                    for (auto job : reservation.jobs_to_reschedule)
+                            all_jobs_to_reschedule.push_back(job);
+                
+                }
+                //now get all the jobs to reschedule that were affected by a machine going down
+                std::map<const Job *,IntervalSet> jobs_affected;
+                _schedule.get_jobs_affected_on_machines(_recently_under_repair_machines,jobs_affected);
+                for(auto job_interval_pair : jobs_affected){
+                    _schedule.remove_job_if_exists(job_interval_pair.first);
+                    all_jobs_to_reschedule.push_back(job_interval_pair.first);
+                }
+                //now sort them based on original_submit_time
+                std::sort(all_jobs_to_reschedule.begin(),all_jobs_to_reschedule.end(),sort_original_submit);
+
+                //now add the kill jobs
+                int queue_size = _queue->nb_jobs();
+                int scheduled = _schedule.nb_jobs_size()-_schedule.get_number_of_running_jobs();
+                for (auto job_forWhat_pair : _resubmitted_jobs_released)
+                {   
+                    if (_workload->_queue_depth != -1 && scheduled >=_workload->_queue_depth)
+                        break;
+                    
+                    Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job_forWhat_pair.first,_selector,false);
+                    if (!alloc.used_machines.is_empty())
+                    {
+                        scheduled++;
+                        if (alloc.started_in_first_slice)
+                        {
+                            _queue->remove_job(job_forWhat_pair.first);
+                            _decision->add_execute_job(job_forWhat_pair.first->id,alloc.used_machines,date);
+                            scheduled--;
+                        }
+                    }
+                }
 
+                //now add them to the schedule
+                for(auto job: all_jobs_to_reschedule)
+                {
+                    if (_workload->_queue_depth != -1 && scheduled >=_workload->_queue_depth)
+                        break;
+                   
+                    Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job,_selector,false);
+                    if (!alloc.used_machines.is_empty())
+                    {
+                        scheduled++;
+                        if (alloc.started_in_first_slice)
+                        {
+                            _queue->remove_job(job);
+                            _decision->add_execute_job(job->id,alloc.used_machines,date);
+                            scheduled--;
+                        }
+                    }
+                }
+
+                //everything should be rescheduled, now add callbacks for each reservation
+                for (auto reservation : _saved_reservations)
+                {
+                    if (reservation.job->start > date)
+                    _decision->add_call_me_later(batsched_tools::call_me_later_types::RESERVATION_START,
+                                                reservation.job->unique_number,
+                                                reservation.job->start,
+                                                date );
+                    else if (reservation.alloc->started_in_first_slice)
+                    {
+                        _reservation_queue->remove_job(reservation.job);
+                        _decision->add_execute_job(reservation.job->id,reservation.alloc->used_machines,date);
+                    }
+                    else
+                        _start_a_reservation = true;
+                        
+                }
+                //make sure to clear the _resubmitted_jobs_released
+                _resubmitted_jobs_released.clear();
+                //we need to compress since things were moved around
+                _need_to_compress = true;
+            }
+            
+            
+        }
+        if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::ALL)
+        {
+        //    LOG_F(INFO,"handle killed jobs sched_policy all");
+            //first we take care of sorting out resubmitted jobs from the
+            //regular submitted jobs, since we will be handling the resubmitted jobs                      
+            std::vector<std::string> recently_queued_jobs2;
+            //go through recently_queued_jobs and get all the resubmitted ones
+            for (std::string job_id : recently_queued_jobs)
+            {
+                //check if it's a resubmitted job
+                if (job_id.find("#") != std::string::npos)
+                {
+                   auto forWhat = _resubmitted_jobs.at(job_id);
+                   _resubmitted_jobs.erase(job_id);
+                   _resubmitted_jobs_released.push_back(std::pair((*_workload)[job_id],forWhat));
+
+                }
+                else
+                    recently_queued_jobs2.push_back(job_id); // it's a normal job, push it back
+            }
+            //set the recently_queued_jobs to a vector without the resubmitted jobs
+            recently_queued_jobs = recently_queued_jobs2;
+          //  LOG_F(INFO,"line 385 _resubmitted_jobs.size %d",_resubmitted_jobs.size());
+            
+            for( auto mypair : _resubmitted_jobs)
+            {
+                resub_jobs_str += mypair.first +",";
+            }
+            //LOG_F(INFO,"line 811 resub_jobs: %s",resub_jobs_str.c_str());
+            //have all the resubmitted_jobs come back?
+            if (_resubmitted_jobs.empty())
+            {
+              //  LOG_F(INFO,"line 389");
+                // _resubmitted_jobs_released should now contain all the resubmitted jobs
+
+                //we have a sorted queue including the resubmitted jobs.   
+                //we should be using the OriginalFCFSOrder on the queue so
+                //the queue should be sorted by original submission time
+                //remove all jobs from the schedule that are in the queue
+                if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF started removing");
+                for (auto job_it = _queue->begin(); job_it != _queue->end();++job_it )
+                {
+                //    LOG_F(INFO,"job: %s ",(*job_it)->job->id.c_str());
+                    //jobs that were affected by the reservation won't be in the schedule
+                    //so we must use the _if_exists version
+                    _schedule.remove_job_if_exists((*job_it)->job);
+                }
+                if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF finished removing, adding them back in");
+                //LOG_F(INFO,"line 402");
+                //so, only the jobs running right now that weren't affected by the reservation
+                //and the reservation itself and other reservations are still in the schedule
+                //now add everything else back to the schedule
+                int scheduled = 0;
+                for (auto job_it = _queue->begin(); job_it != _queue->end(); )
+                {
+                    if (_workload->_queue_depth != -1 && scheduled >= _workload->_queue_depth)
+                        break;
+                    
+                    const Job * job = (*job_it)->job;
+                    Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job, _selector,false);   
+                    if (!alloc.used_machines.is_empty())
+                    {
+                        scheduled++;
             if (alloc.started_in_first_slice)
             {
                 _decision->add_execute_job(job->id, alloc.used_machines, date);
                 job_it = _queue->remove_job(job_it);
+                            scheduled--;
+                        }
+                        else
+                            ++job_it;
             }
             else
                 ++job_it;
         }
+                if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF adding them back in finished");
+                //ok clear recently_queued_jobs since we just went through the entire queue
+                recently_queued_jobs.clear();
+                //everything should be rescheduled, now add callbacks for each reservation
+                for (auto reservation : _saved_reservations)
+                {
+                    if (reservation.job->start > date)
+                    _decision->add_call_me_later(batsched_tools::call_me_later_types::RESERVATION_START,
+                                                reservation.job->unique_number,
+                                                reservation.job->start,
+                                                date );
+                    else if (reservation.alloc->started_in_first_slice)
+                    {
+                        _reservation_queue->remove_job(reservation.job);
+                        _decision->add_execute_job(reservation.job->id,reservation.alloc->used_machines,date);
+                    }
+                    else
+                        _start_a_reservation = true;
+                }
+                //LOG_F(INFO,"line 429");
     }
+        }
+        if (_resubmitted_jobs.empty())
+        {
+            //LOG_F(INFO,"Setting _killed_jobs to false");
+            _saved_reservations.clear();
+            _killed_jobs = false;
+        }
+    } 
+}
 
-    // And now let's see if we can estimate some waiting times
     
-    for (const std::string & job_id : _jobs_whose_waiting_time_estimation_has_been_requested_recently)
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+void ConservativeBackfilling::handle_reservations(std::vector<std::string> & recently_released_reservations, 
+                                                std::vector<std::string> &recently_queued_jobs,
+                                                 double date)
+{
+    auto sort_original_submit = [](const Job * j1,const Job * j2)->bool{
+            if (j1->submission_times[0] == j2->submission_times[0])
+                return j1->id < j2->id;
+            else
+                return j1->submission_times[0] < j2->submission_times[0];
+    };
+    for (const string & new_job_id : recently_released_reservations)
     {
-        const Job * new_job = (*_workload)[job_id];
-        double answer = _schedule.query_wait(new_job->nb_requested_resources, new_job->walltime, _selector);
-            _decision->add_answer_estimate_waiting_time(job_id, answer, date);
+        LOG_F(INFO,"new reservation: %s queue:%s",new_job_id.c_str(),_queue->to_string().c_str());
+        Job * new_job = (*_workload)[new_job_id];
+        LOG_F(INFO,"job %s has walltime %g  start %f and alloc %s",new_job->id.c_str(),(double)new_job->walltime,new_job->start,new_job->future_allocations.to_string_hyphen(" ","-").c_str());
+        //reserve a time slice 
+        LOG_F(INFO,"resched policy %d",_reschedule_policy);
+
+        if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::AFFECTED)
+        {
+            
+            Schedule::ReservedTimeSlice reservation = _schedule.reserve_time_slice(new_job);
+            if (reservation.success == false)
+            {
+                _decision->add_reject_job(new_job_id,date);
+                continue;
     }
+            if (new_job->future_allocations.is_empty() && reservation.success)
+                new_job->future_allocations = reservation.alloc->used_machines;
 
-    if (_dump_provisional_schedules)
-        _schedule.incremental_dump_as_batsim_jobs_file(_dump_prefix);
+            _schedule.add_reservation_for_svg_outline(reservation);
+            
+            if (reservation.success)
+            {
+                //sort the jobs to reschedule;
+                
+                std::sort(reservation.jobs_to_reschedule.begin(), reservation.jobs_to_reschedule.end(),sort_original_submit);
+                
+                //we need to wait on rescheduling if jobs are killed
+                //so check if any jobs need to be killed
+                LOG_F(INFO,"here");
+                if (reservation.jobs_needed_to_be_killed.empty())
+                {//ok no jobs need to be killed, reschedule
+                    
+                    //remove the jobs in order all at once
+                    for(auto job : reservation.jobs_to_reschedule)
+                        _schedule.remove_job(job);
+                    
+                   
+                    Schedule::ReservedTimeSlice reservation2 = _schedule.reserve_time_slice(new_job);
+                    reservation.slice_begin = reservation2.slice_begin;
+                    reservation.slice_end = reservation2.slice_end;
+                    _schedule.add_reservation(reservation);
+                    _schedule.remove_reservation_for_svg_outline(reservation);
+                    Schedule::JobAlloc alloc;
+                    //now add the rescheduled jobs in order
+                    LOG_F(INFO,"here vec");
+                    std::stringstream ss;
+                    bool skip=true;
+                    for(auto job : reservation.jobs_to_reschedule)
+                    { 
+                        if(skip)
+                        { 
+                            ss<<" ";
+                            skip=false;
+                        }
+                        ss<< job->id;
+                    }
+                    LOG_F(INFO,"jobs to reschedule: %s",ss.str().c_str());
+                    for(auto job : reservation.jobs_to_reschedule)
+                    {
+                        alloc = _schedule.add_job_first_fit(job,_selector,false);
+                        //if this job starts in first slice execute it
+                        if (!alloc.used_machines.is_empty())
+                        {
+                            if (alloc.started_in_first_slice)
+                            {
+                                _queue->remove_job(job);
+                                _decision->add_execute_job(job->id,alloc.used_machines,date);
+                            }
+                        }
+                    }
+                   LOG_F(INFO,"here");
+                    //if reservation started in first slice
+                    if (reservation.alloc->started_in_first_slice)
+                    {
+                        _reservation_queue->remove_job(new_job);
+                        _decision->add_execute_job(new_job->id,reservation.alloc->used_machines,date);
+                    }
+                    else if (new_job->start > date)
+                        _decision->add_call_me_later(batsched_tools::call_me_later_types::RESERVATION_START,
+                                                    new_job->unique_number,
+                                                    new_job->start,
+                                                    date);
+                    else
+                        _start_a_reservation = true;
+                    //we need to compress since things moved around
+                    _need_to_compress = true;
+                }
+                else{//ok some jobs do need to be killed
+                    
+                    //make decisions will run a couple times with the same date:
+                    //  right now when job is killed -> when progress comes back and we resubmit -> when notified of resubmit and we reschedule
+                    
+                    //first kill jobs that need to be killed
+                    LOG_F(INFO,"DEBUG line 248");
+                    std::vector<batsched_tools::Job_Message *> msgs;
+                    for(auto job : reservation.jobs_needed_to_be_killed)
+                    {
+                        auto msg = new batsched_tools::Job_Message;
+                        msg->id = job->id;
+                        msg->forWhat = batsched_tools::KILL_TYPES::RESERVATION;
+                        msgs.push_back(msg);
+                    }
+                     
+                    _decision->add_kill_job(msgs,date);//as long as kill jobs happen before an execute job we should be good
+                    LOG_F(INFO,"DEBUG line 253");
+                    //remove kill jobs from schedule
+                    for(auto job : reservation.jobs_needed_to_be_killed)
+                    {
+                        LOG_F(INFO,"DEBUG id %s",job->id.c_str());
+                        _schedule.remove_job(job);
+                    }
+                    LOG_F(INFO,"DEBUG line 257");
+                    //remove jobs to reschedule
+                    for (auto job : reservation.jobs_to_reschedule)
+                        _schedule.remove_job(job);
+                    LOG_F(INFO,"DEBUG line 261");
+                    //we can make the reservation now
+                    Schedule::ReservedTimeSlice reservation2 = _schedule.reserve_time_slice(new_job);
+                    reservation.slice_begin = reservation2.slice_begin;
+                    reservation.slice_end = reservation2.slice_end;
+                    _schedule.add_reservation(reservation);
+                    _schedule.remove_reservation_for_svg_outline(reservation);
+                    //get things ready for once killed_jobs are resubmitted
+                    LOG_F(INFO,"DEBUG line 265");
+                    _saved_reservations.push_back(reservation);
+                    LOG_F(INFO,"line 307");
+                    _killed_jobs = true;
+                    //we need to add the recently_queued_jobs to the schedule eventually
+                    //but not until the killed jobs come back as resubmitted
+                    for (std::string job : recently_queued_jobs)
+                        _saved_recently_queued_jobs.push_back(job);
+                }
+            }
+        }
+        if (_reschedule_policy == Schedule::RESCHEDULE_POLICY::ALL)
+        {
+            Schedule::ReservedTimeSlice reservation = _schedule.reserve_time_slice(new_job);
+            if (reservation.success == false)
+            {
+                _decision->add_reject_job(new_job_id,date);
+                continue;
+            }
+            if (new_job->future_allocations.is_empty() && reservation.success)
+                new_job->future_allocations = reservation.alloc->used_machines;
+            _schedule.add_reservation_for_svg_outline(reservation);
+            if (reservation.success)
+            {
+                // do we need to kill jobs
+                if (reservation.jobs_needed_to_be_killed.empty())
+                {
+                    //we don't need to kill jobs
+                    //remove jobs in the reservation's way
+                    for (auto job : reservation.jobs_to_reschedule)
+                        _schedule.remove_job(job);
+                    //we can make the reservation now
+                    Schedule::ReservedTimeSlice reservation2 = _schedule.reserve_time_slice(new_job);
+                    reservation.slice_begin = reservation2.slice_begin;
+                    reservation.slice_end = reservation2.slice_end;
+                    _schedule.add_reservation(reservation);
+                    _schedule.remove_reservation_for_svg_outline(reservation);
+                    if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF about to remove all jobs in the queue");
+                    //we have a sorted queue including resubmitted jobs.   
+                    //we should be using the OriginalFCFSOrder on the queue so
+                    //the queue should be sorted by original submission time
+                    //remove all jobs from the schedule that are in the queue
+                    for (auto job_it = _queue->begin(); job_it != _queue->end(); ++job_it)
+                    {
+                        //jobs that were affected by the reservation won't be in the schedule
+                        //so we must use the _if_exists version
+                        _schedule.remove_job_if_exists((*job_it)->job);
+                    }
+                    if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF finished removing, adding them back in");
+                    
+                    //so, only the jobs running right now
+                    //and the reservation itself and other reservations are still in the schedule
+                    //now add everything else back to the schedule
+                    int scheduled=0;
+                    for (auto job_it = _queue->begin(); job_it != _queue->end(); )
+                    {
+                        const Job * job = (*job_it)->job;
+                        Schedule::JobAlloc alloc = _schedule.add_job_first_fit(job, _selector,false);   
+                        if (!alloc.used_machines.is_empty())
+                        {
+                            scheduled++;
+                        
+                            if (alloc.started_in_first_slice)
+                            {
+                                _decision->add_execute_job(job->id, alloc.used_machines, date);
+                                job_it = _queue->remove_job(job_it);
+                            }
+                            else
+                                ++job_it;
+                        }
+                        else
+                            ++job_it;
+                    }
+                    if (_output_svg == "all")
+                        _schedule.output_to_svg("CONSERVATIVE_BF finished adding them back in");
+                    //ok clear recently_queued_jobs since we just went through the entire queue
+                    recently_queued_jobs.clear();
+                    //take care of reservation that is in first slice
+                    if (reservation.alloc->started_in_first_slice)
+                    {
+                        _reservation_queue->remove_job(new_job);
+                        _decision->add_execute_job(new_job->id,reservation.alloc->used_machines,date);
+                    }
+                    else if (new_job->start > date)
+                        _decision->add_call_me_later(batsched_tools::call_me_later_types::RESERVATION_START,
+                                                    new_job->unique_number,
+                                                    new_job->start,
+                                                    date);
+                    else
+                        _start_a_reservation = true;
+
+                }
+                else
+                {
+                    //ok we need to kill jobs
+                    //first kill jobs
+                    LOG_F(INFO,"DEBUG line 248");
+                    std::vector<batsched_tools::Job_Message *> msgs;
+                    for(auto job : reservation.jobs_needed_to_be_killed)
+                    {
+                        auto msg = new batsched_tools::Job_Message;
+                        msg->id = job->id;
+                        msg->forWhat = batsched_tools::KILL_TYPES::RESERVATION;
+                        msgs.push_back(msg);
+                    }
+                     
+                    _decision->add_kill_job(msgs,date);//as long as kill jobs happen before an execute job we should be good
+                    LOG_F(INFO,"DEBUG line 253");
+                    //make room for the reservation first
+                    //remove kill jobs from schedule
+                    for(auto job : reservation.jobs_needed_to_be_killed)
+                    {
+                        LOG_F(INFO,"DEBUG id %s",job->id.c_str());
+                        _schedule.remove_job(job);
+                    }
+                    LOG_F(INFO,"DEBUG line 257");
+                    //remove jobs to reschedule
+                    for (auto job : reservation.jobs_to_reschedule)
+                        _schedule.remove_job(job);
+                    LOG_F(INFO,"DEBUG line 261");
+                    //we can make the reservation now
+                    Schedule::ReservedTimeSlice reservation2 = _schedule.reserve_time_slice(new_job);
+                    reservation.slice_begin = reservation2.slice_begin;
+                    reservation.slice_end = reservation2.slice_end;
+                    _schedule.add_reservation(reservation);
+                    _schedule.remove_reservation_for_svg_outline(reservation);
+                    //we need this for issuing the callbacks
+                    _saved_reservations.push_back(reservation);
+                    LOG_F(INFO,"line 307");
+                    //we need to signal we are in a killed_jobs event so keep
+                    _killed_jobs = true;
+                    //we don't need to save the recently_queued_jobs
+                    //since once we get the killed jobs resubmitted we are adding in all of the jobs back into the queue
+                    //for (std::string job : recently_queued_jobs)
+                    //    _saved_recently_queued_jobs.push_back(job);
+                    
+                }
+                    
+                
+            }
+        }
+              
+    }
+    recently_released_reservations.clear();
+    
+    if (_start_a_reservation)
+    {
+        Schedule::JobAlloc alloc;
+        std::vector<const Job *> jobs_removed;
+        LOG_F(INFO,"line 322");
+        if(_schedule.remove_reservations_if_ready(jobs_removed))
+        {
+            LOG_F(INFO,"DEBUG line 323");
+                for(const Job * job : jobs_removed)
+                {
+                    LOG_F(INFO,"DEBUG line 326");
+                    alloc = _schedule.add_current_reservation(job,_selector);
+                    LOG_F(INFO,"DEBUG line 328");
+                    _reservation_queue->remove_job(job);
+                    _decision->add_execute_job(alloc.job->id,alloc.used_machines,date);
+                    
+                }
+            //only set this to false if we  remove and execute some reservations
+            //keep true in case it comes back around after a job completes
+            _start_a_reservation = false;
+        }
+        
+    }
 }
+
diff -burN '--exclude=.git*' ./batsched/src/algo/conservative_bf.hpp ./new_batsched/src/algo/conservative_bf.hpp
--- ./batsched/src/algo/conservative_bf.hpp	2023-07-01 09:20:31.850842135 -0400
+++ ./new_batsched/src/algo/conservative_bf.hpp	2023-06-28 08:26:02.133833308 -0400
@@ -3,27 +3,81 @@
 #include <list>
 
 #include "../isalgorithm.hpp"
+#include "../external/pointers.hpp"
 #include "../json_workload.hpp"
 #include "../locality.hpp"
 #include "../schedule.hpp"
+#include "../batsched_tools.hpp"
+#include "../machine.hpp"
+#include <random>
 
 class ConservativeBackfilling : public ISchedulingAlgorithm
 {
 public:
+    //ConservativeBackfilling(Workload * workload, SchedulingDecision * decision, Queue * queue, ResourceSelector * selector,
+    //                      double rjms_delay, std::string svg_prefix,rapidjson::Document * variant_options);
     ConservativeBackfilling(Workload * workload, SchedulingDecision * decision, Queue * queue, ResourceSelector * selector,
                             double rjms_delay, rapidjson::Document * variant_options);
     virtual ~ConservativeBackfilling();
 
-    virtual void on_simulation_start(double date, const rapidjson::Value & batsim_config);
+    virtual void on_simulation_start(double date, const rapidjson::Value & batsim_event);
 
     virtual void on_simulation_end(double date);
+    void on_machine_instant_down_up(batsched_tools::KILL_TYPES forWhat,double date);
+    void on_machine_down_for_repair(batsched_tools::KILL_TYPES forWhat,double date);
+    virtual void set_workloads(myBatsched::Workloads * w);
+    virtual void set_machines(Machines *m);
+    virtual void on_requested_call(double date,int id,  batsched_tools::call_me_later_types forWhat);
 
     virtual void make_decisions(double date,
                                 SortableJobOrder::UpdateInformation * update_info,
                                 SortableJobOrder::CompareInformation * compare_info);
 
 private:
+    void handle_killed_jobs(std::vector<std::string> & recently_queued_jobs,double date);
+    void handle_reservations(std::vector<std::string> & recently_released_reservations,
+                            std::vector<std::string>& recently_queued_jobs,
+                            double date);
+    void handle_schedule(std::vector<std::string>& recently_queued_jobs,double date);
+    
     Schedule _schedule;
+    Queue * _reservation_queue=nullptr;
+    std::string _output_folder;
+    std::string _output_svg;
+    long _svg_frame_start;
+    long _svg_frame_end;
+    long _svg_output_start;
+    long _svg_output_end;
+    Schedule::RESCHEDULE_POLICY _reschedule_policy;
+    Schedule::IMPACT_POLICY _impact_policy;
+    double _previous_date;
+    std::vector<Schedule::ReservedTimeSlice> _saved_reservations;
+    bool _killed_jobs = false;
+    bool _need_to_send_finished_submitting_jobs = true;
+    std::vector<std::string> _saved_recently_queued_jobs;
+    std::vector<std::string> _saved_recently_ended_jobs;
+    IntervalSet _recently_under_repair_machines;
+    bool _need_to_compress = false;
+    
     bool _dump_provisional_schedules = false;
     std::string _dump_prefix = "/tmp/dump";
+    myBatsched::Workloads * _myWorkloads;
+    bool _checkpointing_on;
+    bool _start_a_reservation=false;
+    b_log *_myBLOG;
+    std::map<std::string,batsched_tools::KILL_TYPES>_resubmitted_jobs;
+    std::vector<std::pair<const Job *,batsched_tools::KILL_TYPES>>_resubmitted_jobs_released;
+    
+
+
+    std::mt19937 generator;
+    std::exponential_distribution<double> * distribution;
+    std::mt19937 generator2;
+    std::uniform_int_distribution<int> * unif_distribution;
+    std::vector<batsched_tools::KILL_TYPES> _on_machine_instant_down_ups;
+    std::vector<batsched_tools::KILL_TYPES> _on_machine_down_for_repairs;
+
+   
+    
+
 };
diff -burN '--exclude=.git*' ./batsched/src/algo/easy_bf_fast2.cpp ./new_batsched/src/algo/easy_bf_fast2.cpp
--- ./batsched/src/algo/easy_bf_fast2.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/easy_bf_fast2.cpp	2023-06-28 08:26:02.130499916 -0400
@@ -0,0 +1,1433 @@
+#include <math.h>
+#include "easy_bf_fast2.hpp"
+
+#include "../pempek_assert.hpp"
+
+#include <loguru.hpp>
+#include "../external/batsched_workload.hpp"
+#include "../external/batsched_job.hpp"
+#include "../external/batsched_profile.hpp"
+#include "../external/pointers.hpp"
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <chrono>
+#include "../batsched_tools.hpp"
+
+
+#define B_LOG_INSTANCE _myBLOG
+namespace myB = myBatsched;
+namespace r = rapidjson;
+const int DEBUG = 10;
+
+easy_bf_fast2::easy_bf_fast2(Workload *workload,
+    SchedulingDecision *decision, Queue *queue, ResourceSelector *selector,
+    double rjms_delay, rapidjson::Document *variant_options) :
+    ISchedulingAlgorithm(workload, decision, queue, selector, rjms_delay,
+        variant_options)
+{
+    
+    _myWorkloads = new myBatsched::Workloads;
+    //batsim log object.  declared in batsched_tools.hpp
+    _myBLOG = new b_log();
+    
+    
+}
+
+easy_bf_fast2::~easy_bf_fast2()
+{
+    
+}
+
+void easy_bf_fast2::on_simulation_start(double date,
+    const rapidjson::Value &batsim_event_data)
+{
+    bool seedFailures = false;
+    bool logBLog = false;
+    const rapidjson::Value & batsim_config = batsim_event_data["config"];
+    if (batsim_config.HasMember("share-packing"))
+        _share_packing = batsim_config["share-packing"].GetBool();
+
+    if (batsim_config.HasMember("core-percent"))
+        _core_percent = batsim_config["core-percent"].GetDouble();
+
+    if (batsim_config.HasMember("output-folder")){
+        _output_folder = batsim_config["output-folder"].GetString();
+        _output_folder=_output_folder.substr(0,_output_folder.find_last_of("/"));
+    }
+    
+    if (batsim_config.HasMember("seed-failures"))
+        seedFailures = batsim_config["seed-failures"].GetBool();
+    if (batsim_config.HasMember("log_b_log"))
+        logBLog = batsim_config["log_b_log"].GetBool();
+    //log BLogs, add log files that you want logged to.
+    if (logBLog){
+        _myBLOG->add_log_file(_output_folder+"/log/failures.log",b_log::FAILURES);
+    }
+    unsigned seed = 0;
+    if (seedFailures)
+        seed = std::chrono::system_clock::now().time_since_epoch().count();
+         
+    generator.seed(seed);
+    generator2.seed(seed);
+    _available_machines.insert(IntervalSet::ClosedInterval(0, _nb_machines - 1));
+    _nb_available_machines = _nb_machines;
+    //LOG_F(INFO,"avail: %d   nb_machines: %d",_available_machines.size(),_nb_machines);
+    PPK_ASSERT_ERROR(_available_machines.size() == (unsigned int) _nb_machines);
+    const rapidjson::Value& resources = batsim_event_data["compute_resources"];
+    for ( auto & itr : resources.GetArray())
+    {
+	machine* a_machine = new machine();
+        if (itr.HasMember("id"))
+            a_machine->id = (itr)["id"].GetInt();
+        if (itr.HasMember("core_count"))
+        {
+            a_machine->core_count = (itr)["core_count"].GetInt();
+            a_machine->cores_available = int(a_machine->core_count * _core_percent);
+        }
+        if (itr.HasMember("speed"))
+            a_machine->speed = (itr)["speed"].GetDouble();
+        if (itr.HasMember("name"))
+            a_machine->name = (itr)["name"].GetString();
+        machines_by_int[a_machine->id] = a_machine;
+        machines_by_name[a_machine->name] = a_machine;
+        //LOG_F(INFO,"machine id = %d, core_count= %d , cores_available= %d",a_machine->id,a_machine->core_count,a_machine->cores_available);
+   }
+     _oldDate=date;
+     if (_myWorkloads->_fixed_failures != -1.0)
+     {
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        double number = _myWorkloads->_fixed_failures;
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);  
+     }
+    if (_myWorkloads->_SMTBF != -1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_SMTBF);
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_SMTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+    }
+    else if (_myWorkloads->_MTBF!=-1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_MTBF);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_MTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+    }
+}      
+void easy_bf_fast2::on_simulation_end(double date){
+    (void) date;
+}
+    
+ /*void easy_bf_fast2::on_machine_unavailable_notify_event(double date, IntervalSet machines){
+    //LOG_F(INFO,"unavailable %s",machines.to_string_hyphen().c_str());
+    _unavailable_machines+=machines;
+    _available_machines-=machines;
+    for(auto key_value : _current_allocations)
+    {
+            if (!((key_value.second.machines & machines).is_empty()))
+                _decision->add_kill_job({key_value.first},date);
+    }
+    
+}
+*/
+void easy_bf_fast2::set_workloads(myBatsched::Workloads *w){
+    _myWorkloads = w;
+    _checkpointing_on = w->_checkpointing_on;
+    
+}
+void easy_bf_fast2::on_machine_available_notify_event(double date, IntervalSet machines){
+    ISchedulingAlgorithm::on_machine_available_notify_event(date, machines);
+    _unavailable_machines-=machines;
+    _available_machines+=machines;
+    _nb_available_machines+=machines.size();
+    
+}
+
+void easy_bf_fast2::on_machine_state_changed(double date, IntervalSet machines, int new_state)
+{
+   
+
+}
+void easy_bf_fast2::on_myKillJob_notify_event(double date){
+    
+    if (!_running_jobs.empty()){
+       auto msg = new batsched_tools::Job_Message;
+        msg->id = *_running_jobs.begin();
+        msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+        _my_kill_jobs.insert(std::make_pair((*_workload)[*_running_jobs.begin()],msg));
+    }
+        
+    
+}
+
+
+
+void easy_bf_fast2::on_machine_down_for_repair(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    //if the machine is already down for repairs ignore it.
+    //LOG_F(INFO,"repair_machines.size(): %d    nb_avail: %d  avail:%d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+    BLOG_F(b_log::FAILURES,"Machine Repair: %d",number);
+    if ((machine & _repair_machines).is_empty())
+    {
+        //ok the machine is not down for repairs
+        //it will be going down for repairs now
+        _available_machines-=machine;
+        _unavailable_machines+=machine;
+        _repair_machines+=machine;
+        _nb_available_machines=_available_machines.size();
+
+        double repair_time = _myWorkloads->_repair_time;
+        //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d  avail: %d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+        //LOG_F(INFO,"date: %f , repair: %f ,repair + date: %f",date,repair_time,date+repair_time);
+        //call me back when the repair is done
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::REPAIR_DONE,number,date+repair_time,date);
+        //now kill the jobs that are running on machines that need to be repaired.        
+        //if there are no running jobs, then there are none to kill
+        if (!_running_jobs.empty()){
+            for(auto key_value : _current_allocations)
+            {
+                if (!((key_value.second.machines & machine).is_empty())){
+                    Job * job_ref = (*_workload)[key_value.first];
+                    auto msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+                   
+                    BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+                }
+            }
+        }
+    }
+    else
+    {
+        BLOG_F(b_log::FAILURES,"Machine Already Being Repaired: %d",number);
+    }
+}
+
+
+void easy_bf_fast2::on_machine_instant_down_up(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    BLOG_F(b_log::FAILURES,"Machine Instant Down Up: %d",number);
+    //if there are no running jobs, then there are none to kill
+    if (!_running_jobs.empty()){
+        for(auto key_value : _current_allocations)   
+	    {
+		    if (!((key_value.second.machines & machine).is_empty())){
+                     Job * job_ref = (*_workload)[key_value.first];
+                    auto msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+                	
+	                BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+            }
+	    }
+    }
+}
+/*void easy_bf_fast2::on_job_fault_notify_event(double date, std::string job){
+    std::unordered_set<std::string>::const_iterator found = _running_jobs.find(job);
+  //LOG_F(INFO,"on_job_fault_notify_event called");
+  if ( found != _running_jobs.end() )    
+        _decision->add_kill_job({job},date);
+  else
+      LOG_F(INFO,"Job %s was not running but was supposed to be killed due to job_fault event",job.c_str());
+}
+*/
+
+void easy_bf_fast2::on_requested_call(double date,int id,batsched_tools::call_me_later_types forWhat)
+{
+    
+        switch (forWhat){
+            case batsched_tools::call_me_later_types::SMTBF:
+                        {
+                            //Log the failure
+                            BLOG_F(b_log::FAILURES,"FAILURE SMTBF");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = distribution->operator()(generator);
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::MTBF:
+                        {
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                            {
+                                double number = distribution->operator()(generator);
+                                on_myKillJob_notify_event(date);
+                                _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+
+                            }
+                        
+                            
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::FIXED_FAILURE:
+                        {
+                            BLOG_F(b_log::FAILURES,"FAILURE FIXED_FAILURE");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = _myWorkloads->_fixed_failures;
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::REPAIR_DONE:
+                        {
+                            BLOG_F(b_log::FAILURES,"REPAIR_DONE");
+                            //a repair is done, all that needs to happen is add the machines to available
+                            //and remove them from repair machines and add one to the number of available
+                            IntervalSet machine = id;
+                            _available_machines += machine;
+                            _unavailable_machines -= machine;
+                            _repair_machines -= machine;
+                            _nb_available_machines=_available_machines.size();
+                            _machines_that_became_available_recently += machine;
+                           //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d avail: %d  running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+                        }
+                        break;
+        }
+    
+
+}
+void easy_bf_fast2::on_no_more_static_job_to_submit_received(double date){
+    ISchedulingAlgorithm::on_no_more_static_job_to_submit_received(date);
+
+}
+void easy_bf_fast2::on_no_more_external_event_to_occur(double date){
+    
+    _wrap_it_up = true;    
+    
+    
+}
+void easy_bf_fast2::on_job_end(double date, std::vector<std::string> job_ids)
+{
+    (void) date;
+    (void) job_ids;
+}
+
+
+
+
+
+/*********************************************************
+ *                                                       *
+ *                    Make Decisions                     *
+ *                                                       *
+**********************************************************/
+
+
+
+void easy_bf_fast2::make_decisions(double date,
+    SortableJobOrder::UpdateInformation *update_info,
+    SortableJobOrder::CompareInformation *compare_info)
+{
+   ////LOG_F(INFO,"line 322   fcfs_fast2.cpp");
+    (void) update_info;
+    (void) compare_info;
+    std::vector<int> mapping = {0};
+    if (_oldDate == -1)
+        _oldDate=date;
+    // This algorithm is a fast version of FCFS without backfilling.
+    // It is meant to be fast in the usual case, not to handle corner cases.
+    // It is not meant to be easily readable or hackable ;).
+
+    // This fast FCFS variant in a few words:
+    // - only handles the FCFS queue order
+    // - only handles the basic resource selection policy
+    // - only handles finite jobs (no switchoff)
+    // - only handles time as floating-point (-> precision errors).
+
+    
+
+    ////LOG_F(INFO,"line 340  fcfs_fast2.cpp");
+    //*****************************************************************
+    // Handle newly finished jobs
+    //*****************************************************************
+    LOG_F(INFO,"line 353");
+    bool job_ended = handle_newly_finished_jobs();
+    LOG_F(INFO,"line 355");    
+    handle_new_jobs_to_kill(date);
+    //************************************************************resubmission if killed
+    //Handle jobs to queue back up (if killed)
+    LOG_F(INFO,"line 359");
+    handle_resubmission(date);    
+    //***********************************************************
+    LOG_F(INFO,"line 362");
+    handle_machines_coming_available(date);
+    LOG_F(INFO,"line 364");
+    handle_ended_job_execution(job_ended,date);
+    LOG_F(INFO,"line 366");
+    handle_newly_released_jobs(date);
+    LOG_F(INFO,"line 368");
+    
+    /*if (_jobs_killed_recently.empty() && _wrap_it_up && _need_to_send_finished_submitting_jobs && !_myWorkloads->_checkpointing_on)
+    {
+        
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+    */
+   LOG_F(INFO,"_e_counter %d _p_counter %d",_e_counter,_p_counter);
+    if (_jobs_killed_recently.empty() && _pending_jobs.empty() && _running_jobs.empty() &&
+             _need_to_send_finished_submitting_jobs && _no_more_static_job_to_submit_received && !date<1.0 )
+    {
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+      
+}
+
+
+
+
+std::string easy_bf_fast2::to_json_desc(rapidjson::Document * doc)
+{
+  rapidjson::StringBuffer buffer;
+
+  buffer.Clear();
+
+  rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+  doc->Accept(writer);
+
+  return std::string( buffer.GetString() );
+}
+
+
+/**********************************************
+ * 
+ *          Newly Finished Jobs
+ * 
+ ***********************************************/
+
+bool easy_bf_fast2::handle_newly_finished_jobs()
+{
+   //LOG_F(INFO,"line 410");
+   std::vector<int> mapping = {0};
+    bool job_ended = false;
+    for (const std::string & ended_job_id : _jobs_ended_recently)
+    {
+        job_ended = true;
+        Job * finished_job = (*_workload)[ended_job_id];
+        const Allocation & alloc = _current_allocations[ended_job_id];
+        if (_share_packing && finished_job->nb_requested_resources == 1)
+        {
+                //first get the machine it was running on
+                int machine_number = alloc.machines[0];
+                machine* current_machine = machines_by_int[machine_number];
+
+                //now increase cores_available on that machine
+                current_machine->cores_available += 1;
+                //if that increase means no jobs are running on that machine (all its cores are available) then put it back in the mix
+                if (current_machine->cores_available == int(current_machine->core_count * _core_percent))
+                {
+                    _available_core_machines -= alloc.machines;  // we subtract a core machine because it is now a regular machine
+                    _available_machines.insert(alloc.machines); // we insert the machine into available machines
+                    _nb_available_machines += 1; // we increase available machines by 1
+                }
+                _current_allocations.erase(ended_job_id);
+                _horizons.erase(alloc.horizon_it);
+                _running_jobs.erase(ended_job_id);
+        }
+            // was not a 1 resource job, do things normally
+        else{
+                _available_machines.insert(alloc.machines);
+                _nb_available_machines += finished_job->nb_requested_resources;
+                _current_allocations.erase(ended_job_id);
+                _running_jobs.erase(ended_job_id);
+                _my_kill_jobs.erase((*_workload)[ended_job_id]);
+                _horizons.erase(alloc.horizon_it);
+        }
+    }
+
+    LOG_F(INFO,"_nb_available_machines %d",_nb_available_machines);
+    return job_ended;
+}
+
+/**********************************************
+ * 
+ *          New Jobs To Kill
+ * 
+ ***********************************************/
+
+
+void easy_bf_fast2::handle_new_jobs_to_kill(double date)
+{
+     if(!_my_kill_jobs.empty()){
+        std::vector<batsched_tools::Job_Message *> kills;
+        for( auto job_msg_pair:_my_kill_jobs)
+        {
+            kills.push_back(job_msg_pair.second);
+        }
+        _decision->add_kill_job(kills,date);
+        _my_kill_jobs.clear();
+    }
+}
+
+/**********************************************
+ * 
+ *          Machines Coming Available TODO
+ * 
+ ***********************************************/
+
+void easy_bf_fast2::handle_machines_coming_available(double date)
+{
+    
+    
+}
+
+/**********************************************
+ * 
+ *          Ended Job Execution
+ * 
+ ***********************************************/
+
+
+
+void easy_bf_fast2::handle_ended_job_execution(bool job_ended,double date)
+{
+    std::vector<int> mapping = {0};
+    // If jobs have finished, execute jobs as long as they fit
+    std::list<Job *>::iterator job_it =_pending_jobs.begin();
+    if (job_ended)
+    {
+        if (_priority_job == nullptr)
+            LOG_F(INFO,"line 499 nullptr");
+        if (_priority_job != nullptr)
+        {
+            LOG_F(INFO,"pending_jobs %d _nb_available_machines %d",_pending_jobs.size(),_nb_available_machines);
+            //first check if priority job fits
+            //it fits if it's a 1 resource job and share_packing is enabled and
+            //we either find an _available_core_machine or
+            //we find a free machine to make an _available_core_machine
+            //or
+            //it fits if share_packing is disabled, or it's greater than a 1 resource job
+            //and
+            //there are enough machines available for the priority job's nb_requested_resources
+            Allocation alloc;
+            FinishedHorizonPoint point;
+            bool executed = false;
+            if (_share_packing && _priority_job->nb_requested_resources == 1)
+            {
+                //ok the job can be share-packed:
+                bool found = false;
+                //first check if there is a share-packing machine available:
+                //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                {
+                    //is this machine able to handle another job?
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {                                
+                        //it is able to handle another job
+                        found = true;
+                        alloc.machines = *it;
+                        break;
+                    }
+                                 
+                }
+                //LOG_F(INFO,"line 529");
+                if (found == true)
+                {
+                    //yes it can be executed right away
+                    _decision->add_execute_job(_priority_job->id,alloc.machines,date,mapping);
+                    _e_counter+=1;
+                    executed = true;
+                    //update data structures
+                    machine* current_machine = machines_by_int[alloc.machines[0]];
+                    point.nb_released_machines = _priority_job->nb_requested_resources;
+                    point.date = date + (double)_priority_job->walltime;
+                    point.machines = alloc.machines;
+                    alloc.horizon_it = insert_horizon_point(point);
+
+                    
+                    current_machine->cores_available -=1;
+                    _current_allocations[_priority_job->id] = alloc;
+                    _running_jobs.insert(_priority_job->id);
+
+                    _priority_job = nullptr;    
+                    
+                }
+                if (found == false && _nb_available_machines > 0)
+                {
+                    
+                    //first get a machine
+                    alloc.machines = _available_machines.left(1);
+                   
+                    _decision->add_execute_job(_priority_job->id,alloc.machines,date,mapping);
+                    _e_counter+=1;
+                    executed = true;
+                    
+                    point.nb_released_machines = _priority_job->nb_requested_resources;
+                    point.date = date + (double)_priority_job->walltime;
+                    point.machines = alloc.machines;
+                    alloc.horizon_it = insert_horizon_point(point);
+
+                    //update data structures
+                    machine* current_machine = machines_by_int[alloc.machines[0]];
+                    current_machine->cores_available -= 1;
+                    _available_core_machines += alloc.machines;
+                    _available_machines -= alloc.machines;
+                    _nb_available_machines -= 1;
+                  
+                    _current_allocations[_priority_job->id] = alloc;
+                   
+                    _running_jobs.insert(_priority_job->id);
+                    _priority_job = nullptr;
+                   
+                }
+            }
+            //ok not share-packing or resources > 1
+            else if (_priority_job->nb_requested_resources <= _nb_available_machines)
+            {
+                //LOG_F(INFO, "Priority job fits!");
+                alloc.machines = _available_machines.left(
+                    _priority_job->nb_requested_resources);
+                _decision->add_execute_job(_priority_job->id, alloc.machines,
+                    date);
+                executed = true;
+                _e_counter+=1;
+                point.nb_released_machines = _priority_job->nb_requested_resources;
+                point.date = date + (double)_priority_job->walltime;
+                point.machines = alloc.machines;
+                alloc.horizon_it = insert_horizon_point(point);
+
+                // Update data structures
+                _available_machines -= alloc.machines;
+                _nb_available_machines -= _priority_job->nb_requested_resources;
+                _current_allocations[_priority_job->id] = alloc;
+                _priority_job = nullptr;
+            }
+            //LOG_F(INFO,"line 597");
+            //ok priority job got to run, now execute the whole queue until a priority job cannot fit  
+            if (executed)
+            {
+                std::list<Job *>::iterator job_it =_pending_jobs.begin();
+                bool erased = false;
+                bool executed2;
+                while(job_it!=_pending_jobs.end())
+                {
+                    Job * pending_job = *job_it;
+                    Allocation alloc;
+                    executed2 = false;
+            
+                    std::string pending_job_id = pending_job->id;
+                
+                    if (_share_packing && pending_job->nb_requested_resources==1)
+                    {
+                    LOG_F(INFO,"line 611");
+                        bool found = false;
+                        //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                        for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                        {
+                            //is this machine able to handle another job?
+                            machine* current_machine = machines_by_int[*it];
+                            if (current_machine->cores_available >= 1)
+                            {                                
+                                //it is able to handle another job, execute a job on it and subtract from cores_available
+                                alloc.machines = *it;
+                                
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                executed2 = true;
+                                _e_counter+=1;
+                                point.nb_released_machines = pending_job->nb_requested_resources;
+                                point.date = date + (double)pending_job->walltime;
+                                point.machines = alloc.machines;
+                                alloc.horizon_it = insert_horizon_point(point);
+                                
+                                //update data structures
+                                current_machine->cores_available -=1;
+                                _current_allocations[pending_job_id] = alloc;
+                                _running_jobs.insert(pending_job_id);
+                                job_it = _pending_jobs.erase(job_it);
+                                _p_counter+=1;
+                                erased = true;
+                                found = true;
+                                    
+                            }
+                            if (found == true)
+                                break; 
+                        }  
+                        // there were no available core machines to put it on, try to put on a new core machine
+                        if (found == false && _nb_available_machines > 0)
+                        {
+                    
+                        //LOG_F(INFO,"line 645");
+                            //first get a machine
+                            alloc.machines = _available_machines.left(1);
+                        
+                            _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                            executed2 = true;
+                            _e_counter+=1;
+                            point.nb_released_machines = pending_job->nb_requested_resources;
+                            point.date = date + (double)pending_job->walltime;
+                            point.machines = alloc.machines;
+                            alloc.horizon_it = insert_horizon_point(point);
+                            //update data structures
+                            machine* current_machine = machines_by_int[alloc.machines[0]];
+                            current_machine->cores_available -= 1;
+                            _available_core_machines += alloc.machines;
+                            _available_machines -= alloc.machines;
+                            _nb_available_machines -= 1;
+                        
+                            _current_allocations[pending_job_id] = alloc;
+                        
+                            _running_jobs.insert(pending_job_id);
+                            
+                            job_it = _pending_jobs.erase(job_it);
+                            _p_counter+=1;
+                            erased = true;
+                        }
+                            
+
+                    } // end of pending jobs share-packing block
+                
+                    else if (pending_job->nb_requested_resources <= _nb_available_machines)
+                    {
+                    
+                        alloc.machines = _available_machines.left(
+                            pending_job->nb_requested_resources);
+                        _decision->add_execute_job(pending_job->id,
+                            alloc.machines, date);
+                        executed2 = true;
+                        _e_counter+=1;
+                        point.nb_released_machines = pending_job->nb_requested_resources;
+                        point.date = date + (double)pending_job->walltime;
+                        point.machines = alloc.machines;
+                        alloc.horizon_it = insert_horizon_point(point);
+                        //LOG_F(INFO,"line 683");
+
+                        // Update data structures
+                        _available_machines -= alloc.machines;
+                        _nb_available_machines -= pending_job->nb_requested_resources;
+                        _current_allocations[pending_job_id] = alloc;
+                        job_it = _pending_jobs.erase(job_it);
+                        _p_counter+=1;
+                        erased = true;
+                        _running_jobs.insert(pending_job->id);
+                    
+                    }
+                    if (executed2==false)
+                    {
+                        //ok we have a priority job, now stop traversing pending jobs
+                        _priority_job = pending_job;
+                        _priority_job->completion_time = compute_priority_job_expected_earliest_starting_time();
+                        LOG_F(INFO,"line 699");
+                        
+                        job_it = _pending_jobs.erase(job_it);
+                        _p_counter+=1;
+                        //LOG_F(INFO,"line 701");
+                        // Stop first queue traversal.
+                        break;
+                    }
+                    if (!erased)
+                        job_it++;
+                    else
+                        erased = false;
+                }
+            }
+            //now let's backfill jobs that don't hinder priority job
+           bool erased = false;
+           job_it =_pending_jobs.begin();
+            while(job_it!=_pending_jobs.end())
+            {
+                bool execute = false;
+                Job * pending_job = *job_it;
+                Allocation alloc;
+           //LOG_F(INFO,"line 715");
+                std::string pending_job_id = pending_job->id;
+            
+                if (_share_packing && pending_job->nb_requested_resources==1)
+                {
+                   
+                    LOG_F(INFO,"line 721");
+                    bool found = false;
+                    //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                    for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                    {
+                        //is this machine able to handle another job?
+                        machine* current_machine = machines_by_int[*it];
+                        //LOG_F(INFO,"line 728");
+                        if (current_machine->cores_available >= 1)
+                        {                                
+                            found = true;
+                            //LOG_F(INFO,"line 731");
+                            if (date + pending_job->walltime <= _priority_job->completion_time)
+                            {
+                                //it is able to handle another job, execute a job on it and subtract from cores_available
+                                alloc.machines = *it;
+                                
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                execute = true;
+                                _e_counter+=1;
+                                point.nb_released_machines = pending_job->nb_requested_resources;
+                                point.date = date + (double)pending_job->walltime;
+                                point.machines = alloc.machines;
+                                alloc.horizon_it = insert_horizon_point(point);
+                                //LOG_F(INFO,"line 744");
+                                //update data structures
+                                current_machine->cores_available -=1;
+                                _current_allocations[pending_job_id] = alloc;
+                                _running_jobs.insert(pending_job_id);
+                                job_it = _pending_jobs.erase(job_it);
+                                _p_counter+=1;
+                                erased = true;
+                                
+                                
+                            }
+                            else
+                                LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                 date,pending_job->walltime,_priority_job->completion_time);
+                        }
+                        if (found == true)
+                            break; 
+                    }  
+                    // there were no available core machines to put it on, try to put on a new core machine
+                    if (found == false && _nb_available_machines > 0)
+                    {
+                        LOG_F(INFO,"line 760");
+                        if (date + pending_job->walltime <= _priority_job->completion_time)
+                        {
+                            //first get a machine
+                            alloc.machines = _available_machines.left(1);
+                        
+                            _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                            _e_counter+=1;
+                            execute=true;
+                            point.nb_released_machines = pending_job->nb_requested_resources;
+                            point.date = date + (double)pending_job->walltime;
+                            point.machines = alloc.machines;
+                            alloc.horizon_it = insert_horizon_point(point);
+                            //update data structures
+                            machine* current_machine = machines_by_int[alloc.machines[0]];
+                            current_machine->cores_available -= 1;
+                            _available_core_machines += alloc.machines;
+                            _available_machines -= alloc.machines;
+                            _nb_available_machines -= 1;
+                        //LOG_F(INFO,"line 778");
+                            _current_allocations[pending_job_id] = alloc;
+                        
+                            _running_jobs.insert(pending_job_id);
+                            
+                            job_it = _pending_jobs.erase(job_it);
+                            _p_counter+=1;
+                            erased = true;
+                        }
+                        else
+                            LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                 date,pending_job->walltime,_priority_job->completion_time);
+                    }
+                } // end of backfilling jobs share-packing block
+                else if (pending_job->nb_requested_resources <= _nb_available_machines &&
+                        date + pending_job->walltime <= _priority_job->completion_time)
+                {
+                    // Yes, it can be backfilled!
+                    //LOG_F(INFO,"line 791");
+                    alloc.machines = _available_machines.left(
+                        pending_job->nb_requested_resources);
+                    _decision->add_execute_job(pending_job->id,
+                        alloc.machines, date);
+                    _e_counter+=1;
+                    execute = true;
+                    point.nb_released_machines = pending_job->nb_requested_resources;
+                    point.date = date + (double)pending_job->walltime;
+                    point.machines = alloc.machines;
+                    //LOG_F(INFO,"line 804");
+                    alloc.horizon_it = insert_horizon_point(point);
+                    //LOG_F(INFO,"line 806");
+                    // Update data structures
+                    _available_machines -= alloc.machines;
+                    _nb_available_machines -= pending_job->nb_requested_resources;
+                    _current_allocations[pending_job->id] = alloc;
+                    //LOG_F(INFO,"line 811");
+                    _running_jobs.insert(pending_job_id);
+                    job_it = _pending_jobs.erase(job_it);
+                    _p_counter+=1;
+                    //LOG_F(INFO,"line 814");
+                    erased = true;
+                }
+                else{
+                    LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                 date,pending_job->walltime,_priority_job->completion_time);
+                }
+                if (erased==false)
+                    job_it++;
+                else
+                   erased = false;
+            }
+        }
+    }
+}
+
+/*************************************************
+ * 
+ *              Newly Released Jobs
+ * 
+ **************************************************/
+
+void easy_bf_fast2::handle_newly_released_jobs(double date)
+{
+    int counter = 0;
+    int pending = 0;
+    std::vector<int> mapping = {0};
+    // Handle newly released jobs
+    for (const std::string & new_job_id : _jobs_released_recently)
+    {
+        Job * new_job = (*_workload)[new_job_id];
+
+        // Is this job valid?
+        if (new_job->nb_requested_resources > _nb_machines)
+        {
+            // Invalid!
+            //LOG_F(INFO,"Job being rejected HERE %s",new_job_id.c_str());
+            _decision->add_reject_job(new_job_id, date);
+            continue;
+        }
+        Allocation alloc;
+        bool executed = false;
+        //Are we share-packing?
+        if (_share_packing && new_job->nb_requested_resources == 1)
+        {
+            //Can the job be executed right now?
+            //first check all core machines running right now
+            
+            bool found = false;
+            for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+            {
+                //is this machine able to handle another job?
+                machine* current_machine = machines_by_int[*it];
+                if (current_machine->cores_available >= 1)
+                {                                
+                    //it is able to handle another job
+                    found = true;
+                    alloc.machines = *it;
+                    break;
+                }
+                                 
+            }
+            if (found == true)
+            {
+                if(_priority_job == nullptr ||
+                         date + new_job->walltime<= _priority_job->completion_time)
+                {
+                    //yes it can be executed right away
+                    _decision->add_execute_job(new_job_id,alloc.machines,date,mapping);
+                    _e_counter+=1;
+                    executed = true;
+                    //update data structures
+                    FinishedHorizonPoint point;
+                    point.nb_released_machines = new_job->nb_requested_resources;
+                    point.date = date + (double)new_job->walltime;
+                    point.machines = alloc.machines;
+                    alloc.horizon_it = insert_horizon_point(point);
+
+                    machine * current_machine = machines_by_int[alloc.machines[0]];
+                    current_machine->cores_available -=1;
+                    _current_allocations[new_job_id] = alloc;
+                    _running_jobs.insert(new_job_id);
+                    
+                }
+            }
+            if (found == false && _nb_available_machines > 0)
+            {
+                       
+                //Can the job be executed without hindering priority job?
+                if(_priority_job == nullptr ||
+                    date + new_job->walltime<= _priority_job->completion_time)
+                {
+                    //yes it can
+                    //first get a machine
+                    alloc.machines = _available_machines.left(1);
+                    _decision->add_execute_job(new_job_id,alloc.machines,date,mapping);
+                    _e_counter+=1;
+                    executed = true;
+                    FinishedHorizonPoint point;
+                    point.nb_released_machines = new_job->nb_requested_resources;
+                    point.date = date + (double) new_job->walltime;
+                    point.machines = alloc.machines;
+                    alloc.horizon_it = insert_horizon_point(point);
+
+
+                    //update data structures
+                    machine* current_machine = machines_by_int[alloc.machines[0]];
+                    current_machine->cores_available -= 1;
+                    _available_core_machines += alloc.machines;
+                    _available_machines -= alloc.machines;
+                    _nb_available_machines -= 1;
+                    
+                    _current_allocations[new_job_id] = alloc;
+                    
+                    _running_jobs.insert(new_job_id);
+                    
+                                                
+                }
+
+            }   
+
+        }//end share-packing block
+        //we are not share-packing or the number of resources != 1
+        else if (new_job->nb_requested_resources <=_nb_available_machines)
+        {
+            if (_priority_job == nullptr ||
+                date + new_job->walltime <= _priority_job->completion_time)
+            {
+                alloc.machines = _available_machines.left(
+                    new_job->nb_requested_resources);
+                _decision->add_execute_job(new_job_id, alloc.machines, date);
+                _e_counter+=1;
+                executed = true;
+
+                FinishedHorizonPoint point;
+                point.nb_released_machines = new_job->nb_requested_resources;
+                point.date = date + (double)new_job->walltime;
+                point.machines = alloc.machines;
+                alloc.horizon_it = insert_horizon_point(point);
+
+                // Update data structures
+                _available_machines -= alloc.machines;
+                _nb_available_machines -= new_job->nb_requested_resources;
+                _current_allocations[new_job_id] = alloc;
+                _running_jobs.insert(new_job_id);
+            }
+        }
+        if (executed==false)
+        {
+            if (_priority_job == nullptr)
+            {
+                _priority_job = new_job;
+                _priority_job->completion_time = compute_priority_job_expected_earliest_starting_time();
+                
+            }
+            // submitted job is a resubmitted one, put at front of pending jobs
+            else if(new_job_id.find("#")!=std::string::npos)
+                _pending_jobs.push_front(new_job);
+                
+            else
+                _pending_jobs.push_back(new_job);
+                
+        }
+    }//end released jobs loop
+    LOG_F(INFO,"pending_jobs size %d",_pending_jobs.size());
+}
+
+        
+
+
+
+void easy_bf_fast2::handle_resubmission(double date)
+{
+ for(const auto & killed_map:_jobs_killed_recently)
+    {
+        std::string killed_job=killed_map.first;
+        batsched_tools::Job_Message * msg = killed_map.second;
+        double progress = msg->progress;
+        //LOG_F(INFO,"REPAIR  progress: %f",progress);
+        auto start = killed_job.find("!")+1;
+        auto end = killed_job.find("#");
+        std::string basename = (end ==std::string::npos) ? killed_job.substr(start) : killed_job.substr(start,end-start); 
+        
+        const std::string workload_str = killed_job.substr(0,start-1); 
+        //get the workload
+        myB::Workload * w0= (*_myWorkloads)[workload_str];
+        //get the conversion from seconds to cpu instructions
+        double one_second = w0->_host_speed;
+        //get the job that was killed
+        myB::JobPtr job_to_queue =(*(w0->jobs))[myB::JobIdentifier(killed_job)];
+        //get the job identifier of the job that was killed
+        myB::JobIdentifier ji = job_to_queue->id;
+        
+        std::string profile_jd=job_to_queue->profile->json_description;
+        std::string job_jd=job_to_queue->json_description;
+        r::Document profile_doc;
+        profile_doc.Parse(profile_jd.c_str());
+        r::Document doc;
+        doc.Parse(job_jd.c_str());
+        
+        if (job_to_queue->profile->type == myB::ProfileType::DELAY )
+        {
+            if (_checkpointing_on)
+            {
+                double progress_time = 0;
+                if (progress > 0)
+                {
+                    
+                    
+                    progress_time =progress * profile_doc["delay"].GetDouble();
+                    //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                    
+                    bool has_checkpointed = false;
+                    std::string meta_str = "null";
+                    int num_checkpoints_completed = 0;
+                    r::Document meta_doc;
+                    //check whether there is a checkpointed value and set has_checkpointed if so
+                    if (doc.HasMember("metadata"))
+                    {
+                        
+                        meta_str = doc["metadata"].GetString();
+                        std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                        meta_doc.Parse(meta_str.c_str());
+                        if (meta_doc.HasMember("checkpointed"))
+                        {
+                            has_checkpointed = meta_doc["checkpointed"].GetBool();
+                            
+                        }
+                    }
+                    //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                    if (has_checkpointed)
+                    {
+                        
+                        //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                        num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                        if (meta_doc.HasMember("work_progress"))
+                        {
+                            double work = meta_doc["work_progress"].GetDouble();
+                            if (num_checkpoints_completed > 0)
+                                work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                            meta_doc["work_progress"] = work;
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                        }
+                        if (meta_doc.HasMember("num_dumps"))
+                        {
+                                int num_dumps = meta_doc["num_dumps"].GetInt();
+                                if (num_checkpoints_completed > 0)
+                                    num_dumps += num_checkpoints_completed;
+                                meta_doc["num_dumps"] = num_dumps;
+                                
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            
+                        }
+                        std::string meta_str = to_json_desc(&meta_doc);
+                        doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                        // the progress_time needs to add back in the read_time
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                    
+                    }
+                    else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                    {
+                        num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                        
+                        
+                        //if a checkpoint has completed set the metadata to reflect this
+                        if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.SetObject();
+                            //if there was previous metadata make sure to include it
+                            if (meta_str!="null")
+                            {
+                                meta_doc.Parse(meta_str.c_str());
+                            }    
+                            r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                            meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                            meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                            std::string myString = to_json_desc(&meta_doc);
+                            r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                
+                            if (meta_str=="null")
+                                doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                            else
+                                doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                        }
+        
+                    }        
+                    //only if a new checkpoint has been reached does the delay time change
+                    //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                    if (num_checkpoints_completed > 0)
+                    {
+                        
+                        double delay = profile_doc["delay"].GetDouble() - progress_time + job_to_queue->read_time;
+                        //LOG_F(INFO,"REPAIR delay: %f  readtime: %f",delay,job_to_queue->read_time);
+                        profile_doc["delay"].SetDouble(delay);
+                        
+                        
+                    }
+                }
+            
+            }
+                                          
+                    
+        }
+    
+        if (job_to_queue->profile->type == myB::ProfileType::PARALLEL_HOMOGENEOUS)
+        {
+            if (_checkpointing_on)
+                {
+                    double progress_time = 0;
+                    if (progress > 0)
+                    {
+                        
+                        
+                        progress_time =(progress * profile_doc["cpu"].GetDouble())/one_second;
+                        //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                        //LOG_F(INFO,"profile_doc[cpu]: %f    , one_second: %f",profile_doc["cpu"].GetDouble(),one_second);
+                        
+                        bool has_checkpointed = false;
+                        std::string meta_str = "null";
+                        int num_checkpoints_completed = 0;
+                        r::Document meta_doc;
+                        //check whether there is a checkpointed value and set has_checkpointed if so
+                        if (doc.HasMember("metadata"))
+                        {
+                            
+                            meta_str = doc["metadata"].GetString();
+                            std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                            meta_doc.Parse(meta_str.c_str());
+                            if (meta_doc.HasMember("checkpointed"))
+                            {
+                                has_checkpointed = meta_doc["checkpointed"].GetBool();
+                                
+                            }
+                        }
+                        //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                        if (has_checkpointed)
+                        {
+                            
+                            //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                            num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                            if (meta_doc.HasMember("work_progress"))
+                            {
+                                double work = meta_doc["work_progress"].GetDouble();
+                                if (num_checkpoints_completed > 0)
+                                    work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                                work = work * one_second;
+                                meta_doc["work_progress"] = work;
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval*one_second),meta_doc.GetAllocator());
+                            }
+                            if (meta_doc.HasMember("num_dumps"))
+                            {
+                                    int num_dumps = meta_doc["num_dumps"].GetInt();
+                                    if (num_checkpoints_completed > 0)
+                                        num_dumps += num_checkpoints_completed;
+                                    meta_doc["num_dumps"] = num_dumps;
+                                    
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                    meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                
+                            }
+                            std::string meta_str = to_json_desc(&meta_doc);
+                            doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                            // the progress_time needs to add back in the read_time
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                        
+                        }
+                        else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                        {
+                            num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                            
+                            
+                            //if a checkpoint has completed set the metadata to reflect this
+                            if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.SetObject();
+                                //if there was previous metadata make sure to include it
+                                if (meta_str!="null")
+                                {
+                                    meta_doc.Parse(meta_str.c_str());
+                                }    
+                                r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                                meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval * one_second),meta_doc.GetAllocator());
+                                std::string myString = to_json_desc(&meta_doc);
+                                r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                    
+                                if (meta_str=="null")
+                                    doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                                else
+                                    doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                            }
+            
+                        }        
+                        //only if a new checkpoint has been reached does the delay time change
+                        //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                        if (num_checkpoints_completed > 0)
+                        {
+                            double cpu = profile_doc["cpu"].GetDouble();
+                            double cpu_time = cpu / one_second;
+                            cpu_time = cpu_time - progress_time + job_to_queue->read_time;
+                            //LOG_F(INFO,"REPAIR cpu_time: %f  readtime: %f",cpu_time,job_to_queue->read_time);
+                            profile_doc["cpu"].SetDouble(cpu_time*one_second);
+                            
+                            
+                        }
+                    }
+                
+                }
+        }
+
+
+        doc["subtime"]=date;
+                
+        //check if resubmitted and get the next resubmission number
+        int resubmit = 1;
+        if (end!=std::string::npos) //if job name has # in it...was resubmitted b4
+        {
+            resubmit = std::stoi(killed_job.substr(end+1));   // then get the resubmitted number
+            resubmit++; // and add 1 to it
+        }
+        std::string resubmit_str = std::to_string(resubmit);
+        
+        
+        std::string profile_name = basename + "#" + resubmit_str;
+        std::string job_name = basename + "#" + resubmit_str;
+        std::string job_id = workload_str+"!" + basename + "#" + resubmit_str;
+        std::string workload_name = workload_str;
+        doc["profile"].SetString(profile_name.data(), profile_name.size(), doc.GetAllocator());
+        doc["id"].SetString(job_id.data(),job_id.size(),doc.GetAllocator());
+        std::string error_prefix = "Invalid JSON job '" + killed_job + "'";
+        profile_jd = to_json_desc(&profile_doc);
+        myB::ProfilePtr p = myB::Profile::from_json(profile_name,profile_jd);
+        w0->profiles->add_profile(p);
+        myB::JobPtr j = myB::Job::from_json(doc,w0,error_prefix);
+        w0->jobs->add_job(j);
+        job_jd = to_json_desc(&doc);
+        //LOG_F(INFO,"workload: %s  job: %s, profile: %s",workload_name.c_str(),job_name.c_str(),profile_name.c_str());
+        _decision->add_submit_profile(workload_name,
+                                    profile_name,
+                                    profile_jd,
+                                    date);
+                                    
+        _decision->add_submit_job(workload_name,
+                                    job_name,
+                                    profile_name,
+                                    job_jd,
+                                    profile_jd,
+                                    date,
+                                    true);
+        if (doc.HasMember("metadata"))
+        {
+            std::string meta = doc["metadata"].GetString();
+            //must replace double quotes with single quotes.  Remember to
+            //replace single quotes with double quotes before parsing metadata
+            std::replace( meta.begin(), meta.end(), '\"', '\'');
+        _decision->add_set_job_metadata(job_id,
+                                        meta,
+                                        date);
+        }                               
+    }            
+    
+       
+}
+
+std::list<easy_bf_fast2::FinishedHorizonPoint>::iterator easy_bf_fast2::insert_horizon_point(const easy_bf_fast2::FinishedHorizonPoint &point)
+{
+    // The data structure is sorted, we can therefore traverse it in order
+    // until finding an insertion point.
+    for (auto it = _horizons.begin(); it != _horizons.end(); ++it)
+    {
+        if (point.date < it->date)
+        {
+            // Insertion point is before the current iterator.
+            return _horizons.insert(it, point);
+        }
+    }
+
+    // Insertion point not found. Insertion at end.
+    return _horizons.insert(_horizons.end(), point);
+}
+
+double easy_bf_fast2::compute_priority_job_expected_earliest_starting_time()
+{
+    int nb_available = _nb_available_machines;
+    int required = _priority_job->nb_requested_resources;
+    //LOG_F(INFO,"line 1294");
+    //make a shallow copy of machines_by_int if share-packing
+    std::map<int,machine *> machines_by_int_copy;
+    if (_share_packing)
+    {
+        for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+            {
+                machine* current_machine = machines_by_int[*it];
+                machine* a_machine = new machine();
+                //all we need to copy are cores_available and core_count
+                a_machine->cores_available = current_machine->cores_available;
+                a_machine->core_count = current_machine->core_count;
+                machines_by_int_copy[*it]=a_machine;
+            }
+
+    }   
+         //LOG_F(INFO,"line 1310");   
+
+    for (auto it = _horizons.begin(); it != _horizons.end(); ++it)
+    {
+        //is this the case that a single core is being released?
+        if (_share_packing && it->nb_released_machines == 1)
+        {
+            //LOG_F(INFO,"line 1324");
+            //ok a single core is released
+            //is that all we needed for the priority_job (unlikely for a priority job but not out of the question)
+            if (required == 1)
+                return it->date;
+            //ok that isn't all we needed, let's keep track of these released cores on each machine
+            int machine_number = it->machines[0];
+            machine * current_machine = machines_by_int_copy[machine_number];
+            current_machine->cores_available +=1;
+            //ok so we added a core to the released machine
+            //does this bring a whole machine available?
+            //LOG_F(INFO,"line 1335");
+            if (current_machine->cores_available == int(current_machine->core_count * _core_percent))
+                {
+                    //yes it did make a whole machine available
+                    nb_available += 1;
+                }
+        }
+        //we are not doing share-packing or more than a single core was released
+        else 
+            nb_available += it->nb_released_machines;
+        //do we now have enough full machines to run the priority job?
+        if (nb_available >= required)
+        {
+            //yes we do, return the time that this will occur
+            return it->date;
+        }
+    }
+
+    PPK_ASSERT_ERROR(false, "The job will never be executable.");
+    return 0;
+}
+/*(Document, Swap) {
+    Document d1;
+    Document::AllocatorType& a = d1.GetAllocator();
+
+    d1.SetArray().PushBack(1, a).PushBack(2, a);
+
+    Value o;
+    o.SetObject().AddMember("a", 1, a);
+
+    // Swap between Document and Value
+    d1.Swap(o);
+*/
diff -burN '--exclude=.git*' ./batsched/src/algo/easy_bf_fast2_holdback.cpp ./new_batsched/src/algo/easy_bf_fast2_holdback.cpp
--- ./batsched/src/algo/easy_bf_fast2_holdback.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/easy_bf_fast2_holdback.cpp	2023-06-28 08:26:02.133833308 -0400
@@ -0,0 +1,1595 @@
+#include <math.h>
+#include "easy_bf_fast2_holdback.hpp"
+
+#include "../pempek_assert.hpp"
+
+#include <loguru.hpp>
+#include "../external/batsched_workload.hpp"
+#include "../external/batsched_job.hpp"
+#include "../external/batsched_profile.hpp"
+#include "../external/pointers.hpp"
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <chrono>
+#include "../batsched_tools.hpp"
+
+
+#define B_LOG_INSTANCE _myBLOG
+namespace myB = myBatsched;
+namespace r = rapidjson;
+const int DEBUG = 10;
+
+easy_bf_fast2_holdback::easy_bf_fast2_holdback(Workload *workload,
+    SchedulingDecision *decision, Queue *queue, ResourceSelector *selector,
+    double rjms_delay, rapidjson::Document *variant_options) :
+    ISchedulingAlgorithm(workload, decision, queue, selector, rjms_delay,
+        variant_options)
+{
+    
+    _myWorkloads = new myBatsched::Workloads;
+    //batsim log object.  declared in batsched_tools.hpp
+    _myBLOG = new b_log();
+    
+    
+}
+
+easy_bf_fast2_holdback::~easy_bf_fast2_holdback()
+{
+    
+}
+
+void easy_bf_fast2_holdback::on_simulation_start(double date,
+    const rapidjson::Value &batsim_event_data)
+{
+    bool seedFailures = false;
+    bool logBLog = false;
+    const rapidjson::Value & batsim_config = batsim_event_data["config"];
+    if (batsim_config.HasMember("share-packing"))
+        _share_packing = batsim_config["share-packing"].GetBool();
+    if (batsim_config.HasMember("share-packing-holdback"))
+        _share_packing_holdback = batsim_config["share-packing-holdback"].GetInt();
+    if (batsim_config.HasMember("core-percent"))
+        _core_percent = batsim_config["core-percent"].GetDouble();
+
+    if (batsim_config.HasMember("output-folder")){
+        _output_folder = batsim_config["output-folder"].GetString();
+        _output_folder=_output_folder.substr(0,_output_folder.find_last_of("/"));
+    }
+    
+    if (batsim_config.HasMember("seed-failures"))
+        seedFailures = batsim_config["seed-failures"].GetBool();
+    if (batsim_config.HasMember("log_b_log"))
+        logBLog = batsim_config["log_b_log"].GetBool();
+    //log BLogs, add log files that you want logged to.
+    if (logBLog){
+        _myBLOG->add_log_file(_output_folder+"/log/failures.log",b_log::FAILURES);
+    }
+    unsigned seed = 0;
+    if (seedFailures)
+        seed = std::chrono::system_clock::now().time_since_epoch().count();
+         
+    generator.seed(seed);
+    generator2.seed(seed);
+    _available_machines.insert(IntervalSet::ClosedInterval(0, _nb_machines - 1));
+    _nb_available_machines = _nb_machines;
+    //LOG_F(INFO,"avail: %d   nb_machines: %d",_available_machines.size(),_nb_machines);
+    PPK_ASSERT_ERROR(_available_machines.size() == (unsigned int) _nb_machines);
+    const rapidjson::Value& resources = batsim_event_data["compute_resources"];
+    for ( auto & itr : resources.GetArray())
+    {
+	machine* a_machine = new machine();
+        if (itr.HasMember("id"))
+            a_machine->id = (itr)["id"].GetInt();
+        if (itr.HasMember("core_count"))
+        {
+            a_machine->core_count = (itr)["core_count"].GetInt();
+            a_machine->cores_available = int(a_machine->core_count * _core_percent);
+        }
+        if (itr.HasMember("speed"))
+            a_machine->speed = (itr)["speed"].GetDouble();
+        if (itr.HasMember("name"))
+            a_machine->name = (itr)["name"].GetString();
+        machines_by_int[a_machine->id] = a_machine;
+        machines_by_name[a_machine->name] = a_machine;
+        
+    
+        //LOG_F(INFO,"machine id = %d, core_count= %d , cores_available= %d",a_machine->id,a_machine->core_count,a_machine->cores_available);
+   }
+   if (_share_packing_holdback > 0)
+   {
+        _nb_available_machines -=_share_packing_holdback;
+        _heldback_machines = _available_machines.left(_share_packing_holdback);
+        _available_machines -= _heldback_machines;
+        _unavailable_machines +=_heldback_machines;
+    }
+     _oldDate=date;
+     if (_myWorkloads->_fixed_failures != -1.0)
+     {
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        double number = _myWorkloads->_fixed_failures;
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);  
+     }
+    if (_myWorkloads->_SMTBF != -1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_SMTBF);
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_SMTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+    }
+    else if (_myWorkloads->_MTBF!=-1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_MTBF);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_MTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+    }
+}      
+void easy_bf_fast2_holdback::on_simulation_end(double date){
+    (void) date;
+}
+    
+ /*void easy_bf_fast2_holdback::on_machine_unavailable_notify_event(double date, IntervalSet machines){
+    //LOG_F(INFO,"unavailable %s",machines.to_string_hyphen().c_str());
+    _unavailable_machines+=machines;
+    _available_machines-=machines;
+    for(auto key_value : _current_allocations)
+    {
+            if (!((key_value.second.machines & machines).is_empty()))
+                _decision->add_kill_job({key_value.first},date);
+    }
+    
+}
+*/
+void easy_bf_fast2_holdback::set_workloads(myBatsched::Workloads *w){
+    _myWorkloads = w;
+    _checkpointing_on = w->_checkpointing_on;
+    
+}
+void easy_bf_fast2_holdback::on_machine_available_notify_event(double date, IntervalSet machines){
+    ISchedulingAlgorithm::on_machine_available_notify_event(date, machines);
+    _unavailable_machines-=machines;
+    _available_machines+=machines;
+    _nb_available_machines+=machines.size();
+    
+}
+
+void easy_bf_fast2_holdback::on_machine_state_changed(double date, IntervalSet machines, int new_state)
+{
+   
+
+}
+void easy_bf_fast2_holdback::on_myKillJob_notify_event(double date){
+    
+    if (!_running_jobs.empty()){
+        auto msg = new batsched_tools::Job_Message;
+        msg->id = *_running_jobs.begin();
+        msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+        _my_kill_jobs.insert(std::make_pair((*_workload)[*_running_jobs.begin()],msg));
+    }
+        
+    
+}
+
+
+
+void easy_bf_fast2_holdback::on_machine_down_for_repair(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    //if the machine is already down for repairs ignore it.
+    //LOG_F(INFO,"repair_machines.size(): %d    nb_avail: %d  avail:%d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+    BLOG_F(b_log::FAILURES,"Machine Repair: %d",number);
+    if ((machine & _repair_machines).is_empty())
+    {
+        //ok the machine is not down for repairs
+        //it will be going down for repairs now
+        _available_machines-=machine;
+        _unavailable_machines+=machine;
+        _repair_machines+=machine;
+        _nb_available_machines=_available_machines.size();
+
+        double repair_time = _myWorkloads->_repair_time;
+        //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d  avail: %d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+        //LOG_F(INFO,"date: %f , repair: %f ,repair + date: %f",date,repair_time,date+repair_time);
+        //call me back when the repair is done
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::REPAIR_DONE,number,date+repair_time,date);
+        //now kill the jobs that are running on machines that need to be repaired.        
+        //if there are no running jobs, then there are none to kill
+        if (!_running_jobs.empty()){
+            for(auto key_value : _current_allocations)
+            {
+                if (!((key_value.second.machines & machine).is_empty())){
+                    Job * job_ref = (*_workload)[key_value.first];
+                    auto msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+                    BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+                }
+            }
+        }
+    }
+    else
+    {
+        BLOG_F(b_log::FAILURES,"Machine Already Being Repaired: %d",number);
+    }
+}
+
+
+void easy_bf_fast2_holdback::on_machine_instant_down_up(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    BLOG_F(b_log::FAILURES,"Machine Instant Down Up: %d",number);
+    //if there are no running jobs, then there are none to kill
+    if (!_running_jobs.empty()){
+        for(auto key_value : _current_allocations)   
+	    {
+		    if (!((key_value.second.machines & machine).is_empty())){
+                	Job * job_ref = (*_workload)[key_value.first];
+                    auto msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+	                BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+            }
+	    }
+    }
+}
+/*void easy_bf_fast2_holdback::on_job_fault_notify_event(double date, std::string job){
+    std::unordered_set<std::string>::const_iterator found = _running_jobs.find(job);
+  //LOG_F(INFO,"on_job_fault_notify_event called");
+  if ( found != _running_jobs.end() )    
+        _decision->add_kill_job({job},date);
+  else
+      LOG_F(INFO,"Job %s was not running but was supposed to be killed due to job_fault event",job.c_str());
+}
+*/
+
+void easy_bf_fast2_holdback::on_requested_call(double date,int id,batsched_tools::call_me_later_types forWhat)
+{
+    
+        switch (forWhat){
+            case batsched_tools::call_me_later_types::SMTBF:
+                        {
+                            //Log the failure
+                            BLOG_F(b_log::FAILURES,"FAILURE SMTBF");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = distribution->operator()(generator);
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::MTBF:
+                        {
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                            {
+                                double number = distribution->operator()(generator);
+                                on_myKillJob_notify_event(date);
+                                _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+
+                            }
+                        
+                            
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::FIXED_FAILURE:
+                        {
+                            BLOG_F(b_log::FAILURES,"FAILURE FIXED_FAILURE");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = _myWorkloads->_fixed_failures;
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::REPAIR_DONE:
+                        {
+                            BLOG_F(b_log::FAILURES,"REPAIR_DONE");
+                            //a repair is done, all that needs to happen is add the machines to available
+                            //and remove them from repair machines and add one to the number of available
+                            IntervalSet machine = id;
+                            _available_machines += machine;
+                            _unavailable_machines -= machine;
+                            _repair_machines -= machine;
+                            _nb_available_machines=_available_machines.size();
+                            _machines_that_became_available_recently += machine;
+                           //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d avail: %d  running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+                        }
+                        break;
+        }
+    
+
+}
+void easy_bf_fast2_holdback::on_no_more_static_job_to_submit_received(double date){
+    ISchedulingAlgorithm::on_no_more_static_job_to_submit_received(date);
+
+}
+void easy_bf_fast2_holdback::on_no_more_external_event_to_occur(double date){
+    
+    _wrap_it_up = true;    
+    
+    
+}
+void easy_bf_fast2_holdback::on_job_end(double date, std::vector<std::string> job_ids)
+{
+    (void) date;
+    (void) job_ids;
+}
+
+
+
+
+
+/*********************************************************
+ *                                                       *
+ *                    Make Decisions                     *
+ *                                                       *
+**********************************************************/
+
+
+
+void easy_bf_fast2_holdback::make_decisions(double date,
+    SortableJobOrder::UpdateInformation *update_info,
+    SortableJobOrder::CompareInformation *compare_info)
+{
+   ////LOG_F(INFO,"line 322   fcfs_fast2.cpp");
+    (void) update_info;
+    (void) compare_info;
+    std::vector<int> mapping = {0};
+    if (_oldDate == -1)
+        _oldDate=date;
+    // This algorithm is a fast version of FCFS without backfilling.
+    // It is meant to be fast in the usual case, not to handle corner cases.
+    // It is not meant to be easily readable or hackable ;).
+
+    // This fast FCFS variant in a few words:
+    // - only handles the FCFS queue order
+    // - only handles the basic resource selection policy
+    // - only handles finite jobs (no switchoff)
+    // - only handles time as floating-point (-> precision errors).
+
+    
+
+    ////LOG_F(INFO,"line 340  fcfs_fast2.cpp");
+    //*****************************************************************
+    // Handle newly finished jobs
+    //*****************************************************************
+    LOG_F(INFO,"line 353");
+    bool job_ended = handle_newly_finished_jobs();
+    LOG_F(INFO,"line 355");    
+    handle_new_jobs_to_kill(date);
+    //************************************************************resubmission if killed
+    //Handle jobs to queue back up (if killed)
+    LOG_F(INFO,"line 359");
+    handle_resubmission(date);    
+    //***********************************************************
+    LOG_F(INFO,"line 362");
+    handle_machines_coming_available(date);
+    LOG_F(INFO,"line 364");
+    handle_ended_job_execution(job_ended,date);
+    LOG_F(INFO,"line 366");
+    handle_newly_released_jobs(date);
+    LOG_F(INFO,"line 368");
+    
+    /*if (_jobs_killed_recently.empty() && _wrap_it_up && _need_to_send_finished_submitting_jobs && !_myWorkloads->_checkpointing_on)
+    {
+        
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+    */
+   LOG_F(INFO,"_e_counter %d _p_counter %d",_e_counter,_p_counter);
+    if (_jobs_killed_recently.empty() && _pending_jobs.empty() && _running_jobs.empty() &&
+             _need_to_send_finished_submitting_jobs && _no_more_static_job_to_submit_received && !date<1.0 )
+    {
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+      
+}
+
+
+
+
+std::string easy_bf_fast2_holdback::to_json_desc(rapidjson::Document * doc)
+{
+  rapidjson::StringBuffer buffer;
+
+  buffer.Clear();
+
+  rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+  doc->Accept(writer);
+
+  return std::string( buffer.GetString() );
+}
+
+
+/**********************************************
+ * 
+ *          Newly Finished Jobs
+ * 
+ ***********************************************/
+
+bool easy_bf_fast2_holdback::handle_newly_finished_jobs()
+{
+   //LOG_F(INFO,"line 410");
+   std::vector<int> mapping = {0};
+    bool job_ended = false;
+    for (const std::string & ended_job_id : _jobs_ended_recently)
+    {
+        job_ended = true;
+        Job * finished_job = (*_workload)[ended_job_id];
+        const Allocation & alloc = _current_allocations[ended_job_id];
+        if (_share_packing && finished_job->nb_requested_resources == 1)
+        {
+                //first get the machine it was running on
+                int machine_number = alloc.machines[0];
+                machine* current_machine = machines_by_int[machine_number];
+
+                //now increase cores_available on that machine
+                current_machine->cores_available += 1;
+                //if that machine was part of heldback machines then that's all that needs to be done
+                bool skip = false;
+                if (_share_packing_holdback > 0 && !((_heldback_machines & alloc.machines).is_empty()))
+                    skip = true;
+                //if that increase means no jobs are running on that machine (all its cores are available) then put it back in the mix
+                if (!skip && current_machine->cores_available == int(current_machine->core_count * _core_percent))
+                {
+                    _available_core_machines -= alloc.machines;  // we subtract a core machine because it is now a regular machine
+                    _available_machines.insert(alloc.machines); // we insert the machine into available machines
+                    _nb_available_machines += 1; // we increase available machines by 1
+                }
+                _current_allocations.erase(ended_job_id);
+                if (alloc.has_horizon == true)
+                    _horizons.erase(alloc.horizon_it);
+                _running_jobs.erase(ended_job_id);
+        }
+            // was not a 1 resource job, do things normally
+        else{
+                _available_machines.insert(alloc.machines);
+                _nb_available_machines += finished_job->nb_requested_resources;
+                _current_allocations.erase(ended_job_id);
+                _running_jobs.erase(ended_job_id);
+                _my_kill_jobs.erase((*_workload)[ended_job_id]);
+                _horizons.erase(alloc.horizon_it);
+        }
+    }
+
+    LOG_F(INFO,"_nb_available_machines %d",_nb_available_machines);
+    return job_ended;
+}
+
+/**********************************************
+ * 
+ *          New Jobs To Kill
+ * 
+ ***********************************************/
+
+
+void easy_bf_fast2_holdback::handle_new_jobs_to_kill(double date)
+{
+     if(!_my_kill_jobs.empty()){
+         std::vector<batsched_tools::Job_Message *> kills;
+        for( auto job_msg_pair:_my_kill_jobs)
+        {
+            kills.push_back(job_msg_pair.second);
+        }
+        _decision->add_kill_job(kills,date);
+        _my_kill_jobs.clear();
+    }
+}
+
+/**********************************************
+ * 
+ *          Machines Coming Available TODO
+ * 
+ ***********************************************/
+
+void easy_bf_fast2_holdback::handle_machines_coming_available(double date)
+{
+    
+    
+}
+
+/**********************************************
+ * 
+ *          Ended Job Execution
+ * 
+ ***********************************************/
+
+
+
+void easy_bf_fast2_holdback::handle_ended_job_execution(bool job_ended,double date)
+{
+    std::vector<int> mapping = {0};
+    // If jobs have finished, execute jobs as long as they fit
+    std::list<Job *>::iterator job_it =_pending_jobs.begin();
+    if (job_ended)
+    {
+        if (_priority_job == nullptr)
+            LOG_F(INFO,"line 499 nullptr");
+        if (_priority_job != nullptr)
+        {
+            LOG_F(INFO,"pending_jobs %d _nb_available_machines %d",_pending_jobs.size(),_nb_available_machines);
+            //first check if priority job fits
+            //it fits if it's a 1 resource job and 
+            //share_packing is enabled and
+            //we either find an _available_core_machine or we find an available heldback machine or
+            //we find a free machine to make an _available_core_machine
+            //or
+            //it fits if share_packing is disabled, or it's greater than a 1 resource job
+            //and
+            //there are enough machines available for the priority job's nb_requested_resources
+            Allocation alloc;
+            FinishedHorizonPoint point;
+            bool executed = false;
+
+            if (_share_packing && _priority_job->nb_requested_resources == 1)
+            {
+                //ok it's a 1 resource job and share packing is enabled
+                //let's check if we can run it on a heldback machine
+                bool found = false;
+                if (_share_packing_holdback > 0)
+                {
+                    for (auto it = _heldback_machines.elements_begin(); it != _heldback_machines.elements_end(); ++it)
+                    {
+                        machine* current_machine = machines_by_int[*it];
+                        if (current_machine->cores_available >= 1)
+                        {
+                            found = true;
+                            alloc.machines = *it;
+                            break;
+                        }
+                    }
+                    if (found == true)
+                    {
+                        _decision->add_execute_job(_priority_job->id,alloc.machines,date,mapping);
+                        _e_counter+=1;
+                        executed = true;
+                        //update data structures
+                        //the job doesn't get put into the horizons because it is not part of backfilling
+                        alloc.has_horizon = false;
+
+                        machine * current_machine = machines_by_int[alloc.machines[0]];
+                        current_machine->cores_available -=1;
+                        _current_allocations[_priority_job->id] = alloc;
+                        _running_jobs.insert(_priority_job->id);
+                        _priority_job = nullptr;
+                        
+                    }
+                }
+
+
+                //ok the job can be share-packed:
+                    if (executed == false) //(not able to run on heldback machines )
+                    {
+                        //first check if there is a share-packing machine available:
+                        //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                        for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                        {
+                            //is this machine able to handle another job?
+                            machine* current_machine = machines_by_int[*it];
+                            if (current_machine->cores_available >= 1)
+                            {                                
+                                //it is able to handle another job
+                                found = true;
+                                alloc.machines = *it;
+                                break;
+                            }
+                                        
+                        }
+                        //LOG_F(INFO,"line 529");
+                        if (found == true)
+                        {
+                            //yes it can be executed right away
+                            _decision->add_execute_job(_priority_job->id,alloc.machines,date,mapping);
+                            _e_counter+=1;
+                            executed = true;
+                            //update data structures
+                            machine* current_machine = machines_by_int[alloc.machines[0]];
+                            point.nb_released_machines = _priority_job->nb_requested_resources;
+                            point.date = date + (double)_priority_job->walltime;
+                            point.machines = alloc.machines;
+                            alloc.horizon_it = insert_horizon_point(point);
+
+                            
+                            current_machine->cores_available -=1;
+                            _current_allocations[_priority_job->id] = alloc;
+                            _running_jobs.insert(_priority_job->id);
+
+                            _priority_job = nullptr;    
+                            
+                        }
+                        if (found == false && _nb_available_machines > 0)
+                        {
+                            
+                            //first get a machine
+                            alloc.machines = _available_machines.left(1);
+                        
+                            _decision->add_execute_job(_priority_job->id,alloc.machines,date,mapping);
+                            _e_counter+=1;
+                            executed = true;
+                            
+                            point.nb_released_machines = _priority_job->nb_requested_resources;
+                            point.date = date + (double)_priority_job->walltime;
+                            point.machines = alloc.machines;
+                            alloc.horizon_it = insert_horizon_point(point);
+
+                            //update data structures
+                            machine* current_machine = machines_by_int[alloc.machines[0]];
+                            current_machine->cores_available -= 1;
+                            _available_core_machines += alloc.machines;
+                            _available_machines -= alloc.machines;
+                            _nb_available_machines -= 1;
+                        
+                            _current_allocations[_priority_job->id] = alloc;
+                        
+                            _running_jobs.insert(_priority_job->id);
+                            _priority_job = nullptr;
+                        
+                        }
+                    }//end not executed
+                
+            }//end share-packing
+            //ok not share-packing or resources > 1
+            else if (_priority_job->nb_requested_resources <= _nb_available_machines)
+            {
+                //LOG_F(INFO, "Priority job fits!");
+                alloc.machines = _available_machines.left(
+                    _priority_job->nb_requested_resources);
+                _decision->add_execute_job(_priority_job->id, alloc.machines,
+                    date);
+                executed = true;
+                _e_counter+=1;
+                point.nb_released_machines = _priority_job->nb_requested_resources;
+                point.date = date + (double)_priority_job->walltime;
+                point.machines = alloc.machines;
+                alloc.horizon_it = insert_horizon_point(point);
+
+                // Update data structures
+                _available_machines -= alloc.machines;
+                _nb_available_machines -= _priority_job->nb_requested_resources;
+                _current_allocations[_priority_job->id] = alloc;
+                _priority_job = nullptr;
+            }
+            //LOG_F(INFO,"line 597");
+              
+            if (executed)
+            {
+                //ok priority job got to run, now execute the whole queue until a priority job cannot fit
+                std::list<Job *>::iterator job_it =_pending_jobs.begin();
+                bool erased = false;
+                bool executed2;
+                while(job_it!=_pending_jobs.end())
+                {
+                    Job * pending_job = *job_it;
+                    Allocation alloc;
+                    executed2 = false;
+            
+                    std::string pending_job_id = pending_job->id;
+                    //can the job be share-packed?
+                    if (_share_packing && pending_job->nb_requested_resources==1)
+                    {
+                        //it can be share-packed, can we run it on a heldback machine?
+                        LOG_F(INFO,"line 611");
+                        bool found = false;
+                        if (_share_packing_holdback > 0)
+                        {
+                            //we can run it on a heldback machine as long as one is available.
+                            for (auto it = _heldback_machines.elements_begin(); it != _heldback_machines.elements_end(); ++it)
+                            {
+                                machine* current_machine = machines_by_int[*it];
+                                if (current_machine->cores_available >= 1)
+                                {
+                                    found = true;
+                                    alloc.machines = *it;
+                                    break;
+                                }
+                            }
+                            if (found == true)
+                            {
+                                //a heldback machine is available, execute the job on it.
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                _e_counter+=1;
+                                executed2 = true;
+                                //update data structures
+                                //the job doesn't get put into the horizons because it is not part of backfilling
+                                alloc.has_horizon = false;
+
+                                machine * current_machine = machines_by_int[alloc.machines[0]];
+                                current_machine->cores_available -=1;
+                                _current_allocations[pending_job_id] = alloc;
+                                _running_jobs.insert(pending_job_id);
+                                 job_it = _pending_jobs.erase(job_it);
+                                 erased = true;
+                                
+                            }
+                        }//end share-packing holdback
+                        //was the job able to be put on a heldback machine?
+                        if (executed2 == false)
+                        {
+                            //no it was not able to be put on a heldback machine, try putting it on a normal share-packing machine.
+                            //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                            for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                            {
+                                //is this machine able to handle another job?
+                                machine* current_machine = machines_by_int[*it];
+                                if (current_machine->cores_available >= 1)
+                                {                                
+                                    //it is able to handle another job, execute a job on it and subtract from cores_available
+                                    alloc.machines = *it;
+                                    
+                                    _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                    executed2 = true;
+                                    _e_counter+=1;
+                                    point.nb_released_machines = pending_job->nb_requested_resources;
+                                    point.date = date + (double)pending_job->walltime;
+                                    point.machines = alloc.machines;
+                                    alloc.horizon_it = insert_horizon_point(point);
+                                    
+                                    //update data structures
+                                    current_machine->cores_available -=1;
+                                    _current_allocations[pending_job_id] = alloc;
+                                    _running_jobs.insert(pending_job_id);
+                                    job_it = _pending_jobs.erase(job_it);
+                                    _p_counter+=1;
+                                    erased = true;
+                                    found = true;
+                                        
+                                }
+                                if (found == true)
+                                    break; 
+                            }  
+                            // there were no available core machines to put it on, try to put on a new core machine
+                            if (found == false && _nb_available_machines > 0)
+                            {
+                        
+                            //LOG_F(INFO,"line 645");
+                                //first get a machine
+                                alloc.machines = _available_machines.left(1);
+                            
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                executed2 = true;
+                                _e_counter+=1;
+                                point.nb_released_machines = pending_job->nb_requested_resources;
+                                point.date = date + (double)pending_job->walltime;
+                                point.machines = alloc.machines;
+                                alloc.horizon_it = insert_horizon_point(point);
+                                //update data structures
+                                machine* current_machine = machines_by_int[alloc.machines[0]];
+                                current_machine->cores_available -= 1;
+                                _available_core_machines += alloc.machines;
+                                _available_machines -= alloc.machines;
+                                _nb_available_machines -= 1;
+                            
+                                _current_allocations[pending_job_id] = alloc;
+                            
+                                _running_jobs.insert(pending_job_id);
+                                
+                                job_it = _pending_jobs.erase(job_it);
+                                _p_counter+=1;
+                                erased = true;
+                            }
+                        }// end not executed     
+
+                    } // end of pending jobs share-packing block
+                
+                    else if (pending_job->nb_requested_resources <= _nb_available_machines)
+                    {
+                    
+                        alloc.machines = _available_machines.left(
+                            pending_job->nb_requested_resources);
+                        _decision->add_execute_job(pending_job->id,
+                            alloc.machines, date);
+                        executed2 = true;
+                        _e_counter+=1;
+                        point.nb_released_machines = pending_job->nb_requested_resources;
+                        point.date = date + (double)pending_job->walltime;
+                        point.machines = alloc.machines;
+                        alloc.horizon_it = insert_horizon_point(point);
+                        //LOG_F(INFO,"line 683");
+
+                        // Update data structures
+                        _available_machines -= alloc.machines;
+                        _nb_available_machines -= pending_job->nb_requested_resources;
+                        _current_allocations[pending_job_id] = alloc;
+                        job_it = _pending_jobs.erase(job_it);
+                        _p_counter+=1;
+                        erased = true;
+                        _running_jobs.insert(pending_job->id);
+                    
+                    }
+                    if (executed2==false)
+                    {
+                        //ok we have a priority job, now stop traversing pending jobs
+                        _priority_job = pending_job;
+                        _priority_job->completion_time = compute_priority_job_expected_earliest_starting_time();
+                        LOG_F(INFO,"line 699");
+                        
+                        job_it = _pending_jobs.erase(job_it);
+                        _p_counter+=1;
+                        //LOG_F(INFO,"line 701");
+                        // Stop first queue traversal.
+                        break;
+                    }
+                    if (!erased)
+                        job_it++;
+                    else
+                        erased = false;
+                }
+            }
+            //now let's backfill jobs that don't hinder priority job
+           bool erased = false;
+           job_it =_pending_jobs.begin();
+            while(job_it!=_pending_jobs.end())
+            {
+                bool execute = false;
+                Job * pending_job = *job_it;
+                Allocation alloc;
+                //LOG_F(INFO,"line 715");
+                std::string pending_job_id = pending_job->id;
+                //can we share-pack it?
+                if (_share_packing && pending_job->nb_requested_resources==1)
+                {
+                        //yes we can share-pack it
+                        //can we use a heldback machine?
+                        bool found = false;
+                        if (_share_packing_holdback > 0)
+                        {
+                            for (auto it = _heldback_machines.elements_begin(); it != _heldback_machines.elements_end(); ++it)
+                            {
+                                machine* current_machine = machines_by_int[*it];
+                                if (current_machine->cores_available >= 1)
+                                {
+                                    found = true;
+                                    alloc.machines = *it;
+                                    break;
+                                }
+                            }
+                            if (found == true)
+                            {
+                                //yes we can use a heldback machine
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                _e_counter+=1;
+                                execute = true;
+                                //update data structures
+                                //the job doesn't get put into the horizons because it is not part of backfilling
+                                alloc.has_horizon = false;
+
+                                machine * current_machine = machines_by_int[alloc.machines[0]];
+                                current_machine->cores_available -=1;
+                                _current_allocations[pending_job_id] = alloc;
+                                _running_jobs.insert(pending_job_id);
+                                 job_it = _pending_jobs.erase(job_it);
+                                 erased = true;
+                                
+                            }
+                        }
+                   if (execute == false)//ok can't backfill on the heldback machines, try the normal machines
+                   {
+                        bool found = false;
+                        //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                        for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                        {
+                            //is this machine able to handle another job?
+                            machine* current_machine = machines_by_int[*it];
+                            //LOG_F(INFO,"line 728");
+                            if (current_machine->cores_available >= 1)
+                            {                                
+                                found = true;
+                                //LOG_F(INFO,"line 731");
+                                if (date + pending_job->walltime <= _priority_job->completion_time)
+                                {
+                                    //it is able to handle another job, execute a job on it and subtract from cores_available
+                                    alloc.machines = *it;
+                                    
+                                    _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                    execute = true;
+                                    _e_counter+=1;
+                                    point.nb_released_machines = pending_job->nb_requested_resources;
+                                    point.date = date + (double)pending_job->walltime;
+                                    point.machines = alloc.machines;
+                                    alloc.horizon_it = insert_horizon_point(point);
+                                    //LOG_F(INFO,"line 744");
+                                    //update data structures
+                                    current_machine->cores_available -=1;
+                                    _current_allocations[pending_job_id] = alloc;
+                                    _running_jobs.insert(pending_job_id);
+                                    job_it = _pending_jobs.erase(job_it);
+                                    _p_counter+=1;
+                                    erased = true;
+                                    
+                                    
+                                }
+                                else
+                                    LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                    date,pending_job->walltime,_priority_job->completion_time);
+                            }
+                            if (found == true)
+                                break; 
+                        }  
+                        // there were no available core machines to put it on, try to put on a new core machine
+                        if (found == false && _nb_available_machines > 0)
+                        {
+                            LOG_F(INFO,"line 760");
+                            if (date + pending_job->walltime <= _priority_job->completion_time)
+                            {
+                                //first get a machine
+                                alloc.machines = _available_machines.left(1);
+                            
+                                _decision->add_execute_job(pending_job_id,alloc.machines,date,mapping);
+                                _e_counter+=1;
+                                execute=true;
+                                point.nb_released_machines = pending_job->nb_requested_resources;
+                                point.date = date + (double)pending_job->walltime;
+                                point.machines = alloc.machines;
+                                alloc.horizon_it = insert_horizon_point(point);
+                                //update data structures
+                                machine* current_machine = machines_by_int[alloc.machines[0]];
+                                current_machine->cores_available -= 1;
+                                _available_core_machines += alloc.machines;
+                                _available_machines -= alloc.machines;
+                                _nb_available_machines -= 1;
+                            //LOG_F(INFO,"line 778");
+                                _current_allocations[pending_job_id] = alloc;
+                            
+                                _running_jobs.insert(pending_job_id);
+                                
+                                job_it = _pending_jobs.erase(job_it);
+                                _p_counter+=1;
+                                erased = true;
+                            }
+                            else
+                                LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                    date,pending_job->walltime,_priority_job->completion_time);
+                        }
+                    }// end of not executed 
+                }// end of backfilling jobs share-packing block
+                else if (pending_job->nb_requested_resources <= _nb_available_machines &&
+                        date + pending_job->walltime <= _priority_job->completion_time)
+                {
+                    // Yes, it can be backfilled!
+                    //LOG_F(INFO,"line 791");
+                    alloc.machines = _available_machines.left(
+                        pending_job->nb_requested_resources);
+                    _decision->add_execute_job(pending_job->id,
+                        alloc.machines, date);
+                    _e_counter+=1;
+                    execute = true;
+                    point.nb_released_machines = pending_job->nb_requested_resources;
+                    point.date = date + (double)pending_job->walltime;
+                    point.machines = alloc.machines;
+                    //LOG_F(INFO,"line 804");
+                    alloc.horizon_it = insert_horizon_point(point);
+                    //LOG_F(INFO,"line 806");
+                    // Update data structures
+                    _available_machines -= alloc.machines;
+                    _nb_available_machines -= pending_job->nb_requested_resources;
+                    _current_allocations[pending_job->id] = alloc;
+                    //LOG_F(INFO,"line 811");
+                    _running_jobs.insert(pending_job_id);
+                    job_it = _pending_jobs.erase(job_it);
+                    _p_counter+=1;
+                    //LOG_F(INFO,"line 814");
+                    erased = true;
+                }
+                else{
+                    LOG_F(INFO,"date %f walltime %f completion_time %f",
+                                 date,pending_job->walltime,_priority_job->completion_time);
+                }
+                if (erased==false)
+                    job_it++;
+                else
+                   erased = false;
+            }
+        }
+    }
+}
+
+/*************************************************
+ * 
+ *              Newly Released Jobs
+ * 
+ **************************************************/
+
+void easy_bf_fast2_holdback::handle_newly_released_jobs(double date)
+{
+    int counter = 0;
+    int pending = 0;
+    std::vector<int> mapping = {0};
+    // Handle newly released jobs
+    for (const std::string & new_job_id : _jobs_released_recently)
+    {
+        Job * new_job = (*_workload)[new_job_id];
+
+        // Is this job valid?
+        if (new_job->nb_requested_resources > (_nb_machines-_share_packing_holdback))
+        {
+            // Invalid!
+            //LOG_F(INFO,"Job being rejected HERE %s",new_job_id.c_str());
+            _decision->add_reject_job(new_job_id, date);
+            continue;
+        }
+        Allocation alloc;
+        bool executed = false;
+        //Are we share-packing?
+        if (_share_packing && new_job->nb_requested_resources == 1)
+        {
+            //Can the job be executed right now?
+            //first check _heldback_machines, if there are any
+            bool found = false;
+            if (_share_packing_holdback > 0)
+            {
+                for (auto it = _heldback_machines.elements_begin(); it != _heldback_machines.elements_end(); ++it)
+                {
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {
+                        found = true;
+                        alloc.machines = *it;
+                        break;
+                    }
+                }
+                if (found == true)
+                {
+                    _decision->add_execute_job(new_job_id,alloc.machines,date,mapping);
+                    _e_counter+=1;
+                    executed = true;
+                    //update data structures
+                    //the job doesn't get put into the horizons because it is not part of backfilling
+                    alloc.has_horizon = false;
+
+                    machine * current_machine = machines_by_int[alloc.machines[0]];
+                    current_machine->cores_available -=1;
+                    _current_allocations[new_job_id] = alloc;
+                    _running_jobs.insert(new_job_id);
+                     
+                }
+            }
+            //then check all core machines running right now
+            //if not executed on heldback machines
+            if (executed == false)
+            {
+            
+                for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                {
+                    //is this machine able to handle another job?
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {                                
+                        //it is able to handle another job
+                        found = true;
+                        alloc.machines = *it;
+                        break;
+                    }
+                                    
+                }
+                if (found == true)
+                {
+                    if(_priority_job == nullptr ||
+                            date + new_job->walltime<= _priority_job->completion_time)
+                    {
+                        //yes it can be executed right away
+                        _decision->add_execute_job(new_job_id,alloc.machines,date,mapping);
+                        _e_counter+=1;
+                        executed = true;
+                        //update data structures
+                        FinishedHorizonPoint point;
+                        point.nb_released_machines = new_job->nb_requested_resources;
+                        point.date = date + (double)new_job->walltime;
+                        point.machines = alloc.machines;
+                        alloc.horizon_it = insert_horizon_point(point);
+
+                        machine * current_machine = machines_by_int[alloc.machines[0]];
+                        current_machine->cores_available -=1;
+                        _current_allocations[new_job_id] = alloc;
+                        _running_jobs.insert(new_job_id);
+                        
+                    }
+                }
+                if (found == false && _nb_available_machines > 0)
+                {
+                        
+                    //Can the job be executed without hindering priority job?
+                    if(_priority_job == nullptr ||
+                        date + new_job->walltime<= _priority_job->completion_time)
+                    {
+                        //yes it can
+                        //first get a machine
+                        alloc.machines = _available_machines.left(1);
+                        _decision->add_execute_job(new_job_id,alloc.machines,date,mapping);
+                        _e_counter+=1;
+                        executed = true;
+                        FinishedHorizonPoint point;
+                        point.nb_released_machines = new_job->nb_requested_resources;
+                        point.date = date + (double) new_job->walltime;
+                        point.machines = alloc.machines;
+                        alloc.horizon_it = insert_horizon_point(point);
+
+
+                        //update data structures
+                        machine* current_machine = machines_by_int[alloc.machines[0]];
+                        current_machine->cores_available -= 1;
+                        _available_core_machines += alloc.machines;
+                        _available_machines -= alloc.machines;
+                        _nb_available_machines -= 1;
+                        
+                        _current_allocations[new_job_id] = alloc;
+                        
+                        _running_jobs.insert(new_job_id);
+                        
+                                                    
+                    }
+
+                }
+            }   
+
+        }//end share-packing block
+        //we are not share-packing or the number of resources != 1
+        else if (new_job->nb_requested_resources <=_nb_available_machines)
+        {
+            if (_priority_job == nullptr ||
+                date + new_job->walltime <= _priority_job->completion_time)
+            {
+                alloc.machines = _available_machines.left(
+                    new_job->nb_requested_resources);
+                _decision->add_execute_job(new_job_id, alloc.machines, date);
+                _e_counter+=1;
+                executed = true;
+
+                FinishedHorizonPoint point;
+                point.nb_released_machines = new_job->nb_requested_resources;
+                point.date = date + (double)new_job->walltime;
+                point.machines = alloc.machines;
+                alloc.horizon_it = insert_horizon_point(point);
+
+                // Update data structures
+                _available_machines -= alloc.machines;
+                _nb_available_machines -= new_job->nb_requested_resources;
+                _current_allocations[new_job_id] = alloc;
+                _running_jobs.insert(new_job_id);
+            }
+        }
+        if (executed==false)
+        {
+             
+            if (_priority_job == nullptr)
+            {
+                //if this job is a 1 resource job then the completion time really doesn't matter
+                //as nothing can really be backfilled, so it doesn't matter if the completion time
+                //is computed from heldback machines or normal machines.  we compute it here from normal machines
+                //regardless of number of resources.
+                    _priority_job = new_job;
+                    _priority_job->completion_time = compute_priority_job_expected_earliest_starting_time();
+                
+            }
+            // submitted job is a resubmitted one, put at front of pending jobs
+            else if(new_job_id.find("#")!=std::string::npos)
+                _pending_jobs.push_front(new_job);
+                
+            else
+                _pending_jobs.push_back(new_job);
+                
+        }
+    }//end released jobs loop
+    LOG_F(INFO,"pending_jobs size %d",_pending_jobs.size());
+}
+
+        
+
+
+
+void easy_bf_fast2_holdback::handle_resubmission(double date)
+{
+ for(const auto & killed_map:_jobs_killed_recently)
+    {
+        std::string killed_job=killed_map.first;
+        double progress = killed_map.second->progress;
+        //LOG_F(INFO,"REPAIR  progress: %f",progress);
+        auto start = killed_job.find("!")+1;
+        auto end = killed_job.find("#");
+        std::string basename = (end ==std::string::npos) ? killed_job.substr(start) : killed_job.substr(start,end-start); 
+        
+        const std::string workload_str = killed_job.substr(0,start-1); 
+        //get the workload
+        myB::Workload * w0= (*_myWorkloads)[workload_str];
+        //get the conversion from seconds to cpu instructions
+        double one_second = w0->_host_speed;
+        //get the job that was killed
+        myB::JobPtr job_to_queue =(*(w0->jobs))[myB::JobIdentifier(killed_job)];
+        //get the job identifier of the job that was killed
+        myB::JobIdentifier ji = job_to_queue->id;
+        
+        std::string profile_jd=job_to_queue->profile->json_description;
+        std::string job_jd=job_to_queue->json_description;
+        r::Document profile_doc;
+        profile_doc.Parse(profile_jd.c_str());
+        r::Document doc;
+        doc.Parse(job_jd.c_str());
+        
+        if (job_to_queue->profile->type == myB::ProfileType::DELAY )
+        {
+            if (_checkpointing_on)
+            {
+                double progress_time = 0;
+                if (progress > 0)
+                {
+                    
+                    
+                    progress_time =progress * profile_doc["delay"].GetDouble();
+                    //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                    
+                    bool has_checkpointed = false;
+                    std::string meta_str = "null";
+                    int num_checkpoints_completed = 0;
+                    r::Document meta_doc;
+                    //check whether there is a checkpointed value and set has_checkpointed if so
+                    if (doc.HasMember("metadata"))
+                    {
+                        
+                        meta_str = doc["metadata"].GetString();
+                        std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                        meta_doc.Parse(meta_str.c_str());
+                        if (meta_doc.HasMember("checkpointed"))
+                        {
+                            has_checkpointed = meta_doc["checkpointed"].GetBool();
+                            
+                        }
+                    }
+                    //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                    if (has_checkpointed)
+                    {
+                        
+                        //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                        num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                        if (meta_doc.HasMember("work_progress"))
+                        {
+                            double work = meta_doc["work_progress"].GetDouble();
+                            if (num_checkpoints_completed > 0)
+                                work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                            meta_doc["work_progress"] = work;
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                        }
+                        if (meta_doc.HasMember("num_dumps"))
+                        {
+                                int num_dumps = meta_doc["num_dumps"].GetInt();
+                                if (num_checkpoints_completed > 0)
+                                    num_dumps += num_checkpoints_completed;
+                                meta_doc["num_dumps"] = num_dumps;
+                                
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            
+                        }
+                        std::string meta_str = to_json_desc(&meta_doc);
+                        doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                        // the progress_time needs to add back in the read_time
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                    
+                    }
+                    else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                    {
+                        num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                        
+                        
+                        //if a checkpoint has completed set the metadata to reflect this
+                        if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.SetObject();
+                            //if there was previous metadata make sure to include it
+                            if (meta_str!="null")
+                            {
+                                meta_doc.Parse(meta_str.c_str());
+                            }    
+                            r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                            meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                            meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                            std::string myString = to_json_desc(&meta_doc);
+                            r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                
+                            if (meta_str=="null")
+                                doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                            else
+                                doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                        }
+        
+                    }        
+                    //only if a new checkpoint has been reached does the delay time change
+                    //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                    if (num_checkpoints_completed > 0)
+                    {
+                        
+                        double delay = profile_doc["delay"].GetDouble() - progress_time + job_to_queue->read_time;
+                        //LOG_F(INFO,"REPAIR delay: %f  readtime: %f",delay,job_to_queue->read_time);
+                        profile_doc["delay"].SetDouble(delay);
+                        
+                        
+                    }
+                }
+            
+            }
+                                          
+                    
+        }
+    
+        if (job_to_queue->profile->type == myB::ProfileType::PARALLEL_HOMOGENEOUS)
+        {
+            if (_checkpointing_on)
+                {
+                    double progress_time = 0;
+                    if (progress > 0)
+                    {
+                        
+                        
+                        progress_time =(progress * profile_doc["cpu"].GetDouble())/one_second;
+                        //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                        //LOG_F(INFO,"profile_doc[cpu]: %f    , one_second: %f",profile_doc["cpu"].GetDouble(),one_second);
+                        
+                        bool has_checkpointed = false;
+                        std::string meta_str = "null";
+                        int num_checkpoints_completed = 0;
+                        r::Document meta_doc;
+                        //check whether there is a checkpointed value and set has_checkpointed if so
+                        if (doc.HasMember("metadata"))
+                        {
+                            
+                            meta_str = doc["metadata"].GetString();
+                            std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                            meta_doc.Parse(meta_str.c_str());
+                            if (meta_doc.HasMember("checkpointed"))
+                            {
+                                has_checkpointed = meta_doc["checkpointed"].GetBool();
+                                
+                            }
+                        }
+                        //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                        if (has_checkpointed)
+                        {
+                            
+                            //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                            num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                            if (meta_doc.HasMember("work_progress"))
+                            {
+                                double work = meta_doc["work_progress"].GetDouble();
+                                if (num_checkpoints_completed > 0)
+                                    work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                                work = work * one_second;
+                                meta_doc["work_progress"] = work;
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval*one_second),meta_doc.GetAllocator());
+                            }
+                            if (meta_doc.HasMember("num_dumps"))
+                            {
+                                    int num_dumps = meta_doc["num_dumps"].GetInt();
+                                    if (num_checkpoints_completed > 0)
+                                        num_dumps += num_checkpoints_completed;
+                                    meta_doc["num_dumps"] = num_dumps;
+                                    
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                    meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                
+                            }
+                            std::string meta_str = to_json_desc(&meta_doc);
+                            doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                            // the progress_time needs to add back in the read_time
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                        
+                        }
+                        else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                        {
+                            num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                            
+                            
+                            //if a checkpoint has completed set the metadata to reflect this
+                            if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.SetObject();
+                                //if there was previous metadata make sure to include it
+                                if (meta_str!="null")
+                                {
+                                    meta_doc.Parse(meta_str.c_str());
+                                }    
+                                r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                                meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval * one_second),meta_doc.GetAllocator());
+                                std::string myString = to_json_desc(&meta_doc);
+                                r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                    
+                                if (meta_str=="null")
+                                    doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                                else
+                                    doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                            }
+            
+                        }        
+                        //only if a new checkpoint has been reached does the delay time change
+                        //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                        if (num_checkpoints_completed > 0)
+                        {
+                            double cpu = profile_doc["cpu"].GetDouble();
+                            double cpu_time = cpu / one_second;
+                            cpu_time = cpu_time - progress_time + job_to_queue->read_time;
+                            //LOG_F(INFO,"REPAIR cpu_time: %f  readtime: %f",cpu_time,job_to_queue->read_time);
+                            profile_doc["cpu"].SetDouble(cpu_time*one_second);
+                            
+                            
+                        }
+                    }
+                
+                }
+        }
+
+
+        doc["subtime"]=date;
+                
+        //check if resubmitted and get the next resubmission number
+        int resubmit = 1;
+        if (end!=std::string::npos) //if job name has # in it...was resubmitted b4
+        {
+            resubmit = std::stoi(killed_job.substr(end+1));   // then get the resubmitted number
+            resubmit++; // and add 1 to it
+        }
+        std::string resubmit_str = std::to_string(resubmit);
+        
+        
+        std::string profile_name = basename + "#" + resubmit_str;
+        std::string job_name = basename + "#" + resubmit_str;
+        std::string job_id = workload_str+"!" + basename + "#" + resubmit_str;
+        std::string workload_name = workload_str;
+        doc["profile"].SetString(profile_name.data(), profile_name.size(), doc.GetAllocator());
+        doc["id"].SetString(job_id.data(),job_id.size(),doc.GetAllocator());
+        std::string error_prefix = "Invalid JSON job '" + killed_job + "'";
+        profile_jd = to_json_desc(&profile_doc);
+        myB::ProfilePtr p = myB::Profile::from_json(profile_name,profile_jd);
+        w0->profiles->add_profile(p);
+        myB::JobPtr j = myB::Job::from_json(doc,w0,error_prefix);
+        w0->jobs->add_job(j);
+        job_jd = to_json_desc(&doc);
+        //LOG_F(INFO,"workload: %s  job: %s, profile: %s",workload_name.c_str(),job_name.c_str(),profile_name.c_str());
+        _decision->add_submit_profile(workload_name,
+                                    profile_name,
+                                    profile_jd,
+                                    date);
+                                    
+        _decision->add_submit_job(workload_name,
+                                    job_name,
+                                    profile_name,
+                                    job_jd,
+                                    profile_jd,
+                                    date,
+                                    true);
+        if (doc.HasMember("metadata"))
+        {
+            std::string meta = doc["metadata"].GetString();
+            //must replace double quotes with single quotes.  Remember to
+            //replace single quotes with double quotes before parsing metadata
+            std::replace( meta.begin(), meta.end(), '\"', '\'');
+        _decision->add_set_job_metadata(job_id,
+                                        meta,
+                                        date);
+        }                               
+    }            
+    
+       
+}
+
+std::list<easy_bf_fast2_holdback::FinishedHorizonPoint>::iterator easy_bf_fast2_holdback::insert_horizon_point(const easy_bf_fast2_holdback::FinishedHorizonPoint &point)
+{
+    // The data structure is sorted, we can therefore traverse it in order
+    // until finding an insertion point.
+    for (auto it = _horizons.begin(); it != _horizons.end(); ++it)
+    {
+        if (point.date < it->date)
+        {
+            // Insertion point is before the current iterator.
+            return _horizons.insert(it, point);
+        }
+    }
+
+    // Insertion point not found. Insertion at end.
+    return _horizons.insert(_horizons.end(), point);
+}
+
+double easy_bf_fast2_holdback::compute_priority_job_expected_earliest_starting_time()
+{
+    int nb_available = _nb_available_machines;
+    int required = _priority_job->nb_requested_resources;
+    //LOG_F(INFO,"line 1294");
+    //make a shallow copy of machines_by_int if share-packing
+    std::map<int,machine *> machines_by_int_copy;
+    if (_share_packing)
+    {
+        for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+            {
+                machine* current_machine = machines_by_int[*it];
+                machine* a_machine = new machine();
+                //all we need to copy are cores_available and core_count
+                a_machine->cores_available = current_machine->cores_available;
+                a_machine->core_count = current_machine->core_count;
+                machines_by_int_copy[*it]=a_machine;
+            }
+
+    }   
+         //LOG_F(INFO,"line 1310");   
+
+    for (auto it = _horizons.begin(); it != _horizons.end(); ++it)
+    {
+        //is this the case that a single core is being released?
+        if (_share_packing && it->nb_released_machines == 1)
+        {
+            //LOG_F(INFO,"line 1324");
+            //ok a single core is released
+            //is that all we needed for the priority_job (unlikely for a priority job but not out of the question)
+            if (required == 1)
+                return it->date;
+            //ok that isn't all we needed, let's keep track of these released cores on each machine
+            int machine_number = it->machines[0];
+            machine * current_machine = machines_by_int_copy[machine_number];
+            current_machine->cores_available +=1;
+            //ok so we added a core to the released machine
+            //does this bring a whole machine available?
+            //LOG_F(INFO,"line 1335");
+            if (current_machine->cores_available == int(current_machine->core_count * _core_percent))
+                {
+                    //yes it did make a whole machine available
+                    nb_available += 1;
+                }
+        }
+        //we are not doing share-packing or more than a single core was released
+        else 
+            nb_available += it->nb_released_machines;
+        //do we now have enough full machines to run the priority job?
+        if (nb_available >= required)
+        {
+            //yes we do, return the time that this will occur
+            return it->date;
+        }
+    }
+
+    PPK_ASSERT_ERROR(false, "The job will never be executable.");
+    return 0;
+}
+/*(Document, Swap) {
+    Document d1;
+    Document::AllocatorType& a = d1.GetAllocator();
+
+    d1.SetArray().PushBack(1, a).PushBack(2, a);
+
+    Value o;
+    o.SetObject().AddMember("a", 1, a);
+
+    // Swap between Document and Value
+    d1.Swap(o);
+*/
diff -burN '--exclude=.git*' ./batsched/src/algo/easy_bf_fast2_holdback.hpp ./new_batsched/src/algo/easy_bf_fast2_holdback.hpp
--- ./batsched/src/algo/easy_bf_fast2_holdback.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/easy_bf_fast2_holdback.hpp	2023-06-28 08:26:02.127166524 -0400
@@ -0,0 +1,137 @@
+#pragma once
+
+#include <unordered_map>
+
+#include <unordered_set>
+#include <list>
+#include <random>
+
+#include "../isalgorithm.hpp"
+#include "../json_workload.hpp"
+#include "../locality.hpp"
+#include "../external/batsched_workload.hpp"
+#include <rapidjson/document.h>
+#include "../batsched_tools.hpp"
+
+class easy_bf_fast2_holdback : public ISchedulingAlgorithm
+{
+public:
+    
+
+    easy_bf_fast2_holdback(Workload * workload, SchedulingDecision * decision,
+        Queue * queue, ResourceSelector * selector,
+        double rjms_delay,
+        rapidjson::Document * variant_options);
+    virtual ~easy_bf_fast2_holdback();
+
+    virtual void on_simulation_start(double date,
+        const rapidjson::Value & batsim_event);
+
+    virtual void on_simulation_end(double date);
+    //virtual void on_machine_unavailable_notify_event(double date, IntervalSet machines);
+    virtual void on_machine_available_notify_event(double date, IntervalSet machines);
+    //virtual void on_job_fault_notify_event(double date, std::string job);
+    virtual void on_myKillJob_notify_event(double date);
+    virtual void on_requested_call(double date,int id,  batsched_tools::call_me_later_types forWhat);
+    virtual void set_workloads(myBatsched::Workloads * w);
+    virtual void make_decisions(double date,
+        SortableJobOrder::UpdateInformation * update_info,
+        SortableJobOrder::CompareInformation * compare_info);
+    std::string to_json_desc(rapidjson::Document *doc);
+    void on_machine_instant_down_up(double date);
+    void on_machine_down_for_repair(double date);
+    virtual void on_no_more_external_event_to_occur(double date);
+    virtual void on_job_end(double date, std::vector<std::string> job_ids);
+    virtual void on_machine_state_changed(double date, IntervalSet machines, int new_state);
+    virtual void on_no_more_static_job_to_submit_received(double date);
+
+private:
+    //Normal maintenance functions
+    bool handle_newly_finished_jobs();
+        
+    void handle_new_jobs_to_kill(double date);
+    //************************************************************resubmission if killed
+    //Handle jobs to queue back up (if killed)  
+    void handle_resubmission(double date);    
+    //***********************************************************
+    
+    void handle_machines_coming_available(double date);
+    void handle_ended_job_execution(bool job_ended,double date);
+    void handle_newly_released_jobs(double date);
+
+    //backfilling
+    struct FinishedHorizonPoint
+    {
+        double date;
+        int nb_released_machines;
+        IntervalSet machines; //used if share-packing
+    };
+
+    struct Allocation
+    {
+        IntervalSet machines;
+        std::list<FinishedHorizonPoint>::iterator horizon_it;
+        bool has_horizon = true;
+    };
+
+
+private:
+    // Machines currently available
+    IntervalSet _available_machines;
+    IntervalSet _unavailable_machines;
+    IntervalSet _repair_machines;
+    IntervalSet _available_core_machines;
+   
+    int _nb_available_machines = -1;
+
+    // Pending jobs (queue)
+    std::list<Job *> _pending_jobs;
+    std::list<Job *> _pending_jobs_heldback;
+    std::map<Job *,batsched_tools::Job_Message *> _my_kill_jobs;
+    std::unordered_set<std::string> _running_jobs;
+    myBatsched::Workloads * _myWorkloads;
+    double _oldDate=-1;
+    int _killed=0;
+    bool _wrap_it_up = false;
+    bool _need_to_send_finished_submitting_jobs = true;
+    bool _checkpointing_on=false;
+    std::vector<double> _call_me_laters;
+    std::mt19937 generator;
+    std::exponential_distribution<double> * distribution;
+    std::mt19937 generator2;
+    std::uniform_int_distribution<int> * unif_distribution;
+    std::string _output_folder;
+        
+    struct machine{
+        int id;
+        std::string name;
+        int core_count = -1;
+        int cores_available;
+        double speed;
+    };
+    bool _share_packing = false;
+    double _core_percent = 1.0;
+    std::map<int,machine *> machines_by_int;
+    std::map<std::string,machine *> machines_by_name;
+    
+
+    // Allocations of running jobs
+    //std::unordered_map<std::string, IntervalSet> _current_allocations;
+
+    //backfilling
+    double compute_priority_job_expected_earliest_starting_time();
+
+    std::list<FinishedHorizonPoint>::iterator insert_horizon_point(const FinishedHorizonPoint & point);
+
+    std::unordered_map<std::string, Allocation> _current_allocations;
+    std::list<FinishedHorizonPoint> _horizons;
+    Job * _priority_job = nullptr;
+    
+    
+    int _p_counter = 0; //pending jobs erased counter
+    int _e_counter = 0; //execute job counter
+    b_log *_myBLOG;
+    int _share_packing_holdback = 0;
+    IntervalSet _heldback_machines;
+
+};
diff -burN '--exclude=.git*' ./batsched/src/algo/easy_bf_fast2.hpp ./new_batsched/src/algo/easy_bf_fast2.hpp
--- ./batsched/src/algo/easy_bf_fast2.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/easy_bf_fast2.hpp	2023-06-28 08:26:02.127166524 -0400
@@ -0,0 +1,132 @@
+#pragma once
+
+#include <unordered_map>
+
+#include <unordered_set>
+#include <list>
+#include <random>
+
+#include "../isalgorithm.hpp"
+#include "../json_workload.hpp"
+#include "../locality.hpp"
+#include "../external/batsched_workload.hpp"
+#include <rapidjson/document.h>
+#include "../batsched_tools.hpp"
+
+class easy_bf_fast2 : public ISchedulingAlgorithm
+{
+public:
+    
+
+    easy_bf_fast2(Workload * workload, SchedulingDecision * decision,
+        Queue * queue, ResourceSelector * selector,
+        double rjms_delay,
+        rapidjson::Document * variant_options);
+    virtual ~easy_bf_fast2();
+
+    virtual void on_simulation_start(double date,
+        const rapidjson::Value & batsim_event);
+
+    virtual void on_simulation_end(double date);
+    //virtual void on_machine_unavailable_notify_event(double date, IntervalSet machines);
+    virtual void on_machine_available_notify_event(double date, IntervalSet machines);
+    //virtual void on_job_fault_notify_event(double date, std::string job);
+    virtual void on_myKillJob_notify_event(double date);
+    virtual void on_requested_call(double date,int id,  batsched_tools::call_me_later_types forWhat);
+    virtual void set_workloads(myBatsched::Workloads * w);
+    virtual void make_decisions(double date,
+        SortableJobOrder::UpdateInformation * update_info,
+        SortableJobOrder::CompareInformation * compare_info);
+    std::string to_json_desc(rapidjson::Document *doc);
+    void on_machine_instant_down_up(double date);
+    void on_machine_down_for_repair(double date);
+    virtual void on_no_more_external_event_to_occur(double date);
+    virtual void on_job_end(double date, std::vector<std::string> job_ids);
+    virtual void on_machine_state_changed(double date, IntervalSet machines, int new_state);
+    virtual void on_no_more_static_job_to_submit_received(double date);
+
+private:
+    //Normal maintenance functions
+    bool handle_newly_finished_jobs();
+        
+    void handle_new_jobs_to_kill(double date);
+    //************************************************************resubmission if killed
+    //Handle jobs to queue back up (if killed)  
+    void handle_resubmission(double date);    
+    //***********************************************************
+    
+    void handle_machines_coming_available(double date);
+    void handle_ended_job_execution(bool job_ended,double date);
+    void handle_newly_released_jobs(double date);
+
+    //backfilling
+    struct FinishedHorizonPoint
+    {
+        double date;
+        int nb_released_machines;
+        IntervalSet machines; //used if share-packing
+    };
+
+    struct Allocation
+    {
+        IntervalSet machines;
+        std::list<FinishedHorizonPoint>::iterator horizon_it;
+    };
+
+
+private:
+    // Machines currently available
+    IntervalSet _available_machines;
+    IntervalSet _unavailable_machines;
+    IntervalSet _repair_machines;
+    IntervalSet _available_core_machines;
+   
+    int _nb_available_machines = -1;
+
+    // Pending jobs (queue)
+    std::list<Job *> _pending_jobs;
+    std::map<Job *,batsched_tools::Job_Message *> _my_kill_jobs;
+    std::unordered_set<std::string> _running_jobs;
+    myBatsched::Workloads * _myWorkloads;
+    double _oldDate=-1;
+    int _killed=0;
+    bool _wrap_it_up = false;
+    bool _need_to_send_finished_submitting_jobs = true;
+    bool _checkpointing_on=false;
+    std::vector<double> _call_me_laters;
+    std::mt19937 generator;
+    std::exponential_distribution<double> * distribution;
+    std::mt19937 generator2;
+    std::uniform_int_distribution<int> * unif_distribution;
+    std::string _output_folder;
+        
+    struct machine{
+        int id;
+        std::string name;
+        int core_count = -1;
+        int cores_available;
+        double speed;
+    };
+    bool _share_packing = false;
+    double _core_percent = 1.0;
+    std::map<int,machine *> machines_by_int;
+    std::map<std::string,machine *> machines_by_name;
+    const std::string SEQUENTIAL = "sequential";
+    const std::string PARALLEL = "parallel";
+
+    // Allocations of running jobs
+    //std::unordered_map<std::string, IntervalSet> _current_allocations;
+
+    //backfilling
+    double compute_priority_job_expected_earliest_starting_time();
+
+    std::list<FinishedHorizonPoint>::iterator insert_horizon_point(const FinishedHorizonPoint & point);
+
+    std::unordered_map<std::string, Allocation> _current_allocations;
+    std::list<FinishedHorizonPoint> _horizons;
+    Job * _priority_job = nullptr;
+    int _p_counter = 0; //pending jobs erased counter
+    int _e_counter = 0; //execute job counter
+    b_log *_myBLOG;
+
+};
diff -burN '--exclude=.git*' ./batsched/src/algo/fcfs_fast2.cpp ./new_batsched/src/algo/fcfs_fast2.cpp
--- ./batsched/src/algo/fcfs_fast2.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/fcfs_fast2.cpp	2023-06-28 08:26:02.130499916 -0400
@@ -0,0 +1,1059 @@
+#include <math.h>
+#include "fcfs_fast2.hpp"
+
+#include "../pempek_assert.hpp"
+
+#include <loguru.hpp>
+#include "../external/batsched_workload.hpp"
+#include "../external/batsched_job.hpp"
+#include "../external/batsched_profile.hpp"
+#include "../external/pointers.hpp"
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <chrono>
+#include <utility>
+#include "../batsched_tools.hpp"
+
+
+#define B_LOG_INSTANCE _myBLOG
+namespace myB = myBatsched;
+namespace r = rapidjson;
+const int DEBUG = 10;
+FCFSFast2::FCFSFast2(Workload *workload,
+    SchedulingDecision *decision, Queue *queue, ResourceSelector *selector,
+    double rjms_delay, rapidjson::Document *variant_options) :
+    ISchedulingAlgorithm(workload, decision, queue, selector, rjms_delay,
+        variant_options)
+{
+    //LOG_F(INFO,"created 4");
+    _myWorkloads = new myBatsched::Workloads;
+    //batsim log object.  declared in batsched_tools.hpp
+    _myBLOG = new b_log();
+    
+    
+}
+
+FCFSFast2::~FCFSFast2()
+{
+    
+}
+
+void FCFSFast2::on_simulation_start(double date,
+    const rapidjson::Value &batsim_event_data)
+{
+    LOG_F(INFO,"On simulation start");
+    bool seedFailures = false;
+    bool logBLog = false;
+    const rapidjson::Value & batsim_config = batsim_event_data["config"];
+    if (batsim_config.HasMember("share-packing"))
+        _share_packing = batsim_config["share-packing"].GetBool();
+
+    if (batsim_config.HasMember("core-percent"))
+        _core_percent = batsim_config["core-percent"].GetDouble();
+
+    if (batsim_config.HasMember("output-folder")){
+        _output_folder = batsim_config["output-folder"].GetString();
+        _output_folder=_output_folder.substr(0,_output_folder.find_last_of("/"));
+    }
+    
+    if (batsim_config.HasMember("seed-failures"))
+        seedFailures = batsim_config["seed-failures"].GetBool();
+    if (batsim_config.HasMember("log_b_log"))
+        logBLog = batsim_config["log_b_log"].GetBool();
+    //log BLogs, add log files that you want logged to.
+    if (logBLog){
+        _myBLOG->add_log_file(_output_folder+"/log/failures.log",b_log::FAILURES);
+    }
+    unsigned seed = 0;
+    if (seedFailures)
+        seed = std::chrono::system_clock::now().time_since_epoch().count();
+         
+    generator.seed(seed);
+    generator2.seed(seed);
+    _available_machines.insert(IntervalSet::ClosedInterval(0, _nb_machines - 1));
+    LOG_F(INFO,"_available_machines %d",_available_machines.size());
+    _nb_available_machines = _nb_machines;
+    //LOG_F(INFO,"avail: %d   nb_machines: %d",_available_machines.size(),_nb_machines);
+    PPK_ASSERT_ERROR(_available_machines.size() == (unsigned int) _nb_machines);
+    const rapidjson::Value& resources = batsim_event_data["compute_resources"];
+    for ( auto & itr : resources.GetArray())
+    {
+	machine* a_machine = new machine();
+        if (itr.HasMember("id"))
+            a_machine->id = (itr)["id"].GetInt();
+        if (itr.HasMember("core_count"))
+        {
+            a_machine->core_count = (itr)["core_count"].GetInt();
+            a_machine->cores_available = int(a_machine->core_count * _core_percent);
+        }
+        if (itr.HasMember("speed"))
+            a_machine->speed = (itr)["speed"].GetDouble();
+        if (itr.HasMember("name"))
+            a_machine->name = (itr)["name"].GetString();
+        machines_by_int[a_machine->id] = a_machine;
+        machines_by_name[a_machine->name] = a_machine;
+        //LOG_F(INFO,"machine id = %d, core_count= %d , cores_available= %d",a_machine->id,a_machine->core_count,a_machine->cores_available);
+   }
+     _oldDate=date;
+     if (_myWorkloads->_fixed_failures != -1.0)
+     {
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        double number = _myWorkloads->_fixed_failures;
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);  
+     }
+    if (_myWorkloads->_SMTBF != -1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_SMTBF);
+        if (unif_distribution == nullptr)
+            unif_distribution = new std::uniform_int_distribution<int>(0,_nb_machines-1);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_SMTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+    }
+    else if (_myWorkloads->_MTBF!=-1.0)
+    {
+        distribution = new std::exponential_distribution<double>(1.0/_myWorkloads->_MTBF);
+        std::exponential_distribution<double>::param_type new_lambda(1.0/_myWorkloads->_MTBF);
+        distribution->param(new_lambda);
+        double number;         
+        number = distribution->operator()(generator);
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+    }
+}      
+void FCFSFast2::on_simulation_end(double date){
+    (void) date;
+}
+    
+ /*void FCFSFast2::on_machine_unavailable_notify_event(double date, IntervalSet machines){
+    //LOG_F(INFO,"unavailable %s",machines.to_string_hyphen().c_str());
+    _unavailable_machines+=machines;
+    _available_machines-=machines;
+    for(auto key_value : _current_allocations)
+    {
+            if (!((key_value.second & machines).is_empty()))
+                _decision->add_kill_job({key_value.first},date);
+    }
+    
+}
+*/
+void FCFSFast2::set_workloads(myBatsched::Workloads *w){
+    _myWorkloads = w;
+    _checkpointing_on = w->_checkpointing_on;
+    
+}
+void FCFSFast2::on_machine_available_notify_event(double date, IntervalSet machines){
+    ISchedulingAlgorithm::on_machine_available_notify_event(date, machines);
+    _unavailable_machines-=machines;
+    _available_machines+=machines;
+    _nb_available_machines+=machines.size();
+    
+}
+
+void FCFSFast2::on_machine_state_changed(double date, IntervalSet machines, int new_state)
+{
+   
+
+}
+void FCFSFast2::on_myKillJob_notify_event(double date){
+    
+    if (!_running_jobs.empty()){
+        batsched_tools::Job_Message * msg = new batsched_tools::Job_Message;
+        msg->id = *_running_jobs.begin();
+        msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+        _my_kill_jobs.insert(std::make_pair((*_workload)[*_running_jobs.begin()], msg));
+    }
+        
+    
+}
+
+
+
+void FCFSFast2::on_machine_down_for_repair(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    //if the machine is already down for repairs ignore it.
+    //LOG_F(INFO,"repair_machines.size(): %d    nb_avail: %d  avail:%d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+    BLOG_F(b_log::FAILURES,"Machine Repair: %d",number);
+    if ((machine & _repair_machines).is_empty())
+    {
+        //ok the machine is not down for repairs
+        //it will be going down for repairs now
+        _available_machines-=machine;
+        _unavailable_machines+=machine;
+        _repair_machines+=machine;
+        _nb_available_machines=_available_machines.size();
+
+        double repair_time = _myWorkloads->_repair_time;
+        //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d  avail: %d running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+        //LOG_F(INFO,"date: %f , repair: %f ,repair + date: %f",date,repair_time,date+repair_time);
+        //call me back when the repair is done
+        _decision->add_call_me_later(batsched_tools::call_me_later_types::REPAIR_DONE,number,date+repair_time,date);
+        //now kill the jobs that are running on machines that need to be repaired.        
+        //if there are no running jobs, then there are none to kill
+        if (!_running_jobs.empty()){
+            //ok there are jobs to kill
+            for(auto key_value : _current_allocations)
+            {
+                if (!((key_value.second & machine).is_empty())){
+                    Job * job_ref = (*_workload)[key_value.first];
+                    batsched_tools::Job_Message * msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+                    LOG_F(INFO,"Killing Job: %s",key_value.first.c_str());
+                    BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+                }
+            }
+        }
+    }
+    else
+    {
+        BLOG_F(b_log::FAILURES,"Machine Already Being Repaired: %d",number);
+    }
+}
+
+
+void FCFSFast2::on_machine_instant_down_up(double date){
+    //get a random number of a machine to kill
+    int number = unif_distribution->operator()(generator2);
+    //make it an intervalset so we can find the intersection of it with current allocations
+    IntervalSet machine = number;
+    BLOG_F(b_log::FAILURES,"Machine Instant Down Up: %d",number);
+    //if there are no running jobs, then there are none to kill
+    if (!_running_jobs.empty()){
+        for(auto key_value : _current_allocations)   
+	{
+		if (!((key_value.second & machine).is_empty())){
+                    Job * job_ref = (*_workload)[key_value.first];
+                    batsched_tools::Job_Message* msg = new batsched_tools::Job_Message;
+                    msg->id = key_value.first;
+                    msg->forWhat = batsched_tools::KILL_TYPES::NONE;
+                    _my_kill_jobs.insert(std::make_pair(job_ref,msg));
+	                BLOG_F(b_log::FAILURES,"Killing Job: %s",key_value.first.c_str());
+            	}
+	}
+    }
+}
+/*void FCFSFast2::on_job_fault_notify_event(double date, std::string job){
+    std::unordered_set<std::string>::const_iterator found = _running_jobs.find(job);
+  //LOG_F(INFO,"on_job_fault_notify_event called");
+  if ( found != _running_jobs.end() )    
+        _decision->add_kill_job({job},date);
+  else
+      LOG_F(INFO,"Job %s was not running but was supposed to be killed due to job_fault event",job.c_str());
+}
+*/
+
+void FCFSFast2::on_requested_call(double date,int id,batsched_tools::call_me_later_types forWhat)
+{
+    
+        switch (forWhat){
+            case batsched_tools::call_me_later_types::SMTBF:
+                        {
+                            //Log the failure
+                            BLOG_F(b_log::FAILURES,"FAILURE SMTBF");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = distribution->operator()(generator);
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::SMTBF,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::MTBF:
+                        {
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                            {
+                                double number = distribution->operator()(generator);
+                                on_myKillJob_notify_event(date);
+                                _decision->add_call_me_later(batsched_tools::call_me_later_types::MTBF,1,number+date,date);
+
+                            }
+                        
+                            
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::FIXED_FAILURE:
+                        {
+                            BLOG_F(b_log::FAILURES,"FAILURE FIXED_FAILURE");
+                            if (!_running_jobs.empty() || !_pending_jobs.empty() || !_no_more_static_job_to_submit_received)
+                                {
+                                    double number = _myWorkloads->_fixed_failures;
+                                    if (_myWorkloads->_repair_time == 0.0)
+                                        on_machine_instant_down_up(date);
+                                    else
+                                        on_machine_down_for_repair(date);
+                                    _decision->add_call_me_later(batsched_tools::call_me_later_types::FIXED_FAILURE,1,number+date,date);
+                                }
+                        }
+                        break;
+            case batsched_tools::call_me_later_types::REPAIR_DONE:
+                        {
+                            BLOG_F(b_log::FAILURES,"REPAIR_DONE");
+                            //a repair is done, all that needs to happen is add the machines to available
+                            //and remove them from repair machines and add one to the number of available
+                            IntervalSet machine = id;
+                            _available_machines += machine;
+                            _unavailable_machines -= machine;
+                            _repair_machines -= machine;
+                            _nb_available_machines=_available_machines.size();
+                            _machines_that_became_available_recently += machine;
+                           //LOG_F(INFO,"in repair_machines.size(): %d nb_avail: %d avail: %d  running_jobs: %d",_repair_machines.size(),_nb_available_machines,_available_machines.size(),_running_jobs.size());
+                        }
+                        break;
+        }
+    
+
+}
+void FCFSFast2::on_no_more_static_job_to_submit_received(double date){
+    ISchedulingAlgorithm::on_no_more_static_job_to_submit_received(date);
+
+}
+void FCFSFast2::on_no_more_external_event_to_occur(double date){
+    
+    _wrap_it_up = true;    
+    
+    
+}
+void FCFSFast2::on_job_end(double date, std::vector<std::string> job_ids)
+{
+    (void) date;
+    (void) job_ids;
+}
+
+void FCFSFast2::make_decisions(double date,
+    SortableJobOrder::UpdateInformation *update_info,
+    SortableJobOrder::CompareInformation *compare_info)
+{
+   LOG_F(INFO,"Line 322   fcfs_fast2.cpp");
+    (void) update_info;
+    (void) compare_info;
+    std::vector<int> mapping = {0};
+    if (_oldDate == -1)
+        _oldDate=date;
+    // This algorithm is a fast version of FCFS without backfilling.
+    // It is meant to be fast in the usual case, not to handle corner cases.
+    // It is not meant to be easily readable or hackable ;).
+
+    // This fast FCFS variant in a few words:
+    // - only handles the FCFS queue order
+    // - only handles the basic resource selection policy
+    // - only handles finite jobs (no switchoff)
+    // - only handles time as floating-point (-> precision errors).
+
+    
+
+//LOG_F(INFO,"Line 340  fcfs_fast2.cpp");
+    //*****************************************************************
+    // Handle newly finished jobs
+    //*****************************************************************
+    bool job_ended = false;
+    for (const std::string & ended_job_id : _jobs_ended_recently)
+    {
+        job_ended = true;
+        Job * finished_job = (*_workload)[ended_job_id];
+        if (_share_packing && finished_job->nb_requested_resources == 1)
+        {
+                //first get the machine it was running on
+                int machine_number = (_current_allocations[ended_job_id])[0];
+                machine* current_machine = machines_by_int[machine_number];
+
+                //now increase cores_available on that machine
+                current_machine->cores_available += 1;
+                //if that increase means no jobs are running on that machine (all its cores are available) then put it back in the mix
+                if (current_machine->cores_available == int(current_machine->core_count * _core_percent))
+                {
+                    _available_core_machines -= _current_allocations[ended_job_id];  // we subtract a core machine because it is now a regular machine
+                    _available_machines.insert(_current_allocations[ended_job_id]); // we insert the machine into available machines
+                    _nb_available_machines += 1; // we increase available machines by 1
+                }
+                _current_allocations.erase(ended_job_id);
+                _running_jobs.erase(ended_job_id);
+        }
+            // was not a 1 resource job, do things normally
+        else{
+                IntervalSet machines_to_add = _current_allocations[ended_job_id];
+                machines_to_add-=_unavailable_machines;
+                _available_machines.insert(machines_to_add);
+
+                _available_machines-=_unavailable_machines;
+                _nb_available_machines += machines_to_add.size();
+                _current_allocations.erase(ended_job_id);
+                _running_jobs.erase(ended_job_id);
+                _my_kill_jobs.erase((*_workload)[ended_job_id]);
+        }
+    }
+    
+
+    
+    //LOG_F(INFO,"Line 379  fcfs_fast2.cpp");
+    //Handle new jobs to kill
+   
+    if(!_my_kill_jobs.empty()){
+         std::vector<batsched_tools::Job_Message *> kills;
+        for( auto job_msg_pair:_my_kill_jobs)
+        {
+            LOG_F(INFO,"adding kill job %s",job_msg_pair.first->id.c_str());
+            kills.push_back(job_msg_pair.second);
+        }
+        _decision->add_kill_job(kills,date);
+        _my_kill_jobs.clear();
+    }
+    //************************************************************resubmission if killed
+    //Handle jobs to queue back up (if killed)  
+    handle_resubmission(date);    
+    //*************************************************************
+    
+    
+    
+    
+    //LOG_F(INFO,"Line 397  fcfs_fast2.cpp");
+    
+    if (!(_machines_that_became_available_recently.is_empty()) && !(_pending_jobs.empty()))
+    {
+        std::list<Job *>::iterator job_it =_pending_jobs.begin();
+        bool erased = false;
+        while(job_it!=_pending_jobs.end())
+        {
+            Job * pending_job = *job_it;
+            std::string pending_job_id = pending_job->id;
+            if (_share_packing && pending_job->nb_requested_resources==1)
+            {
+                 bool found = false;
+                //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                {
+                    //is this machine able to handle another job?
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {                                
+                            //it is able to handle another job, execute a job on it and subtract from cores_available
+                            IntervalSet machines = *it;
+                            
+                            _decision->add_execute_job(pending_job_id,machines,date,mapping);
+                            //update data structures
+                            current_machine->cores_available -=1;
+                            _current_allocations[pending_job_id] = machines;
+                            _running_jobs.insert(pending_job_id);
+                            job_it = _pending_jobs.erase(job_it);
+                            erased = true;
+                            found = true;
+                    }
+                    if (found == true)
+                        break; 
+                }  
+                // there were no available core machines to put it on, try to put on a new core machine
+                if (found == false && _nb_available_machines > 0)
+                {
+                    
+                    //first get a machine
+                    LOG_F(INFO,"here");
+                    IntervalSet machines = _available_machines.left(1);
+                    
+                    _decision->add_execute_job(pending_job_id,machines,date,mapping);
+
+                    //update data structures
+                    machine* current_machine = machines_by_int[machines[0]];
+                    current_machine->cores_available -= 1;
+                    _available_core_machines += machines;
+                    _available_machines -= machines;
+                    _nb_available_machines -= 1;
+                    _current_allocations[pending_job_id] = machines;
+                    _running_jobs.insert(pending_job_id);
+                    job_it = _pending_jobs.erase(job_it);
+                    erased = true;
+
+                } 
+            }
+            else if (pending_job->nb_requested_resources <= _nb_available_machines)
+            {
+                LOG_F(INFO,"here");
+                IntervalSet machines = _available_machines.left(
+                    pending_job->nb_requested_resources);
+                _decision->add_execute_job(pending_job->id,
+                    machines, date);
+                
+
+                // Update data structures
+                _available_machines -= machines;
+                _nb_available_machines -= pending_job->nb_requested_resources;
+                 _current_allocations[pending_job_id] = machines;
+                job_it = _pending_jobs.erase(job_it);
+                erased = true;
+                _running_jobs.insert(pending_job->id);
+                
+            }
+            else
+            {
+                // The job becomes priority!
+                // As there is no backfilling, we can simply leave this loop.
+                break;
+            }
+            if (!erased)
+                job_it++;
+            else
+                erased = false;
+        }
+    }
+    
+//LOG_F(INFO,"Line 476  fcfs_fast2.cpp");
+    // If jobs have finished, execute jobs as long as they fit
+    std::list<Job *>::iterator job_it =_pending_jobs.begin();
+    if (job_ended)
+    {
+        bool erased = false;
+        while(job_it!=_pending_jobs.end())
+            
+        {
+            //LOG_F(INFO,"Line 483  fcfs_fast2.cpp");
+            Job * pending_job = *job_it;
+            //LOG_F(INFO,"Line 485  fcfs_fast2.cpp");
+            //LOG_F(INFO,"Line 486 pending job %p",static_cast<void *>(pending_job));
+            //LOG_F(INFO,"Line 487 pending job %s",(*job_it)->id.c_str());
+            //LOG_F(INFO,"Line 488 pending job %d ",pending_job->nb_requested_resources);
+            std::string pending_job_id = pending_job->id;
+            //LOG_F(INFO,"Line 489  fcfs_fast2.cpp");
+            if (_share_packing && pending_job->nb_requested_resources==1)
+            {
+                //LOG_F(INFO,"Line 492 fcfs_fast2.cpp");
+                 bool found = false;
+                //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                {
+                    //is this machine able to handle another job?
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {                                
+                            //it is able to handle another job, execute a job on it and subtract from cores_available
+                            IntervalSet machines = *it;
+                            
+                            _decision->add_execute_job(pending_job_id,machines,date,mapping);
+                            //update data structures
+                            current_machine->cores_available -=1;
+                            _current_allocations[pending_job_id] = machines;
+                            _running_jobs.insert(pending_job_id);
+                            job_it = _pending_jobs.erase(job_it);
+                            erased = true;
+                            found = true;
+                            //LOG_F(INFO,"Line 511  fcfs_fast2.cpp");
+                    }
+                    if (found == true)
+                        break; 
+                }  
+                // there were no available core machines to put it on, try to put on a new core machine
+                if (found == false && _nb_available_machines > 0)
+                {
+                    LOG_F(INFO,"Line 519  fcfs_fast2.cpp");
+                    //first get a machine
+                    
+                    IntervalSet machines = _available_machines.left(1);
+                    //LOG_F(INFO,"Line 522  fcfs_fast2.cpp");
+                    _decision->add_execute_job(pending_job_id,machines,date,mapping);
+
+                    //update data structures
+                    machine* current_machine = machines_by_int[machines[0]];
+                    current_machine->cores_available -= 1;
+                    _available_core_machines += machines;
+                    _available_machines -= machines;
+                    _nb_available_machines -= 1;
+                    //LOG_F(INFO,"Line 531  fcfs_fast2.cpp");
+                    _current_allocations[pending_job_id] = machines;
+                    //LOG_F(INFO,"Line 533  fcfs_fast2.cpp");
+                    _running_jobs.insert(pending_job_id);
+                    //LOG_F(INFO,"Line 535  fcfs_fast2.cpp");
+                    //LOG_F(INFO,"Line 536  fcfs_fast2.cpp pending_job: %p",static_cast<void *>(*job_it));
+                    //LOG_F(INFO,"Line   fcfs_fast2.cpp pending_job_id: %s",pending_job->id.c_str());
+                    job_it = _pending_jobs.erase(job_it);
+                    erased = true;
+                    //LOG_F(INFO,"Line 537  fcfs_fast2.cpp");
+
+                } 
+            }
+            else if (pending_job->nb_requested_resources <= _nb_available_machines)
+            {
+                LOG_F(INFO,"Line 543  fcfs_fast2.cpp"); 
+                IntervalSet machines = _available_machines.left(
+                    pending_job->nb_requested_resources);
+                _decision->add_execute_job(pending_job->id,
+                    machines, date);
+                
+
+                // Update data structures
+                _available_machines -= machines;
+                _nb_available_machines -= pending_job->nb_requested_resources;
+                 _current_allocations[pending_job_id] = machines;
+                job_it = _pending_jobs.erase(job_it);
+                erased = true;
+                _running_jobs.insert(pending_job->id);
+                //LOG_F(INFO,"Line 556  fcfs_fast2.cpp");
+            }
+            else
+            {
+                // The job becomes priority!
+                // As there is no backfilling, we can simply leave this loop.
+                break;
+            }
+            if (!erased)
+                job_it++;
+            else
+                erased = false;
+        }
+        //LOG_F(INFO,"Line 566  fcfs_fast2.cpp");
+    }
+    //LOG_F(INFO,"Line 567  fcfs_fast2.cpp");
+    // Handle newly released jobs
+    for (const std::string & new_job_id : _jobs_released_recently)
+    {
+        Job * new_job = (*_workload)[new_job_id];
+
+        // Is this job valid?
+        if (new_job->nb_requested_resources > _nb_machines)
+        {
+            // Invalid!
+            //LOG_F(INFO,"Job being rejected HERE %s",new_job_id.c_str());
+            _decision->add_reject_job(new_job_id, date);
+            continue;
+        }
+
+        // Is there a waiting job?
+        if (!_pending_jobs.empty())
+        {   
+            // submitted job is a resubmitted one, put at front of pending jobs
+           if (new_job_id.find("#")!=std::string::npos)
+               _pending_jobs.push_front(new_job);
+            else{
+                // Yes. The new job is queued up.
+                //LOG_F(INFO,"Line 590  fcfs_fast2.cpp  new_job: %p  new_job_id: %s",static_cast<void *>(new_job),new_job_id.c_str());
+                _pending_jobs.push_back(new_job);
+            }
+        }
+        else
+        {
+            // No, the queue is empty.
+            // Can the new job be executed now?
+            
+            if (_share_packing && new_job->nb_requested_resources==1)
+            {
+                 bool found = false;
+                //it is a 1 resource job, iterate over the available core machines until it finds one to put the job on.
+                for (auto it = _available_core_machines.elements_begin(); it != _available_core_machines.elements_end(); ++it)
+                {
+                    //is this machine able to handle another job?
+                    machine* current_machine = machines_by_int[*it];
+                    if (current_machine->cores_available >= 1)
+                    {                                
+                            //it is able to handle another job, execute a job on it and subtract from cores_available
+                            IntervalSet machines = *it;
+                            
+                            _decision->add_execute_job(new_job_id,machines,date,mapping);
+                            //update data structures
+                            current_machine->cores_available -=1;
+                            _current_allocations[new_job_id] = machines;
+                            _running_jobs.insert(new_job_id);
+                            found = true;
+                    }
+                    if (found == true)
+                        break; 
+                }  
+                // there were no available core machines to put it on, try to put on a new core machine
+                if (found == false && _nb_available_machines > 0)
+                {
+                    
+                    //first get a machine
+                    LOG_F(INFO,"here");
+                    IntervalSet machines = _available_machines.left(1);
+                    
+                    _decision->add_execute_job(new_job_id,machines,date,mapping);
+
+                    //update data structures
+                    machine* current_machine = machines_by_int[machines[0]];
+                    current_machine->cores_available -= 1;
+                    _available_core_machines += machines;
+                    _available_machines -= machines;
+                    _nb_available_machines -= 1;
+                    _current_allocations[new_job_id] = machines;
+                    _running_jobs.insert(new_job_id);
+
+                } 
+                else if (found == false){ // there was no machine available...queue it up
+                    _pending_jobs.push_back(new_job);
+                }
+
+            } // do things normally, we don't have share-packing or job isn't 1 resource
+            else if (new_job->nb_requested_resources <= _nb_available_machines)
+            {
+                LOG_F(INFO,"here");
+                IntervalSet machines = _available_machines.left(
+                    new_job->nb_requested_resources);
+                _decision->add_execute_job(new_job->id,
+                        machines, date);
+                
+
+                // Update data structures
+                _available_machines -= machines;
+                _nb_available_machines -= new_job->nb_requested_resources;
+                 _current_allocations[new_job_id] = machines;
+                _running_jobs.insert(new_job->id);
+            }
+            
+            else
+            {
+                // No. The job is queued up.
+                //LOG_F(INFO,"Line 656   fcfs_fast2.cpp  new job:%p  new job id: %s",static_cast<void *>(new_job),new_job_id.c_str());
+                _pending_jobs.push_back(new_job);
+            }
+        }
+    }
+    //LOG_F(INFO,"Line 650  fcfs_fast2.cpp");
+    /*if (_jobs_killed_recently.empty() && _wrap_it_up && _need_to_send_finished_submitting_jobs && !_myWorkloads->_checkpointing_on)
+    {
+        
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+    */
+    if (_jobs_killed_recently.empty() && _pending_jobs.empty() && _running_jobs.empty() &&
+             _need_to_send_finished_submitting_jobs && _no_more_static_job_to_submit_received && !date<1.0 )
+    {
+        _decision->add_scheduler_finished_submitting_jobs(date);
+        _need_to_send_finished_submitting_jobs = false;
+    }
+      
+}
+std::string FCFSFast2::to_json_desc(rapidjson::Document * doc)
+{
+  rapidjson::StringBuffer buffer;
+
+  buffer.Clear();
+
+  rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+  doc->Accept(writer);
+
+  return std::string( buffer.GetString() );
+}
+void FCFSFast2::handle_resubmission(double date)
+{
+ for(const auto & killed_map:_jobs_killed_recently)
+    {
+        std::string killed_job=killed_map.first;
+        double progress = killed_map.second->progress;
+        //LOG_F(INFO,"REPAIR  progress: %f",progress);
+        auto start = killed_job.find("!")+1;
+        auto end = killed_job.find("#");
+        std::string basename = (end ==std::string::npos) ? killed_job.substr(start) : killed_job.substr(start,end-start); 
+        
+        const std::string workload_str = killed_job.substr(0,start-1); 
+        //get the workload
+        myB::Workload * w0= (*_myWorkloads)[workload_str];
+        //get the conversion from seconds to cpu instructions
+        double one_second = w0->_host_speed;
+        //get the job that was killed
+        myB::JobPtr job_to_queue =(*(w0->jobs))[myB::JobIdentifier(killed_job)];
+        //get the job identifier of the job that was killed
+        myB::JobIdentifier ji = job_to_queue->id;
+        
+        std::string profile_jd=job_to_queue->profile->json_description;
+        std::string job_jd=job_to_queue->json_description;
+        r::Document profile_doc;
+        profile_doc.Parse(profile_jd.c_str());
+        r::Document doc;
+        doc.Parse(job_jd.c_str());
+        
+        if (job_to_queue->profile->type == myB::ProfileType::DELAY )
+        {
+            if (_checkpointing_on)
+            {
+                double progress_time = 0;
+                if (progress > 0)
+                {
+                    
+                    
+                    progress_time =progress * profile_doc["delay"].GetDouble();
+                    //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                    
+                    bool has_checkpointed = false;
+                    std::string meta_str = "null";
+                    int num_checkpoints_completed = 0;
+                    r::Document meta_doc;
+                    //check whether there is a checkpointed value and set has_checkpointed if so
+                    if (doc.HasMember("metadata"))
+                    {
+                        
+                        meta_str = doc["metadata"].GetString();
+                        std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                        meta_doc.Parse(meta_str.c_str());
+                        if (meta_doc.HasMember("checkpointed"))
+                        {
+                            has_checkpointed = meta_doc["checkpointed"].GetBool();
+                            
+                        }
+                    }
+                    //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                    if (has_checkpointed)
+                    {
+                        
+                        //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                        num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                        if (meta_doc.HasMember("work_progress"))
+                        {
+                            double work = meta_doc["work_progress"].GetDouble();
+                            if (num_checkpoints_completed > 0)
+                                work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                            meta_doc["work_progress"] = work;
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                        }
+                        if (meta_doc.HasMember("num_dumps"))
+                        {
+                                int num_dumps = meta_doc["num_dumps"].GetInt();
+                                if (num_checkpoints_completed > 0)
+                                    num_dumps += num_checkpoints_completed;
+                                meta_doc["num_dumps"] = num_dumps;
+                                
+                        }
+                        else if (num_checkpoints_completed > 0)
+                        {
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            
+                        }
+                        std::string meta_str = to_json_desc(&meta_doc);
+                        doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                        // the progress_time needs to add back in the read_time
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                    
+                    }
+                    else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                    {
+                        num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                        progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                        
+                        
+                        //if a checkpoint has completed set the metadata to reflect this
+                        if (num_checkpoints_completed > 0)
+                        {
+                            meta_doc.SetObject();
+                            //if there was previous metadata make sure to include it
+                            if (meta_str!="null")
+                            {
+                                meta_doc.Parse(meta_str.c_str());
+                            }    
+                            r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                            meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                            meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                            meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                            std::string myString = to_json_desc(&meta_doc);
+                            r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                
+                            if (meta_str=="null")
+                                doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                            else
+                                doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                        }
+        
+                    }        
+                    //only if a new checkpoint has been reached does the delay time change
+                    //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                    if (num_checkpoints_completed > 0)
+                    {
+                        
+                        double delay = profile_doc["delay"].GetDouble() - progress_time + job_to_queue->read_time;
+                        //LOG_F(INFO,"REPAIR delay: %f  readtime: %f",delay,job_to_queue->read_time);
+                        profile_doc["delay"].SetDouble(delay);
+                        
+                        
+                    }
+                }
+            
+            }
+                                          
+                    
+        }
+    
+        if (job_to_queue->profile->type == myB::ProfileType::PARALLEL_HOMOGENEOUS)
+        {
+            if (_checkpointing_on)
+                {
+                    double progress_time = 0;
+                    if (progress > 0)
+                    {
+                        
+                        
+                        progress_time =(progress * profile_doc["cpu"].GetDouble())/one_second;
+                        //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+                        //LOG_F(INFO,"profile_doc[cpu]: %f    , one_second: %f",profile_doc["cpu"].GetDouble(),one_second);
+                        
+                        bool has_checkpointed = false;
+                        std::string meta_str = "null";
+                        int num_checkpoints_completed = 0;
+                        r::Document meta_doc;
+                        //check whether there is a checkpointed value and set has_checkpointed if so
+                        if (doc.HasMember("metadata"))
+                        {
+                            
+                            meta_str = doc["metadata"].GetString();
+                            std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                            meta_doc.Parse(meta_str.c_str());
+                            if (meta_doc.HasMember("checkpointed"))
+                            {
+                                has_checkpointed = meta_doc["checkpointed"].GetBool();
+                                
+                            }
+                        }
+                        //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+                        if (has_checkpointed)
+                        {
+                            
+                            //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                            num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                            if (meta_doc.HasMember("work_progress"))
+                            {
+                                double work = meta_doc["work_progress"].GetDouble();
+                                if (num_checkpoints_completed > 0)
+                                    work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                                work = work * one_second;
+                                meta_doc["work_progress"] = work;
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval*one_second),meta_doc.GetAllocator());
+                            }
+                            if (meta_doc.HasMember("num_dumps"))
+                            {
+                                    int num_dumps = meta_doc["num_dumps"].GetInt();
+                                    if (num_checkpoints_completed > 0)
+                                        num_dumps += num_checkpoints_completed;
+                                    meta_doc["num_dumps"] = num_dumps;
+                                    
+                            }
+                            else if (num_checkpoints_completed > 0)
+                            {
+                                    meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                
+                            }
+                            std::string meta_str = to_json_desc(&meta_doc);
+                            doc["metadata"].SetString(meta_str.c_str(),doc.GetAllocator());
+                            // the progress_time needs to add back in the read_time
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+                        
+                        }
+                        else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+                        {
+                            num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                            progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                            
+                            
+                            //if a checkpoint has completed set the metadata to reflect this
+                            if (num_checkpoints_completed > 0)
+                            {
+                                meta_doc.SetObject();
+                                //if there was previous metadata make sure to include it
+                                if (meta_str!="null")
+                                {
+                                    meta_doc.Parse(meta_str.c_str());
+                                }    
+                                r::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                                meta_doc.AddMember("checkpointed",r::Value().SetBool(true),myAlloc);
+                                meta_doc.AddMember("num_dumps",r::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                                meta_doc.AddMember("work_progress",r::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval * one_second),meta_doc.GetAllocator());
+                                std::string myString = to_json_desc(&meta_doc);
+                                r::Document::AllocatorType& myAlloc2 = doc.GetAllocator();
+                                                    
+                                if (meta_str=="null")
+                                    doc.AddMember("metadata",r::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                                else
+                                    doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                            }
+            
+                        }        
+                        //only if a new checkpoint has been reached does the delay time change
+                        //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+                        if (num_checkpoints_completed > 0)
+                        {
+                            double cpu = profile_doc["cpu"].GetDouble();
+                            double cpu_time = cpu / one_second;
+                            cpu_time = cpu_time - progress_time + job_to_queue->read_time;
+                            //LOG_F(INFO,"REPAIR cpu_time: %f  readtime: %f",cpu_time,job_to_queue->read_time);
+                            profile_doc["cpu"].SetDouble(cpu_time*one_second);
+                            
+                            
+                        }
+                    }
+                
+                }
+        }
+
+
+        doc["subtime"]=date;
+                
+        //check if resubmitted and get the next resubmission number
+        int resubmit = 1;
+        if (end!=std::string::npos) //if job name has # in it...was resubmitted b4
+        {
+            resubmit = std::stoi(killed_job.substr(end+1));   // then get the resubmitted number
+            resubmit++; // and add 1 to it
+        }
+        std::string resubmit_str = std::to_string(resubmit);
+        
+        
+        std::string profile_name = basename + "#" + resubmit_str;
+        std::string job_name = basename + "#" + resubmit_str;
+        std::string job_id = workload_str+"!" + basename + "#" + resubmit_str;
+        std::string workload_name = workload_str;
+        doc["profile"].SetString(profile_name.data(), profile_name.size(), doc.GetAllocator());
+        doc["id"].SetString(job_id.data(),job_id.size(),doc.GetAllocator());
+        std::string error_prefix = "Invalid JSON job '" + killed_job + "'";
+        profile_jd = to_json_desc(&profile_doc);
+        myB::ProfilePtr p = myB::Profile::from_json(profile_name,profile_jd);
+        w0->profiles->add_profile(p);
+        myB::JobPtr j = myB::Job::from_json(doc,w0,error_prefix);
+        w0->jobs->add_job(j);
+        job_jd = to_json_desc(&doc);
+        //LOG_F(INFO,"workload: %s  job: %s, profile: %s",workload_name.c_str(),job_name.c_str(),profile_name.c_str());
+        _decision->add_submit_profile(workload_name,
+                                    profile_name,
+                                    profile_jd,
+                                    date);
+                                    
+        _decision->add_submit_job(workload_name,
+                                    job_name,
+                                    profile_name,
+                                    job_jd,
+                                    profile_jd,
+                                    date,
+                                    true);
+        if (doc.HasMember("metadata"))
+        {
+            std::string meta = doc["metadata"].GetString();
+            //must replace double quotes with single quotes.  Remember to
+            //replace single quotes with double quotes before parsing metadata
+            std::replace( meta.begin(), meta.end(), '\"', '\'');
+        _decision->add_set_job_metadata(job_id,
+                                        meta,
+                                        date);
+        }                               
+    }            
+    
+       
+}
+/*(Document, Swap) {
+    Document d1;
+    Document::AllocatorType& a = d1.GetAllocator();
+
+    d1.SetArray().PushBack(1, a).PushBack(2, a);
+
+    Value o;
+    o.SetObject().AddMember("a", 1, a);
+
+    // Swap between Document and Value
+    d1.Swap(o);
+*/
diff -burN '--exclude=.git*' ./batsched/src/algo/fcfs_fast2.hpp ./new_batsched/src/algo/fcfs_fast2.hpp
--- ./batsched/src/algo/fcfs_fast2.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/algo/fcfs_fast2.hpp	2023-06-28 08:26:02.133833308 -0400
@@ -0,0 +1,92 @@
+#pragma once
+
+#include <unordered_map>
+
+#include <unordered_set>
+#include <list>
+#include <random>
+
+#include "../isalgorithm.hpp"
+#include "../json_workload.hpp"
+#include "../locality.hpp"
+#include "../external/batsched_workload.hpp"
+#include <rapidjson/document.h>
+#include "../batsched_tools.hpp"
+
+class FCFSFast2 : public ISchedulingAlgorithm
+{
+public:
+    
+
+    FCFSFast2(Workload * workload, SchedulingDecision * decision,
+        Queue * queue, ResourceSelector * selector,
+        double rjms_delay,
+        rapidjson::Document * variant_options);
+    virtual ~FCFSFast2();
+
+    virtual void on_simulation_start(double date,
+        const rapidjson::Value & batsim_config);
+
+    virtual void on_simulation_end(double date);
+    //virtual void on_machine_unavailable_notify_event(double date, IntervalSet machines);
+    virtual void on_machine_available_notify_event(double date, IntervalSet machines);
+    //virtual void on_job_fault_notify_event(double date, std::string job);
+    virtual void on_myKillJob_notify_event(double date);
+    virtual void on_requested_call(double date,int id,  batsched_tools::call_me_later_types forWhat);
+    virtual void set_workloads(myBatsched::Workloads * w);
+    virtual void make_decisions(double date,
+        SortableJobOrder::UpdateInformation * update_info,
+        SortableJobOrder::CompareInformation * compare_info);
+    std::string to_json_desc(rapidjson::Document *doc);
+    void handle_resubmission(double date);
+    void on_machine_instant_down_up(double date);
+    void on_machine_down_for_repair(double date);
+    virtual void on_no_more_external_event_to_occur(double date);
+    virtual void on_job_end(double date, std::vector<std::string> job_ids);
+    virtual void on_machine_state_changed(double date, IntervalSet machines, int new_state);
+    virtual void on_no_more_static_job_to_submit_received(double date);
+
+private:
+    // Machines currently available
+    IntervalSet _available_machines;
+    IntervalSet _unavailable_machines;
+    IntervalSet _repair_machines;
+    IntervalSet _available_core_machines;
+   
+    int _nb_available_machines = -1;
+
+    // Pending jobs (queue)
+    std::list<Job *> _pending_jobs;
+    std::map<Job *,batsched_tools::Job_Message *> _my_kill_jobs;
+    std::unordered_set<std::string> _running_jobs;
+    myBatsched::Workloads * _myWorkloads;
+    double _oldDate=-1;
+    int _killed=0;
+    bool _wrap_it_up = false;
+    bool _need_to_send_finished_submitting_jobs = true;
+    bool _checkpointing_on=false;
+    std::vector<double> _call_me_laters;
+    std::mt19937 generator;
+    std::exponential_distribution<double> * distribution;
+    std::mt19937 generator2;
+    std::uniform_int_distribution<int> * unif_distribution;
+    std::string _output_folder;
+        
+    struct machine{
+        int id;
+        std::string name;
+        int core_count = -1;
+        int cores_available;
+        double speed;
+    };
+    bool _share_packing = false;
+    double _core_percent = 1.0;
+    std::map<int,machine *> machines_by_int;
+    std::map<std::string,machine *> machines_by_name;
+
+
+    // Allocations of running jobs
+    std::unordered_map<std::string, IntervalSet> _current_allocations;
+    b_log *_myBLOG;
+
+};
diff -burN '--exclude=.git*' ./batsched/src/batsched_tools.cpp ./new_batsched/src/batsched_tools.cpp
--- ./batsched/src/batsched_tools.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/batsched_tools.cpp	2023-06-28 08:26:02.143833485 -0400
@@ -0,0 +1,47 @@
+#include <cstdarg>
+#include <string>
+#include "batsched_tools.hpp"
+#include <cstdio>
+b_log::b_log(){
+
+}
+b_log::~b_log(){
+ for (auto key_value:_files)
+    fclose(key_value.second);
+}
+void b_log::add_log_file(std::string file,logging_type type){
+    FILE* myFile=fopen(file.c_str(),"w");
+    _files[type]=myFile;
+}
+void b_log::blog(logging_type type, std::string fmt, double date, ...){
+    
+    if (_files.size() > 0 && _files.find(type) != _files.end()){
+        va_list args;
+        va_start(args,date);
+        FILE* file = _files[type];                                                                                                                                                           
+        std::fprintf(file,"%-60f ||",date);
+        fmt=fmt + "\n";
+        std::vfprintf(file,fmt.c_str(),args);
+        va_end(args);
+    }
+    
+}
+batsched_tools::id_separation batsched_tools::tools::separate_id(const std::string job_id){
+    batsched_tools::id_separation separation;
+    auto start = job_id.find("!")+1;
+    auto end = job_id.find("#");
+    separation.basename = (end ==std::string::npos) ? job_id.substr(start) : job_id.substr(start,end-start); 
+    separation.workload = job_id.substr(0,start-1);
+    separation.resubmit_number = 1;
+    int next_number = 1;
+    if (end!=std::string::npos) //if job name has # in it...was resubmitted b4
+    {
+            separation.resubmit_number = std::stoi(job_id.substr(end+1));   // then get the resubmitted number
+            next_number = separation.resubmit_number + 1;
+    }                                                                                                                                                                                                                                                                                                                                                                                    
+    separation.resubmit_string = std::to_string(separation.resubmit_number);
+    separation.next_resubmit_string = separation.workload + "!" +
+                                      separation.basename + "#" +
+                                      std::to_string(next_number);
+    return separation;
+}
\ No newline at end of file
diff -burN '--exclude=.git*' ./batsched/src/batsched_tools.hpp ./new_batsched/src/batsched_tools.hpp
--- ./batsched/src/batsched_tools.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/batsched_tools.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -0,0 +1,47 @@
+#ifndef BATSCHED_TOOLS_HPP
+#define BATSCHED_TOOLS_HPP
+#include <unordered_map>
+#include <string>
+#include <cstdarg>
+#include <cstdio>
+
+
+
+#define BLOG_F(log_type,fmt,...) B_LOG_INSTANCE->blog(log_type,fmt,date,## __VA_ARGS__)
+class b_log{
+    
+public:
+b_log();
+~b_log();
+enum logging_type{FAILURES};
+const char * logging_types = {"FAILURES"};
+void blog(logging_type type,std::string fmt, double date,...);
+void add_log_file(std::string file, logging_type type);
+
+std::unordered_map<logging_type,FILE*> _files;
+};
+
+
+namespace batsched_tools{
+    enum class call_me_later_types {FIXED_FAILURE,SMTBF,MTBF,REPAIR_DONE,RESERVATION_START};
+    enum class KILL_TYPES {NONE,FIXED_FAILURE,SMTBF,MTBF,RESERVATION};
+    struct id_separation{
+        std::string basename;
+        std::string resubmit_string;
+        int resubmit_number;
+        std::string next_resubmit_string;
+        std::string workload;
+        };
+    struct Job_Message{
+        std::string id;
+        std::string progress_str;
+        double progress;
+        batsched_tools::KILL_TYPES forWhat = batsched_tools::KILL_TYPES::NONE;
+    };
+    struct tools{
+        static id_separation separate_id(const std::string job_id);
+    };
+}
+
+
+#endif
\ No newline at end of file
diff -burN '--exclude=.git*' ./batsched/src/decision.cpp ./new_batsched/src/decision.cpp
--- ./batsched/src/decision.cpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/decision.cpp	2023-06-28 08:26:02.140500092 -0400
@@ -4,6 +4,12 @@
 #include "pempek_assert.hpp"
 #include "protocol.hpp"
 #include "data_storage.hpp"
+#include "batsched_tools.hpp"
+#include "json_workload.hpp"
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <utility>
+#include <loguru.hpp>
 
 namespace n = network;
 using namespace std;
@@ -32,9 +38,9 @@
     _proto_writer->append_reject_job(job_id, date);
 }
 
-void SchedulingDecision::add_kill_job(const vector<string> &job_ids, double date)
+void SchedulingDecision::add_kill_job(const vector<batsched_tools::Job_Message *> &job_msgs, double date)
 {
-    _proto_writer->append_kill_job(job_ids, date);
+    _proto_writer->append_kill_job(job_msgs, date);
 }
 
 void SchedulingDecision::add_submit_job(const string & workload_name,
@@ -64,6 +70,371 @@
                                          profile_json_description,
                                          send_profile);
 }
+void SchedulingDecision::handle_resubmission(std::unordered_map<std::string,batsched_tools::Job_Message *> jobs_killed_recently,
+                                            Workload *w0,
+                                            double date)
+{
+    
+    for(const auto & killed_map:jobs_killed_recently)
+    {
+        std::string killed_job=killed_map.first;
+        
+    
+        Job * job_to_queue = (*w0)[killed_job];
+
+        auto start = killed_job.find("!")+1;
+        auto end = killed_job.find("#");
+        std::string basename = (end ==std::string::npos) ? killed_job.substr(start) : killed_job.substr(start,end-start); 
+        const std::string workload_str = killed_job.substr(0,start-1); 
+        
+        //const std::string workload_str = killed_job.substr(0,start-1);  //used when having multiple workloads
+        //get the conversion from seconds to cpu instructions
+            
+        //get the job identifier of the job that was killed
+        std::string jid = killed_job;
+        std::string profile_jd=job_to_queue->profile->json_description;
+        rapidjson::Document profile_doc;
+        profile_doc.Parse(profile_jd.c_str());
+        rapidjson::Document job_doc;
+        job_doc.Parse(job_to_queue->json_description.c_str());
+
+        
+        
+        if (job_to_queue->profile->type == myBatsched::ProfileType::DELAY )
+        {
+            get_meta_data_from_delay(killed_map,profile_doc,job_doc,w0);
+        }
+        else if (job_to_queue->profile->type == myBatsched::ProfileType::PARALLEL_HOMOGENEOUS)
+        {
+            get_meta_data_from_parallel_homogeneous(killed_map,profile_doc,job_doc,w0);
+        }
+        
+        job_doc["subtime"]=date;
+        rapidjson::Document::AllocatorType & myAlloc(job_doc.GetAllocator());
+        job_doc["submission_times"].PushBack(date,myAlloc);
+        
+                
+        //check if resubmitted and get the next resubmission number
+        int resubmit = 1;
+        if (end!=std::string::npos) //if job name has # in it...was resubmitted b4
+        {
+            resubmit = std::stoi(killed_job.substr(end+1));   // then get the resubmitted number
+            resubmit++; // and add 1 to it
+        }
+        std::string resubmit_str = std::to_string(resubmit);
+        
+        
+        std::string profile_name = basename + "#" + resubmit_str;
+        std::string job_name = basename + "#" + resubmit_str;
+        std::string job_id = workload_str+"!" + basename + "#" + resubmit_str;
+        std::string workload_name = workload_str;
+        job_doc["profile"].SetString(profile_name.data(), profile_name.size(), myAlloc);
+        job_doc["id"].SetString(job_id.data(),job_id.size(),myAlloc);
+        std::string error_prefix = "Invalid JSON job '" + killed_job + "'";
+        profile_jd = to_json_desc(&profile_doc);
+        std::string job_jd = to_json_desc(&job_doc);
+        //LOG_F(INFO,"workload: %s  job: %s, profile: %s",workload_name.c_str(),job_name.c_str(),profile_name.c_str());
+        add_submit_profile(workload_name,
+                                    profile_name,
+                                    profile_jd,
+                                    date);
+                                    
+        add_submit_job(workload_name,
+                                    job_name,
+                                    profile_name,
+                                    job_jd,
+                                    profile_jd,
+                                    date,
+                                    true);
+        if (job_doc.HasMember("metadata"))
+        {
+            std::string meta = job_doc["metadata"].GetString();
+            //must replace double quotes with single quotes.  Remember to
+            //replace single quotes with double quotes before parsing metadata
+            std::replace( meta.begin(), meta.end(), '\"', '\'');
+        add_set_job_metadata(job_id,
+                                        meta,
+                                        date);
+        }                               
+    }            
+ 
+
+ 
+}
+std::string SchedulingDecision::to_json_desc(rapidjson::Document * doc){
+
+    rapidjson::StringBuffer buffer;
+
+    buffer.Clear();
+
+    rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+    doc->Accept(writer);
+
+    return std::string( buffer.GetString() );
+
+}
+ 
+ void SchedulingDecision::get_meta_data_from_parallel_homogeneous(std::pair<std::string,batsched_tools::Job_Message *> killed_map,
+                                                                rapidjson::Document & profile_doc,
+                                                                rapidjson::Document & job_doc,
+                                                                Workload* w0)
+ {
+        double one_second = w0->_host_speed;
+        std::string killed_job = killed_map.first;
+        double progress = killed_map.second->progress;
+        //get the job that was killed
+        Job * job_to_queue =(*w0)[killed_job];
+        LOG_F(INFO,"ccu chkpt_interval %f",job_to_queue->checkpoint_interval);
+  
+    if (w0->_checkpointing_on)
+    {
+        double progress_time = 0;
+        if (progress > 0)
+        {
+            
+            
+            progress_time =(progress * profile_doc["cpu"].GetDouble())/one_second;
+
+            LOG_F(INFO,"job %s progress is > 0  progress: %f  progress_time: %f",job_to_queue->id.c_str(),progress,progress_time);
+            //LOG_F(INFO,"profile_doc[cpu]: %f    , one_second: %f",profile_doc["cpu"].GetDouble(),one_second);
+            
+            bool has_checkpointed = false;
+            
+            std::string meta_str = "null";
+            int num_checkpoints_completed = 0;
+            rapidjson::Document meta_doc;
+            //check whether there is a checkpointed value and set has_checkpointed if so
+            if (job_doc.HasMember("metadata"))
+            {
+                
+                meta_str = job_doc["metadata"].GetString();
+                std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                meta_doc.Parse(meta_str.c_str());
+                if (meta_doc.HasMember("checkpointed"))
+                {
+                    has_checkpointed = meta_doc["checkpointed"].GetBool();
+                  
+                    
+                }
+            }
+            //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+            if (has_checkpointed)
+            {
+                
+                //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                if (meta_doc.HasMember("work_progress"))
+                {
+                    double work = meta_doc["work_progress"].GetDouble();
+                    if (num_checkpoints_completed > 0)
+                        work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                    work = work * one_second;
+                    meta_doc["work_progress"] = work;
+                }
+                else if (num_checkpoints_completed > 0)
+                {
+                    meta_doc.AddMember("work_progress",rapidjson::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval*one_second),meta_doc.GetAllocator());
+                }
+                if (meta_doc.HasMember("num_dumps"))
+                {
+                        int num_dumps = meta_doc["num_dumps"].GetInt();
+                        if (num_checkpoints_completed > 0)
+                            num_dumps += num_checkpoints_completed;
+                        meta_doc["num_dumps"] = num_dumps;
+                        
+                }
+                else if (num_checkpoints_completed > 0)
+                {
+                        meta_doc.AddMember("num_dumps",rapidjson::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                    
+                }
+                std::string meta_str = to_json_desc(&meta_doc);
+                job_doc["metadata"].SetString(meta_str.c_str(),job_doc.GetAllocator());
+                // the progress_time needs to add back in the read_time
+                progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+            
+            }
+            else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+            {
+                num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                LOG_F(INFO,"line 258 num_checkpoints_completed %d",num_checkpoints_completed);
+                LOG_F(INFO,"progress time %f  checkpoint interval: %f dump time %f  num check: %f",
+                progress_time,job_to_queue->checkpoint_interval,job_to_queue->dump_time,
+                progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                
+                //if a checkpoint has completed set the metadata to reflect this
+                if (num_checkpoints_completed > 0)
+                {
+                    meta_doc.SetObject();
+                    //if there was previous metadata make sure to include it
+                    if (meta_str!="null")
+                    {
+                        meta_doc.Parse(meta_str.c_str());
+                    }    
+                    rapidjson::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                    meta_doc.AddMember("checkpointed",rapidjson::Value().SetBool(true),myAlloc);
+                    meta_doc.AddMember("num_dumps",rapidjson::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                    meta_doc.AddMember("work_progress",rapidjson::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval * one_second),meta_doc.GetAllocator());
+                    std::string myString = to_json_desc(&meta_doc);
+                    rapidjson::Document::AllocatorType& myAlloc2 = job_doc.GetAllocator();
+                                        
+                    if (meta_str=="null")
+                        job_doc.AddMember("metadata",rapidjson::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                    else
+                        job_doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                }
+
+            }        
+            //only if a new checkpoint has been reached does the delay time change
+            //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+            if (num_checkpoints_completed > 0)
+            {
+                LOG_F(INFO,"job %s num_checkpoints_completed: %d",job_to_queue->id.c_str(),num_checkpoints_completed);
+                //if we have checkpointed, the walltime can be reduced.  Reduce by the num of checkpoints. if _subtract_progress_from_walltime is false, skip
+                if (job_to_queue->walltime > 0 && job_doc.HasMember("walltime") && w0->_subtract_progress_from_walltime) 
+                {
+                    LOG_F(INFO,"decision line 288");
+                    job_doc["walltime"].SetDouble( (double)job_to_queue->walltime - 
+                                         (num_checkpoints_completed * (job_to_queue->checkpoint_interval+job_to_queue->dump_time) - job_to_queue->read_time));
+                }
+                double cpu = profile_doc["cpu"].GetDouble();
+                double cpu_time = cpu / one_second;
+                cpu_time = cpu_time - progress_time + job_to_queue->read_time;
+                //LOG_F(INFO,"REPAIR cpu_time: %f  readtime: %f",cpu_time,job_to_queue->read_time);
+                profile_doc["cpu"].SetDouble(cpu_time*one_second);
+                
+                
+            }
+        }
+    
+    }
+}
+void SchedulingDecision::get_meta_data_from_delay(std::pair<std::string,batsched_tools::Job_Message *> killed_map,
+                                                rapidjson::Document & profile_doc,
+                                                rapidjson::Document & job_doc,
+                                                Workload * w0)
+{
+    double one_second = w0->_host_speed;
+    std::string killed_job = killed_map.first;
+    double progress = killed_map.second->progress;
+    //get the job that was killed
+    Job * job_to_queue =(*w0)[killed_job];
+
+    if (w0->_checkpointing_on)
+    {
+        double progress_time = 0;
+        if (progress > 0)
+        {
+            
+            
+            progress_time =progress * profile_doc["delay"].GetDouble();
+            //LOG_F(INFO,"REPAIR progress is > 0  progress: %f  progress_time: %f",progress,progress_time);
+            
+            bool has_checkpointed = false;
+            std::string meta_str = "null";
+            int num_checkpoints_completed = 0;
+            rapidjson::Document meta_doc;
+            //check whether there is a checkpointed value and set has_checkpointed if so
+            if (job_doc.HasMember("metadata"))
+            {
+                
+                meta_str = job_doc["metadata"].GetString();
+                std::replace(meta_str.begin(),meta_str.end(),'\'','\"');
+                meta_doc.Parse(meta_str.c_str());
+                if (meta_doc.HasMember("checkpointed"))
+                {
+                    has_checkpointed = meta_doc["checkpointed"].GetBool();
+                    
+                }
+            }
+            //if has checkpointed we need to alter how we check num_checkpoints_completed and progress time
+            if (has_checkpointed)
+            {
+                
+                //progress_time must be subtracted by read_time to see how many checkpoints we have gone through
+                num_checkpoints_completed = floor((progress_time-job_to_queue->read_time)/(job_to_queue->checkpoint_interval + job_to_queue->dump_time));
+                if (meta_doc.HasMember("work_progress"))
+                {
+                    double work = meta_doc["work_progress"].GetDouble();
+                    if (num_checkpoints_completed > 0)
+                        work += num_checkpoints_completed * job_to_queue->checkpoint_interval;
+                    meta_doc["work_progress"] = work;
+                }
+                else if (num_checkpoints_completed > 0)
+                {
+                    meta_doc.AddMember("work_progress",rapidjson::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                }
+                if (meta_doc.HasMember("num_dumps"))
+                {
+                        int num_dumps = meta_doc["num_dumps"].GetInt();
+                        if (num_checkpoints_completed > 0)
+                            num_dumps += num_checkpoints_completed;
+                        meta_doc["num_dumps"] = num_dumps;
+                        
+                }
+                else if (num_checkpoints_completed > 0)
+                {
+                        meta_doc.AddMember("num_dumps",rapidjson::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                    
+                }
+                std::string meta_str = to_json_desc(&meta_doc);
+                job_doc["metadata"].SetString(meta_str.c_str(),job_doc.GetAllocator());
+                // the progress_time needs to add back in the read_time
+                progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time) + job_to_queue->read_time;
+            
+            }
+            else // there hasn't been any checkpoints in the past, do normal check on num_checkpoints_completed
+            {
+                num_checkpoints_completed = floor(progress_time/(job_to_queue->checkpoint_interval + job_to_queue->dump_time ));
+                progress_time = num_checkpoints_completed * (job_to_queue->checkpoint_interval + job_to_queue->dump_time);
+                
+                
+                //if a checkpoint has completed set the metadata to reflect this
+                if (num_checkpoints_completed > 0)
+                {
+                    meta_doc.SetObject();
+                    //if there was previous metadata make sure to include it
+                    if (meta_str!="null")
+                    {
+                        meta_doc.Parse(meta_str.c_str());
+                    }    
+                    rapidjson::Document::AllocatorType& myAlloc = meta_doc.GetAllocator();
+                    meta_doc.AddMember("checkpointed",rapidjson::Value().SetBool(true),myAlloc);
+                    meta_doc.AddMember("num_dumps",rapidjson::Value().SetInt(num_checkpoints_completed),meta_doc.GetAllocator());
+                    meta_doc.AddMember("work_progress",rapidjson::Value().SetDouble(num_checkpoints_completed * job_to_queue->checkpoint_interval),meta_doc.GetAllocator());
+                    std::string myString = to_json_desc(&meta_doc);
+                    rapidjson::Document::AllocatorType& myAlloc2 = job_doc.GetAllocator();
+                                        
+                    if (meta_str=="null")
+                        job_doc.AddMember("metadata",rapidjson::Value().SetString(myString.c_str(),myAlloc2),myAlloc2);
+                    else
+                        job_doc["metadata"].SetString(myString.c_str(),myAlloc2);
+                }
+
+            }        
+            //only if a new checkpoint has been reached does the delay time change
+            //LOG_F(INFO,"REPAIR num_checkpoints_completed: %d",num_checkpoints_completed);
+            if (num_checkpoints_completed > 0)
+            {
+                //if we have checkpointed, the walltime can be reduced.  Reduce by the num of checkpoints. if _subtract_progress_from_walltime is false, skip
+                if (job_to_queue->walltime > 0 && job_doc.HasMember("walltime") && w0->_subtract_progress_from_walltime) 
+                {
+                    job_doc["walltime"].SetDouble( (double)job_to_queue->walltime - 
+                                         (num_checkpoints_completed * (job_to_queue->checkpoint_interval+job_to_queue->dump_time) - job_to_queue->read_time));
+                }
+                double delay = profile_doc["delay"].GetDouble() - progress_time + job_to_queue->read_time;
+                //LOG_F(INFO,"REPAIR delay: %f  readtime: %f",delay,job_to_queue->read_time);
+                profile_doc["delay"].SetDouble(delay);
+                
+                
+            }
+        }
+    
+    }
+                                    
+            
+}
 
 void SchedulingDecision::add_submit_profile(const string &workload_name,
                                             const string &profile_name,
@@ -88,9 +459,14 @@
     _proto_writer->append_set_job_metadata(job_id, metadata, date);
 }
 
-void SchedulingDecision::add_call_me_later(double future_date, double date)
+void SchedulingDecision::add_call_me_later(batsched_tools::call_me_later_types forWhat, int id,double future_date, double date)
 {
-    _proto_writer->append_call_me_later(future_date, date);
+    _proto_writer->append_call_me_later(forWhat,id, future_date, date);
+}
+
+void SchedulingDecision::add_generic_notification(const std::string &type,const std::string & notify_data,double date)
+{
+    _proto_writer->append_generic_notification(type,notify_data,date);
 }
 
 void SchedulingDecision::add_scheduler_finished_submitting_jobs(double date)
@@ -98,6 +474,11 @@
     _proto_writer->append_scheduler_finished_submitting_jobs(date);
 }
 
+void SchedulingDecision::add_scheduler_continue_submitting_jobs(double date)
+{
+    _proto_writer->append_scheduler_continue_submitting_jobs(date);
+}
+
 void SchedulingDecision::add_query_energy_consumption(double date)
 {
     _proto_writer->append_query_consumed_energy(date);
diff -burN '--exclude=.git*' ./batsched/src/decision.hpp ./new_batsched/src/decision.hpp
--- ./batsched/src/decision.hpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/decision.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -4,6 +4,9 @@
 #include <string>
 
 #include <intervalset.hpp>
+#include "json_workload.hpp"
+#include "batsched_tools.hpp"
+#include <utility>
 
 class AbstractProtocolWriter;
 class RedisStorage;
@@ -16,8 +19,9 @@
 
     void add_execute_job(const std::string &job_id, const IntervalSet & machine_ids, double date,
                          std::vector<int> executor_to_allocated_resource_mapping = {});
+    void handle_resubmission(std::unordered_map<std::string,batsched_tools::Job_Message *> recently_killed_jobs,Workload * workload,double date);
     void add_reject_job(const std::string &job_id, double date);
-    void add_kill_job(const std::vector<std::string> & job_ids, double date);
+    void add_kill_job(const std::vector<batsched_tools::Job_Message *> & job_msgs, double date);
 
     /**
      * @brief add_submit_jobs
@@ -47,8 +51,10 @@
                               const std::string & metadata,
                               double date);
 
-    void add_call_me_later(double future_date, double date);
+    void add_call_me_later(batsched_tools::call_me_later_types forWhat, int id, double future_date, double date);
     void add_scheduler_finished_submitting_jobs(double date);
+    void add_scheduler_continue_submitting_jobs(double date);
+    void add_generic_notification(const std::string &type,const std::string &notify_data,double date);
 
     void add_query_energy_consumption(double date);
     void add_answer_estimate_waiting_time(const std::string & job_id,
@@ -61,8 +67,20 @@
     double last_date() const;
 
     void set_redis(bool enabled, RedisStorage * redis);
+    std::string to_json_desc(rapidjson::Document * doc);
+
 
 private:
+    void get_meta_data_from_delay(std::pair<std::string,batsched_tools::Job_Message *> killed_map, 
+                                                        rapidjson::Document & profile_doc,
+                                                        rapidjson::Document & job_doc,
+                                                        Workload * w0);
+    void get_meta_data_from_parallel_homogeneous(std::pair<std::string,batsched_tools::Job_Message *> killed_map,
+                                                        rapidjson::Document & profile_doc,
+                                                        rapidjson::Document & job_doc,
+                                                        Workload* w0);
+    
+    
     AbstractProtocolWriter * _proto_writer = nullptr;
     bool _redis_enabled = false;
     RedisStorage * _redis = nullptr;
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_job.cpp ./new_batsched/src/external/batsched_job.cpp
--- ./batsched/src/external/batsched_job.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_job.cpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,463 @@
+#include <string>
+#include <fstream>
+#include <streambuf>
+#include <algorithm>
+#include <regex>
+#include <math.h>
+
+#include <boost/algorithm/string.hpp>
+#include <boost/algorithm/string/join.hpp>
+#include <loguru.hpp>
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <rapidjson/stringbuffer.h>
+#include "batsched_job.hpp"
+#include "batsched_profile.hpp"
+#include "batsched_workload.hpp"
+
+using namespace rapidjson;
+namespace myBatsched{
+Jobs::~Jobs()
+{
+    _jobs.clear();
+}
+
+JobIdentifier::JobIdentifier(const std::string & workload_name,
+                             const std::string & job_name) :
+    _workload_name(workload_name),
+    _job_name(job_name)
+{
+    _representation = representation();
+}
+
+JobIdentifier::JobIdentifier(const std::string & job_id_str)
+{
+    // Split the job_identifier by '!'
+    std::vector<std::string> job_identifier_parts;
+    boost::split(job_identifier_parts, job_id_str,
+                 boost::is_any_of("!"), boost::token_compress_on);
+
+    CHECK_F(job_identifier_parts.size() == 2,
+               "Invalid string job identifier '%s': should be formatted as two '!'-separated "
+               "parts, the second one being any string without '!'. Example: 'some_text!42'.",
+               job_id_str.c_str());
+
+    this->_workload_name = job_identifier_parts[0];
+    this->_job_name = job_identifier_parts[1];
+    _representation = representation();
+}
+std::string JobIdentifier::to_string() const
+{
+    return _representation;
+}
+const char *JobIdentifier::to_cstring() const
+{
+    return _representation.c_str();
+}
+std::string JobIdentifier::representation() const
+{
+    return _workload_name + '!' + _job_name;
+}
+bool operator<(const JobIdentifier &ji1, const JobIdentifier &ji2)
+{
+    return ji1.to_string() < ji2.to_string();
+}
+
+bool operator==(const JobIdentifier &ji1, const JobIdentifier &ji2)
+{
+    return ji1.to_string() == ji2.to_string();
+}
+std::size_t JobIdentifierHasher::operator()(const JobIdentifier & id) const
+{
+    return std::hash<std::string>()(id.to_string());
+}
+std::string JobIdentifier::workload_name() const
+{
+    return _workload_name;
+}
+
+std::string JobIdentifier::job_name() const
+{
+    return _job_name;
+}
+
+void Jobs::set_profiles(Profiles *profiles)
+{
+    _profiles = profiles;
+}
+
+void Jobs::set_workload(Workload *workload)
+{
+    _workload = workload;
+}
+void Jobs::add_job(JobPtr job)
+{
+ _jobs[job->id]=job;
+ _jobs_met.insert({job->id,true}); // not sure about this, whether it's really needed or not    
+    
+}
+void Jobs::load_from_json(const rapidjson::Document &doc, const std::string &filename)
+{
+    std::string error_prefix = "Invalid JSON file '" + filename + "'";
+
+    CHECK_F(doc.IsObject(), "%s: not a JSON object", error_prefix.c_str());
+    CHECK_F(doc.HasMember("jobs"), "%s: the 'jobs' array is missing", error_prefix.c_str());
+    const Value & jobs = doc["jobs"];
+    if (jobs.IsArray())
+    {
+
+        for (SizeType i = 0; i < jobs.Size(); i++) // Uses SizeType instead of size_t
+        {
+            //const Value & job_json_description = jobs[i];
+            std::string job_desc = jobs[i].GetString();
+            LOG_F(INFO,"our string: %s",job_desc.c_str());
+            job_desc=Job::not_escaped(job_desc);
+            LOG_F(INFO,"after not_escaped");
+            Document d;
+            d.Parse(job_desc.c_str());
+            const rapidjson::Value & job_json_description = d.GetObject();
+            auto j = Job::from_json(job_json_description, _workload, error_prefix);
+            LOG_F(INFO,"after from_json");
+            CHECK_F(!exists(j->id), "%s: duplication of job id '%s'",
+                    error_prefix.c_str(), j->id.to_string().c_str());
+            _jobs[j->id] = j;
+            _jobs_met.insert({j->id, true});
+        }
+    }
+    
+}
+
+std::string Job::not_escaped(const std::string& input)
+{
+    std::string output;
+    output.reserve(input.size());
+    for (const char c: input) {
+        switch (c) {
+            case '\\':  output += "";        break;
+            default:    output += c;            break;
+        }
+    }
+
+    return output;
+}
+std::string Job::to_json_desc(rapidjson::Document * doc)
+{
+  rapidjson::StringBuffer buffer;
+
+  buffer.Clear();
+
+  rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+  doc->Accept(writer);
+
+  return std::string( buffer.GetString() );
+}
+JobPtr Job::from_json(const rapidjson::Value & json_desc,
+                     Workload * workload,
+                     const std::string & error_prefix)
+{
+        
+    // Create and initialize with default values
+    auto j =std::make_shared<Job>();
+    j->workload = workload;
+    j->starting_time = -1;
+    j->runtime = -1;
+    j->state = JobState::JOB_STATE_NOT_SUBMITTED;
+    j->cores = 1;
+    j->purpose = "job";
+    j->start = -1.0;
+    j->future_allocation;
+    
+
+    CHECK_F(json_desc.IsObject(), "%s: one job is not an object", error_prefix.c_str());
+
+    // Get job id and create a JobIdentifier
+    CHECK_F(json_desc.HasMember("id"), "%s: one job has no 'id' field", error_prefix.c_str());
+    CHECK_F(json_desc["id"].IsString() || json_desc["id"].IsInt(), "%s: on job id field is invalid, it should be a string or an integer", error_prefix.c_str());
+    std::string job_id_str;
+    if (json_desc["id"].IsString())
+    {
+        job_id_str = json_desc["id"].GetString();
+    }
+    else if (json_desc["id"].IsInt())
+    {
+        job_id_str = std::to_string(json_desc["id"].GetInt());
+    }
+
+    if (job_id_str.find(workload->name) == std::string::npos)
+    {
+        // the workload name is not present in the job id string
+        j->id = JobIdentifier(workload->name, job_id_str);
+    }
+    else
+    {
+        j->id = JobIdentifier(job_id_str);
+    }
+
+    // Get submission time
+    CHECK_F(json_desc.HasMember("subtime"), "%s: job '%s' has no 'subtime' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+    CHECK_F(json_desc["subtime"].IsNumber(), "%s: job '%s' has a non-number 'subtime' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+    j->submission_time = static_cast<long double>(json_desc["subtime"].GetDouble());
+
+    // Get walltime (optional)
+    if (!json_desc.HasMember("walltime"))
+    {
+        LOG_F(INFO,"job '%s' has no 'walltime' field", j->id.to_string().c_str());
+    }
+    else
+    {
+        CHECK_F(json_desc["walltime"].IsNumber(), "%s: job %s has a non-number 'walltime' field",
+                   error_prefix.c_str(), j->id.to_string().c_str());
+        j->walltime = static_cast<long double>(json_desc["walltime"].GetDouble());
+    }
+    CHECK_F(j->walltime == -1 || j->walltime > 0,
+               "%s: job '%s' has an invalid walltime (%Lg). It should either be -1 (no walltime) "
+               "or a strictly positive number.",
+               error_prefix.c_str(), j->id.to_string().c_str(), j->walltime);
+
+    // Get number of requested resources
+    CHECK_F(json_desc.HasMember("res"), "%s: job %s has no 'res' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+    CHECK_F(json_desc["res"].IsInt(), "%s: job %s has a non-number 'res' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+    CHECK_F(json_desc["res"].GetInt() >= 0, "%s: job %s has a negative 'res' field (%d)",
+               error_prefix.c_str(), j->id.to_string().c_str(), json_desc["res"].GetInt());
+    j->requested_nb_res = static_cast<unsigned int>(json_desc["res"].GetInt());
+
+    // Get the job profile
+    CHECK_F(json_desc.HasMember("profile"), "%s: job %s has no 'profile' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+    CHECK_F(json_desc["profile"].IsString(), "%s: job %s has a non-string 'profile' field",
+               error_prefix.c_str(), j->id.to_string().c_str());
+
+    // TODO raise exception when the profile does not exist.
+    std::string profile_name = json_desc["profile"].GetString();
+    CHECK_F(workload->profiles->exists(profile_name), "%s: the profile %s for job %s does not exist",
+               error_prefix.c_str(), profile_name.c_str(), j->id.to_string().c_str());
+    j->profile = workload->profiles->at(profile_name);
+    
+    if (json_desc.HasMember("cores"))
+    {
+        CHECK_F(json_desc["cores"].IsInt(), "%s: job %s has a non-number 'cores' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        CHECK_F(json_desc["cores"].GetInt() >= 0, "%s: job %s has a negative 'cores' field (%d)",
+               error_prefix.c_str(), j->id.to_string().c_str(), json_desc["cores"].GetInt());
+        j->cores = json_desc["cores"].GetInt();
+        
+    }
+     if (json_desc.HasMember("purpose"))
+    {
+        CHECK_F(json_desc["purpose"].IsString(), "%s: job %s has a non-string 'purpose' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        j->purpose = json_desc["purpose"].GetString();
+        
+    }
+    if (json_desc.HasMember("start"))
+    {
+        CHECK_F(json_desc["start"].IsNumber(), "%s: job %s has a non-number 'start' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        j->start = json_desc["start"].GetDouble();
+    }
+    if (json_desc.HasMember("alloc"))
+    {
+        CHECK_F(json_desc["alloc"].IsString(), "%s: job %s has a non-string 'alloc' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        j->future_allocation = IntervalSet::from_string_hyphen(json_desc["alloc"].GetString()," ","-");
+    }
+    if(workload->_checkpointing_on)
+    {
+    
+        //***** got rid of CHECK_F statements as checkpointing is optional so, so are the fields
+        /*CHECK_F(json_desc.HasMember("checkpoint"),"%s: job %s has no 'checkpoint' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        CHECK_F(json_desc["checkpoint"].IsNumber(), "%s: job %s has non double 'checkpoint' field",
+                error_prefix.c_str(),j->id.to_string().c_str()); */
+        if (json_desc.HasMember("checkpoint") && json_desc["checkpoint"].IsNumber())
+            j->checkpoint_interval=json_desc["checkpoint"].GetDouble();
+        /*
+        CHECK_F(json_desc.HasMember("dumptime"),"%s: job %s has no 'dumptime' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        CHECK_F(json_desc["dumptime"].IsNumber(), "%s: job %s has non double 'dumptime' field",
+                error_prefix.c_str(),j->id.to_string().c_str());   */
+        if (json_desc.HasMember("dumptime") && json_desc["dumptime"].IsNumber())
+            j->dump_time=json_desc["dumptime"].GetDouble();
+        /*
+        CHECK_F(json_desc.HasMember("readtime"),"%s: job %s has no 'readtime' field",
+                error_prefix.c_str(),j->id.to_string().c_str());
+        CHECK_F(json_desc["readtime"].IsNumber(), "%s: job %s has non double 'readtime' field",
+                error_prefix.c_str(),j->id.to_string().c_str()); */
+        if (json_desc.HasMember("readtime") && json_desc["readtime"].IsNumber())
+            j->read_time=json_desc["readtime"].GetDouble();
+        
+        /*if (j->id.job_name().find("#")== std::string::npos)
+        {    
+            Document profile_doc;
+            profile_doc.Parse(j->profile->json_description.c_str());
+            
+            DelayProfileData * data =static_cast<DelayProfileData *>(j->profile->data);
+            double delay = data->delay;
+            int subtract = 0;
+            data->real_delay = delay;
+            if (std::fmod(delay,j->checkpoint_interval) == 0)
+                subtract = 1;
+            delay = (floor(delay / j->checkpoint_interval) - subtract )* j->dump_time + delay;
+            data->delay = delay;
+            j->profile->data = data;
+            profile_doc["delay"]=delay;
+            j->profile->json_description = Job::to_json_desc(& profile_doc);
+           LOG_F(INFO,"DEBUG delay: %f",delay);
+           LOG_F(INFO,"DEBUG profile data %f",(static_cast<DelayProfileData *>(j->profile->data))->delay);
+        }
+        }*/
+    
+    }
+    LOG_F(INFO,"Profile name %s and '%s'", profile_name.c_str(), j->profile->name.c_str());
+    // Let's get the JSON string which originally described the job
+    // (to conserve potential fields unused by Batsim)
+    rapidjson::StringBuffer buffer;
+    rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+    json_desc.Accept(writer);
+
+    // Let's replace the job ID by its WLOAD!NUMBER counterpart if needed
+    // in the json raw description
+    std::string json_description_tmp(buffer.GetString(), buffer.GetSize());
+    /// @cond DOXYGEN_FAILS_PARSING_THIS_REGEX
+    std::regex r(R"("id"\s*:\s*(?:"*[^(,|})]*"*)\s*)");
+    /// @endcond
+    std::string replacement_str = "\"id\":\"" + j->id.to_string() + "\"";
+    // LOG_F(INFO,"Before regexp: %s", json_description_tmp.c_str());
+    j->json_description = std::regex_replace(json_description_tmp, r, replacement_str);
+
+    // Let's check that the new description is a valid JSON string
+    rapidjson::Document check_doc;
+    check_doc.Parse(j->json_description.c_str());
+    CHECK_F(!check_doc.HasParseError(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart:"
+               "The output string '%s' is not valid JSON.", j->json_description.c_str());
+    CHECK_F(check_doc.IsObject(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output string '%s' is not valid JSON.", j->json_description.c_str());
+    CHECK_F(check_doc.HasMember("id"),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has no 'id' field.", j->json_description.c_str());
+    CHECK_F(check_doc["id"].IsString(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has a non-string 'id' field.", j->json_description.c_str());
+    CHECK_F(check_doc.HasMember("subtime") && check_doc["subtime"].IsNumber(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has no 'subtime' field (or it is not a number)",
+               j->json_description.c_str());
+    CHECK_F((check_doc.HasMember("walltime") && check_doc["walltime"].IsNumber())
+               || (!check_doc.HasMember("walltime")),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has no 'walltime' field (or it is not a number)",
+               j->json_description.c_str());
+    CHECK_F(check_doc.HasMember("res") && check_doc["res"].IsInt(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has no 'res' field (or it is not an integer)",
+               j->json_description.c_str());
+    CHECK_F(check_doc.HasMember("profile") && check_doc["profile"].IsString(),
+               "A problem occured when replacing the job_id by its WLOAD!job_name counterpart: "
+               "The output JSON '%s' has no 'profile' field (or it is not a string)",
+               j->json_description.c_str());
+
+    if (json_desc.HasMember("smpi_ranks_to_hosts_mapping"))
+    {
+        CHECK_F(json_desc["smpi_ranks_to_hosts_mapping"].IsArray(),
+                "%s: job '%s' has a non-array 'smpi_ranks_to_hosts_mapping' field",
+                error_prefix.c_str(), j->id.to_string().c_str());
+
+        const auto & mapping_array = json_desc["smpi_ranks_to_hosts_mapping"];
+        j->smpi_ranks_to_hosts_mapping.resize(mapping_array.Size());
+
+        for (unsigned int i = 0; i < mapping_array.Size(); ++i)
+        {
+            CHECK_F(mapping_array[i].IsInt(),
+                       "%s: job '%s' has a bad 'smpi_ranks_to_hosts_mapping' field: rank "
+                       "%d does not point to an integral number",
+                       error_prefix.c_str(), j->id.to_string().c_str(), i);
+            int host_number = mapping_array[i].GetInt();
+            CHECK_F(host_number >= 0 && static_cast<unsigned int>(host_number) < j->requested_nb_res,
+                       "%s: job '%s' has a bad 'smpi_ranks_to_hosts_mapping' field: rank "
+                       "%d has an invalid value %d : should be in [0,%d[",
+                       error_prefix.c_str(), j->id.to_string().c_str(),
+                       i, host_number, j->requested_nb_res);
+
+            j->smpi_ranks_to_hosts_mapping[i] = host_number;
+        }
+    }
+
+    LOG_F(INFO,"Job '%s' Loaded", j->id.to_string().c_str());
+    return j;
+}
+
+// Do NOT remove namespaces in the arguments (to avoid doxygen warnings)
+JobPtr Job::from_json(const std::string & json_str,
+                     Workload * workload,
+                     const std::string & error_prefix)
+{
+    
+    Document doc;
+    doc.Parse(json_str.c_str());
+    LOG_F(INFO,"after parse");
+    CHECK_F(!doc.HasParseError(),
+               "%s: Cannot be parsed. Content (between '##'):\n#%s#",
+               error_prefix.c_str(), json_str.c_str());
+
+    return Job::from_json(doc, workload, error_prefix);
+}
+int Jobs::nb_jobs() const
+{
+    return static_cast<int>(_jobs.size());
+}
+bool Jobs::exists(const JobIdentifier & job_id) const
+{
+    auto it = _jobs_met.find(job_id);
+    return it != _jobs_met.end();
+}
+std::unordered_map<JobIdentifier, JobPtr,JobIdentifierHasher> &Jobs::jobs()
+{
+    return _jobs;
+}
+
+JobPtr Jobs::operator[](JobIdentifier job_id)
+{
+    auto it = _jobs.find(job_id);
+    CHECK_F(it != _jobs.end(), "Cannot get job '%s': it does not exist",
+               job_id.to_cstring());
+    return it->second;
+}
+void Jobs::delete_job(const JobIdentifier & job_id, const bool & garbage_collect_profiles)
+{
+    CHECK_F(exists(job_id),
+               "Bad Jobs::delete_job call: The job with name='%s' does not exist.",
+               job_id.to_cstring());
+
+    std::string profile_name = _jobs[job_id]->profile->name;
+    _jobs.erase(job_id);
+    if (garbage_collect_profiles)
+    {
+        _workload->profiles->remove_profile(profile_name);
+    }
+}
+
+const JobPtr Jobs::operator[](JobIdentifier job_id) const
+{
+    auto it = _jobs.find(job_id);
+    CHECK_F(it != _jobs.end(), "Cannot get job '%s': it does not exist",
+               job_id.to_cstring());
+    return it->second;
+}
+
+JobPtr Jobs::at(JobIdentifier job_id)
+{
+    return operator[](job_id);
+}
+
+const JobPtr Jobs::at(JobIdentifier job_id) const
+{
+    return operator[](job_id);
+}
+}
+
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_job.hpp ./new_batsched/src/external/batsched_job.hpp
--- ./batsched/src/external/batsched_job.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_job.hpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,214 @@
+#ifndef BATSCHED_JOB_HPP
+#define BATSCHED_JOB_HPP
+
+#include <unordered_map>
+#include <vector>
+#include <rapidjson/document.h>
+#include <intervalset.hpp>
+
+#include "pointers.hpp"
+
+
+namespace myBatsched{
+class Profiles;
+struct Profile;
+class Workload;
+struct Job;
+enum class JobState
+{
+     JOB_STATE_NOT_SUBMITTED                //!< The job exists but cannot be scheduled yet.
+    ,JOB_STATE_SUBMITTED                    //!< The job has been submitted, it can now be scheduled.
+    ,JOB_STATE_RUNNING                      //!< The job has been scheduled and is currently being processed.
+    ,JOB_STATE_COMPLETED_SUCCESSFULLY       //!< The job execution finished before its walltime successfully.
+    ,JOB_STATE_COMPLETED_FAILED             //!< The job execution finished before its walltime but the job failed.
+    ,JOB_STATE_COMPLETED_WALLTIME_REACHED   //!< The job has reached its walltime and has been killed.
+    ,JOB_STATE_COMPLETED_KILLED             //!< The job has been killed.
+    ,JOB_STATE_REJECTED                     //!< The job has been rejected by the scheduler.
+};
+
+class JobIdentifier
+{
+public:
+    
+    JobIdentifier() = default;
+    /**
+     * @brief Creates a JobIdentifier
+     * @param[in] workload_name The workload name
+     * @param[in] job_name The job name
+     */
+    explicit JobIdentifier(const std::string & workload_name,
+                           const std::string & job_name);
+
+    /**
+     * @brief Creates a JobIdentifier from a string to parse
+     * @param[in] job_id_str The string to parse
+     */
+    explicit JobIdentifier(const std::string & job_id_str);
+
+    std::string _workload_name;
+    std::string _job_name;
+    std::string _representation;
+
+    std::string representation() const;
+    std::string to_string() const;
+      /**
+     * @brief Returns a null-terminated C string of the JobIdentifier representation.
+     * @return A null-terminated C string of the JobIdentifier representation.
+     */
+    const char * to_cstring() const;
+    std::string workload_name() const;
+
+    /**
+     * @brief Returns the job name within the workload.
+     * @return The job name within the workload.
+     */
+    std::string job_name() const;
+    
+};
+/**
+ * @brief Compares two JobIdentifier thanks to their string representations
+ * @param[in] ji1 The first JobIdentifier
+ * @param[in] ji2 The second JobIdentifier
+ * @return ji1.to_string() < ji2.to_string()
+ */
+bool operator<(const JobIdentifier & ji1, const JobIdentifier & ji2);
+
+/**
+ * @brief Compares two JobIdentifier thanks to their string representations
+ * @param[in] ji1 The first JobIdentifier
+ * @param[in] ji2 The second JobIdentifier
+ * @return ji1.to_string() == ji2.to_string()
+ */
+bool operator==(const JobIdentifier & ji1, const JobIdentifier & ji2);
+struct JobIdentifierHasher
+{
+    /**
+     * @brief Hashes a JobIdentifier.
+     * @param[in] id The JobIdentifier to hash.
+     * @return Whatever is returned by std::hash to match C++ conventions.
+     */
+    std::size_t operator()(const JobIdentifier & id) const;
+};
+struct Job
+{
+        Job()=default;
+        
+        
+        
+        Workload * workload = nullptr;
+        JobIdentifier id;
+        std::string json_description;
+        IntervalSet allocation;
+        std::string metadata;
+        std::vector<int> smpi_ranks_to_hosts_mapping; //!< If the job uses a SMPI profile, stores which host number each MPI rank should use. These numbers must be in [0,required_nb_res[.
+        
+        JobState state;
+        long double starting_time;
+        long double runtime;
+        bool kill_requested = false;
+        ProfilePtr profile;
+        long double submission_time;
+        long double walltime=-1;
+        unsigned int requested_nb_res;
+        double checkpoint_interval;
+        double dump_time;
+        double read_time;
+        int cores=1;
+        std::string purpose = "job";
+        double start;
+        IntervalSet future_allocation; 
+public:
+    static JobPtr from_json(const rapidjson::Value & json_desc,
+                           Workload * workload,
+                           const std::string & error_prefix = "Invalid JSON job");
+
+    /**
+     * @brief Creates a new-allocated Job from a JSON description
+     * @param[in] json_str The JSON description of the job (as a string)
+     * @param[in] workload The Workload the job is in
+     * @param[in] error_prefix The prefix to display when an error occurs
+     * @return The newly allocated Job
+     * @pre The JSON description of the job is valid
+     */
+    static JobPtr from_json(const std::string & json_str,
+                           Workload * workload,
+                           const std::string & error_prefix = "Invalid JSON job");
+    /**
+     * @brief Checks whether a job is complete (regardless of the job success)
+     * @return true if the job is complete (=has started then finished), false otherwise.
+     */
+    bool is_complete() const;
+    
+    static std::string to_json_desc(rapidjson::Document * doc);
+    static std::string not_escaped(const std::string & input);
+
+    //! Functor to hash a JobIdentifier
+    
+    
+};
+
+class Jobs
+{
+public:
+    
+    Jobs() = default;
+    ~Jobs();
+public:    
+    void set_profiles(Profiles * profiles);
+    void set_workload(Workload * workload);
+    void load_from_json(const rapidjson::Document & doc, const std::string & filename);
+    void add_job(JobPtr job);
+    int nb_jobs() const;
+    bool exists(const JobIdentifier & job_id) const;
+       /**
+     * @brief Returns a reference to the map that contains the jobs
+     * @return A reference to the map that contains the jobs
+     */
+    std::unordered_map<JobIdentifier, JobPtr,JobIdentifierHasher> & jobs();
+        /**
+     * @brief Accesses one job thanks to its identifier
+     * @param[in] job_id The job id
+     * @return A pointer to the job associated to the given job id
+     */
+    JobPtr operator[](JobIdentifier job_id);
+
+    /**
+     * @brief Accesses one job thanks to its unique name (const version)
+     * @param[in] job_id The job id
+     * @return A (const) pointer to the job associated to the given job id
+     */
+    const JobPtr operator[](JobIdentifier job_id) const;
+
+    /**
+     * @brief Accesses one job thanks to its unique id
+     * @param[in] job_id The job unique id
+     * @return A pointer to the job associated to the given job id
+     */
+    JobPtr at(JobIdentifier job_id);
+
+    /**
+     * @brief Accesses one job thanks to its unique id (const version)
+     * @param[in] job_id The job unique name
+     * @return A (const) pointer to the job associated to the given job
+     * name
+     */
+    const JobPtr at(JobIdentifier job_id) const;
+   /**
+     * @brief Deletes a job
+     * @param[in] job_id The identifier of the job to delete
+     * @param[in] garbage_collect_profiles Whether to garbage collect its profiles
+     */
+    void delete_job(const JobIdentifier & job_id,
+                    const bool & garbage_collect_profiles);
+
+private:
+    std::unordered_map<JobIdentifier,JobPtr,JobIdentifierHasher> _jobs;
+    std::unordered_map<JobIdentifier, bool, JobIdentifierHasher> _jobs_met; //!< Stores the jobs id already met during the simulation
+    Profiles * _profiles = nullptr;
+    Workload * _workload=nullptr;
+    
+    
+};
+}
+
+#endif
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_profile.cpp ./new_batsched/src/external/batsched_profile.cpp
--- ./batsched/src/external/batsched_profile.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_profile.cpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,753 @@
+
+#include <fstream>
+#include <iostream>
+#if __has_include(<filesystem>)
+#include <filesystem>
+namespace fs = std::filesystem;
+#elif __has_include(<experimental/filesystem>)
+#include <experimental/filesystem>
+namespace fs = std::experimental::filesystem;
+#endif
+
+#include <boost/algorithm/string.hpp>
+#include <loguru.hpp>
+
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <rapidjson/stringbuffer.h>
+#include "pointers.hpp"
+#include "batsched_profile.hpp"
+
+using namespace rapidjson;
+//namespace fs = std::filesystem;
+namespace myBatsched{
+Profile::~Profile()
+{
+    LOG_F(INFO,"Profile '%s' is being deleted.", name.c_str());
+    if (type == ProfileType::DELAY)
+    {
+        auto * d = static_cast<DelayProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+            
+        }
+    }
+    else if (type == ProfileType::PARALLEL)
+    {
+        auto * d = static_cast<ParallelProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::PARALLEL_HOMOGENEOUS)
+    {
+        auto * d = static_cast<ParallelHomogeneousProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT)
+    {
+        auto * d = static_cast<ParallelHomogeneousTotalAmountProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::SMPI)
+    {
+        auto * d = static_cast<SmpiProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::SEQUENCE)
+    {
+        auto * d = static_cast<SequenceProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::PARALLEL_HOMOGENEOUS_PFS)
+    {
+        auto * d = static_cast<ParallelHomogeneousPFSProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::DATA_STAGING)
+    {
+        auto * d = static_cast<DataStagingProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::SCHEDULER_SEND)
+    {
+        auto * d = static_cast<SchedulerSendProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else if (type == ProfileType::SCHEDULER_RECV)
+    {
+        auto * d = static_cast<SchedulerRecvProfileData *>(data);
+        if (d != nullptr)
+        {
+            delete d;
+            d = nullptr;
+        }
+    }
+    else
+    {
+        LOG_F(INFO,"Deletion of an unknown profile type (%d)", static_cast<int>(type));
+    }
+}
+ParallelProfileData::~ParallelProfileData()
+{
+    if (cpu != nullptr)
+    {
+        delete[] cpu;
+        cpu = nullptr;
+    }
+    if (com != nullptr)
+    {
+        delete[] com;
+        com = nullptr;
+    }
+}
+// Do NOT remove namespaces in the arguments (to avoid doxygen warnings)
+ProfilePtr Profile::from_json(const std::string & profile_name,
+                            const rapidjson::Value & json_desc,
+                            const std::string & error_prefix,
+                            bool is_from_a_file,
+                            const std::string & json_filename)
+{
+    (void) error_prefix; // Avoids a warning if assertions are ignored
+
+    auto profile = std::make_shared<Profile>();
+    profile->name = profile_name;
+
+    CHECK_F(json_desc.IsObject(), "%s: profile '%s' value must be an object",
+               error_prefix.c_str(), profile_name.c_str());
+    CHECK_F(json_desc.HasMember("type"), "%s: profile '%s' has no 'type' field",
+               error_prefix.c_str(), profile_name.c_str());
+    CHECK_F(json_desc["type"].IsString(), "%s: profile '%s' has a non-string 'type' field",
+               error_prefix.c_str(), profile_name.c_str());
+
+    std::string profile_type = json_desc["type"].GetString();
+
+    int return_code = 0;
+    if (json_desc.HasMember("ret"))
+    {
+        return_code = json_desc["ret"].GetInt();
+    }
+    profile->return_code = return_code;
+
+    if (profile_type == "delay")
+    {
+        /*
+        {
+            "type": "delay",
+            "delay": 20.20
+        }
+        */
+        
+        profile->type = ProfileType::DELAY;
+        DelayProfileData * data = new DelayProfileData;
+        
+        CHECK_F(json_desc.HasMember("delay"), "%s: profile '%s' has no 'delay' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["delay"].IsNumber(), "%s: profile '%s' has a non-number 'delay' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        
+        data->delay = json_desc["delay"].GetDouble();
+        
+        if (json_desc.HasMember("original_delay")){
+            data->real_delay = json_desc["original_delay"].GetDouble();
+        }
+        else{
+            data->real_delay = data->delay;
+        }
+        
+        CHECK_F(data->delay > 0, "%s: profile '%s' has a non-strictly-positive 'delay' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->delay);
+        
+        profile->data = data;
+        
+    }
+    else if (profile_type == "parallel")
+    {
+        /*
+        {
+            "type": "parallel",
+            "cpu": [5e6,  0,  0,  0],
+            "com": [5e6,  0,  0,  0,
+                    5e6,5e6,  0,  0,
+                    5e6,5e6,  0,  0,
+                    5e6,5e6,5e6,  0]
+        }
+        */
+        profile->type = ProfileType::PARALLEL;
+        ParallelProfileData * data = new ParallelProfileData;
+
+        // basic checks
+        CHECK_F(json_desc.HasMember("cpu"), "%s: profile '%s' has no 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc.HasMember("com"), "%s: profile '%s' has no 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+
+        // get and check CPU vector
+        const Value & cpu = json_desc["cpu"];
+        CHECK_F(cpu.IsArray(), "%s: profile '%s' has a non-array 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(cpu.Size() > 0, "%s: profile '%s' has an invalid-sized array 'cpu' (size=%d): "
+                   "must be strictly positive",
+                   error_prefix.c_str(), profile_name.c_str(), cpu.Size());
+
+        data->nb_res = cpu.Size();
+        data->cpu = new double[data->nb_res];
+        for (unsigned int i = 0; i < cpu.Size(); ++i)
+        {
+            CHECK_F(cpu[i].IsNumber(), "%s: profile '%s' computation array is invalid: all "
+                       "elements must be numbers", error_prefix.c_str(), profile_name.c_str());
+            data->cpu[i] = cpu[i].GetDouble();
+            CHECK_F(data->cpu[i] >= 0, "%s: profile '%s' computation array is invalid: all "
+                       "elements must be non-negative", error_prefix.c_str(), profile_name.c_str());
+        }
+
+        // get and check Comm vector
+        const Value & com = json_desc["com"];
+        CHECK_F(com.IsArray(), "%s: profile '%s' has a non-array 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(com.Size() == data->nb_res * data->nb_res, "%s: profile '%s' is incoherent: "
+                   "com array has size %d whereas the required array size is %d",
+                   error_prefix.c_str(), profile_name.c_str(), com.Size(), data->nb_res * data->nb_res);
+
+        data->com = new double[data->nb_res * data->nb_res];
+        for (unsigned int i = 0; i < com.Size(); ++i)
+        {
+            CHECK_F(com[i].IsNumber(), "%s: profile '%s' communication array is invalid: all "
+                       "elements must be numbers", error_prefix.c_str(), profile_name.c_str());
+            data->com[i] = com[i].GetDouble();
+            CHECK_F(data->com[i] >= 0, "%s: profile '%s' communication array is invalid: all "
+                       "elements must be non-negative", error_prefix.c_str(), profile_name.c_str());
+        }
+
+        profile->data = data;
+    }
+    else if (profile_type == "parallel_homogeneous")
+    {
+        /*
+        {
+            "type": "parallel_homogeneous",
+            "cpu": 10e6,
+            "com": 1e6
+        }
+        */
+        profile->type = ProfileType::PARALLEL_HOMOGENEOUS;
+        ParallelHomogeneousProfileData * data = new ParallelHomogeneousProfileData;
+
+        CHECK_F(json_desc.HasMember("cpu"), "%s: profile '%s' has no 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["cpu"].IsNumber(), "%s: profile '%s' has a non-number 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->cpu = json_desc["cpu"].GetDouble();
+        CHECK_F(data->cpu >= 0, "%s: profile '%s' has a non-positive 'cpu' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->cpu);
+
+        CHECK_F(json_desc.HasMember("com"), "%s: profile '%s' has no 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["com"].IsNumber(), "%s: profile '%s' has a non-number 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->com = json_desc["com"].GetDouble();
+        CHECK_F(data->com >= 0, "%s: profile '%s' has a non-positive 'com' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->com);
+
+        if (json_desc.HasMember("original_cpu")){
+            data->real_cpu = json_desc["original_cpu"].GetDouble();
+        }
+        else{
+            data->real_cpu = data->cpu;
+        }
+
+
+        profile->data = data;
+    }
+    else if (profile_type == "parallel_homogeneous_total")
+    {
+        /*
+        {
+            "type": "parallel_homogeneous_total",
+            "cpu": 10e6,
+            "com": 1e6
+        }
+        */
+        profile->type = ProfileType::PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT;
+        ParallelHomogeneousTotalAmountProfileData * data = new ParallelHomogeneousTotalAmountProfileData;
+
+        CHECK_F(json_desc.HasMember("cpu"), "%s: profile '%s' has no 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["cpu"].IsNumber(), "%s: profile '%s' has a non-number 'cpu' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->cpu = json_desc["cpu"].GetDouble();
+        CHECK_F(data->cpu >= 0, "%s: profile '%s' has a non-positive 'cpu' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->cpu);
+
+        CHECK_F(json_desc.HasMember("com"), "%s: profile '%s' has no 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["com"].IsNumber(), "%s: profile '%s' has a non-number 'com' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->com = json_desc["com"].GetDouble();
+        CHECK_F(data->com >= 0, "%s: profile '%s' has a non-positive 'com' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->com);
+
+        profile->data = data;
+    }
+    else if (profile_type == "composed")
+    {
+        /*
+        {
+            "type": "composed",
+            "repeat" : 4,
+            "seq": ["simple","homogeneous","simple"]
+        }
+        */
+        profile->type = ProfileType::SEQUENCE;
+        SequenceProfileData * data = new SequenceProfileData;
+
+        unsigned int repeat = 1;
+        if (json_desc.HasMember("repeat"))
+        {
+            CHECK_F(json_desc["repeat"].IsInt(), "%s: profile '%s' has a non-integral 'repeat' field",
+                   error_prefix.c_str(), profile_name.c_str());
+            CHECK_F(json_desc["repeat"].GetInt() >= 0, "%s: profile '%s' has a negative 'repeat' field (%d)",
+                   error_prefix.c_str(), profile_name.c_str(), json_desc["repeat"].GetInt());
+            repeat = static_cast<unsigned int>(json_desc["repeat"].GetInt());
+        }
+        data->repeat = repeat;
+
+        CHECK_F(data->repeat > 0, "%s: profile '%s' has a non-strictly-positive 'repeat' field (%d)",
+                   error_prefix.c_str(), profile_name.c_str(), data->repeat);
+
+        CHECK_F(json_desc.HasMember("seq"), "%s: profile '%s' has no 'seq' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["seq"].IsArray(), "%s: profile '%s' has a non-array 'seq' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        const Value & seq = json_desc["seq"];
+        CHECK_F(seq.Size() > 0, "%s: profile '%s' has an invalid array 'seq': its size must be "
+                   "strictly positive", error_prefix.c_str(), profile_name.c_str());
+        data->sequence.reserve(seq.Size());
+        for (unsigned int i = 0; i < seq.Size(); ++i)
+        {
+            data->sequence.push_back(std::string(seq[i].GetString()));
+        }
+
+        profile->data = data;
+    }
+    else if (profile_type == "parallel_homogeneous_pfs")
+    {
+        /*
+        {
+            "type": "parallel_homogeneous_pfs",
+            "bytes_to_read": 10e5,
+            "bytes_to_write": 10e5,
+            "storage": "my_io_node" //optional (default: 'pfs')
+        }
+        */
+        profile->type = ProfileType::PARALLEL_HOMOGENEOUS_PFS;
+        ParallelHomogeneousPFSProfileData * data = new ParallelHomogeneousPFSProfileData;
+
+        CHECK_F(json_desc.HasMember("bytes_to_read") or json_desc.HasMember("bytes_to_write"), "%s: profile '%s' has no 'bytes_to_read' or 'bytes_to_write' field (0 if not set)",
+                   error_prefix.c_str(), profile_name.c_str());
+        if (json_desc.HasMember("bytes_to_read"))
+        {
+            CHECK_F(json_desc["bytes_to_read"].IsNumber(), "%s: profile '%s' has a non-number 'bytes_to_read' field",
+                       error_prefix.c_str(), profile_name.c_str());
+            data->bytes_to_read = json_desc["bytes_to_read"].GetDouble();
+        }
+        if (json_desc.HasMember("bytes_to_write"))
+        {
+            CHECK_F(json_desc["bytes_to_write"].IsNumber(), "%s: profile '%s' has a non-number 'bytes_to_write' field",
+                       error_prefix.c_str(), profile_name.c_str());
+            data->bytes_to_write = json_desc["bytes_to_write"].GetDouble();
+        }
+
+        // If not set Use the "pfs" label by default
+        if (json_desc.HasMember("storage") or json_desc.HasMember("host"))
+        {
+            std::string key;
+            if (json_desc.HasMember("storage"))
+            {
+                key = "storage";
+            }
+            else
+            {
+                key = "host";
+
+            }
+            CHECK_F(json_desc[key.c_str()].IsString(),
+                           "%s: profile '%s' has a non-string '%s' field",
+                           error_prefix.c_str(), profile_name.c_str(),
+                           key.c_str());
+            data->storage_label = json_desc[key.c_str()].GetString();
+        }
+
+        profile->data = data;
+    }
+    else if (profile_type == "data_staging")
+    {
+        /*
+        {
+            "type": "data_staging",
+            "nb_bytes": 10e5,
+            "from": "pfs",
+            "to": "lcfs"
+        }
+        */
+        profile->type = ProfileType::DATA_STAGING;
+        DataStagingProfileData * data = new DataStagingProfileData;
+
+        CHECK_F(json_desc.HasMember("nb_bytes"), "%s: profile '%s' has no 'nb_bytes' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["nb_bytes"].IsNumber(), "%s: profile '%s' has a non-number 'nb_bytes' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->nb_bytes = json_desc["nb_bytes"].GetDouble();
+        CHECK_F(data->nb_bytes >= 0, "%s: profile '%s' has a non-positive 'nb_bytes' field (%g)",
+                   error_prefix.c_str(), profile_name.c_str(), data->nb_bytes);
+
+        CHECK_F(json_desc.HasMember("from"), "%s: profile '%s' has no 'from' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["from"].IsString(),
+                   "%s: profile '%s' has a non-string 'from' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->from_storage_label = json_desc["from"].GetString();
+
+        CHECK_F(json_desc.HasMember("to"), "%s: profile '%s' has no 'to' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["to"].IsString(),
+                   "%s: profile '%s' has a non-string 'to' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        data->to_storage_label = json_desc["to"].GetString();
+
+        profile->data = data;
+    }
+    else if (profile_type == "send")
+    {
+        profile->type = ProfileType::SCHEDULER_SEND;
+        SchedulerSendProfileData * data = new SchedulerSendProfileData;
+
+        CHECK_F(json_desc.HasMember("msg"), "%s: profile '%s' has no 'msg' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["msg"].IsObject(), "%s: profile '%s' field 'msg' is no object",
+                   error_prefix.c_str(), profile_name.c_str());
+
+        data->message.CopyFrom(json_desc["msg"], data->message.GetAllocator());
+
+        if (json_desc.HasMember("sleeptime"))
+        {
+            CHECK_F(json_desc["sleeptime"].IsNumber(),
+                       "%s: profile '%s' has a non-number 'sleeptime' field",
+                       error_prefix.c_str(), profile_name.c_str());
+            data->sleeptime = json_desc["sleeptime"].GetDouble();
+            CHECK_F(data->sleeptime > 0,
+                       "%s: profile '%s' has a non-positive 'sleeptime' field (%g)",
+                       error_prefix.c_str(), profile_name.c_str(), data->sleeptime);
+        }
+        else
+        {
+            data->sleeptime = 0.0000001;
+        }
+        profile->data = data;
+    }
+    else if (profile_type == "recv")
+    {
+        profile->type = ProfileType::SCHEDULER_RECV;
+        SchedulerRecvProfileData * data = new SchedulerRecvProfileData;
+
+        data->regex =std:: string(".*");
+        if (json_desc.HasMember("regex"))
+        {
+            data->regex = json_desc["regex"].GetString();
+        }
+
+        data->on_success = std::string("");
+        if (json_desc.HasMember("success"))
+        {
+            data->on_success = json_desc["success"].GetString();
+        }
+
+        data->on_failure = std::string("");
+        if (json_desc.HasMember("failure"))
+        {
+            data->on_failure = json_desc["failure"].GetString();
+        }
+
+        data->on_timeout = std::string("");
+        if (json_desc.HasMember("timeout"))
+        {
+            data->on_timeout = json_desc["timeout"].GetString();
+        }
+
+        if (json_desc.HasMember("polltime"))
+        {
+            CHECK_F(json_desc["polltime"].IsNumber(),
+                       "%s: profile '%s' has a non-number 'polltime' field",
+                       error_prefix.c_str(), profile_name.c_str());
+            data->polltime = json_desc["polltime"].GetDouble();
+            CHECK_F(data->polltime > 0,
+                       "%s: profile '%s' has a non-positive 'polltime' field (%g)",
+                       error_prefix.c_str(), profile_name.c_str(), data->polltime);
+        }
+        else
+        {
+            data->polltime = 0.005;
+        }
+        profile->data = data;
+    }
+    else if (profile_type == "smpi")
+    {
+        profile->type = ProfileType::SMPI;
+        SmpiProfileData * data = new SmpiProfileData;
+
+        CHECK_F(json_desc.HasMember("trace"), "%s: profile '%s' has no 'trace' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        CHECK_F(json_desc["trace"].IsString(), "%s: profile '%s' has a non-string 'trace' field",
+                   error_prefix.c_str(), profile_name.c_str());
+        const std::string trace_filename = json_desc["trace"].GetString();
+
+        CHECK_F(is_from_a_file, "Trying to create a SMPI profile from another source than "
+                   "a file workload, which is not implemented at the moment.");
+        (void) is_from_a_file; // Avoids a warning if assertions are ignored
+
+        fs::path base_dir = json_filename;
+        base_dir = base_dir.parent_path();
+        LOG_F(INFO,"base_dir = '%s'", base_dir.string().c_str());
+        CHECK_F(fs::exists(base_dir) && fs::is_directory(base_dir));
+
+        //LOG_F(INFO,"base_dir = '%s'", base_dir.string().c_str());
+        //LOG_F(INFO,"trace = '%s'", trace.c_str());
+        fs::path trace_path = base_dir.string() + "/" + trace_filename;
+        //LOG_F(INFO,"trace_path = '%s'", trace_path.string().c_str());
+        CHECK_F(fs::exists(trace_path) && fs::is_regular_file(trace_path),
+                   "Invalid JSON: profile '%s' has an invalid 'trace' field ('%s'), which leads to a non-existent file ('%s')",
+                   profile_name.c_str(), trace_filename.c_str(), trace_path.string().c_str());
+
+        std::ifstream trace_file(trace_path.string());
+        CHECK_F(trace_file.is_open(), "Cannot open file '%s'", trace_path.string().c_str());
+
+        std::string line;
+        while (std::getline(trace_file, line))
+        {
+            boost::trim_right(line);
+            fs::path rank_trace_path = trace_path.parent_path().string() + "/" + line;
+            data->trace_filenames.push_back(rank_trace_path.string());
+        }
+
+        std::string filenames = boost::algorithm::join(data->trace_filenames, ", ");
+        LOG_F(INFO,"Filenames of profile '%s': [%s]", profile_name.c_str(), filenames.c_str());
+
+        profile->data = data;
+    }
+    else
+    {
+        ABORT_F("Cannot create the profile '%s' of unknown type '%s'",
+                profile_name.c_str(), profile_type.c_str());
+    }
+
+
+    // Let's get the JSON string which describes the profile (to conserve potential fields unused by Batsim)
+    rapidjson::StringBuffer buffer;
+    rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);
+    json_desc.Accept(writer);
+    profile->json_description = std::string(buffer.GetString(), buffer.GetSize());
+
+    return profile;
+}
+
+// Do NOT remove namespaces in the arguments (to avoid doxygen warnings)
+ProfilePtr Profile::from_json(const std::string & profile_name,
+                            const std::string & json_str,
+                            const std::string & error_prefix)
+{
+    Document doc;
+    doc.Parse(json_str.c_str());
+    CHECK_F(!doc.HasParseError(), "%s: Cannot be parsed. Content (between '##'):\n#%s#",
+               error_prefix.c_str(), json_str.c_str());
+
+    return Profile::from_json(profile_name, doc, error_prefix, false);
+}
+
+bool Profile::is_parallel_task() const
+{
+    return (type == ProfileType::PARALLEL) ||
+           (type == ProfileType::PARALLEL_HOMOGENEOUS) ||
+           (type == ProfileType::PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT) ||
+           (type == ProfileType::PARALLEL_HOMOGENEOUS_PFS) ||
+           (type == ProfileType::DATA_STAGING);
+}
+
+
+std::string profile_type_to_string(const ProfileType & type)
+{
+    std::string str;
+
+    switch(type)
+    {
+    case ProfileType::DELAY:
+        str = "DELAY";
+        break;
+    case ProfileType::PARALLEL:
+        str = "PARALLEL";
+        break;
+    case ProfileType::PARALLEL_HOMOGENEOUS:
+        str = "PARALLEL_HOMOGENEOUS";
+        break;
+    case ProfileType::PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT:
+        str = "PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT";
+        break;
+    case ProfileType::SMPI:
+        str = "SMPI";
+        break;
+    case ProfileType::SEQUENCE:
+        str = "SEQUENCE";
+        break;
+    case ProfileType::PARALLEL_HOMOGENEOUS_PFS:
+        str = "PARALLEL_HOMOGENEOUS_PFS";
+        break;
+    case ProfileType::DATA_STAGING:
+        str = "DATA_STAGING";
+        break;
+    case ProfileType::SCHEDULER_SEND:
+        str = "SCHEDULER_SEND";
+        break;
+    case ProfileType::SCHEDULER_RECV:
+        str = "SCHEDULER_RECV";
+        break;
+    default:
+        str = "unset";
+        break;
+    }
+
+    return str;
+}
+void Profiles::add_profile(ProfilePtr profile)
+{
+    _profiles[profile->name]=profile;
+}
+void Profiles::load_from_json(const Document &doc, const std::string & filename)
+{
+    std::string error_prefix = "Invalid JSON file '" + filename + "'";
+   
+    CHECK_F(doc.IsObject(), "%s: not a JSON object", error_prefix.c_str());
+    
+    CHECK_F(doc.HasMember("profiles"), "%s: the 'profiles' object is missing",
+               error_prefix.c_str());
+    
+    const Value & profiles = doc["profiles"];
+    
+    CHECK_F(profiles.IsObject(), "%s: the 'profiles' member is not an object",
+               error_prefix.c_str());
+    
+    for (Value::ConstMemberIterator it = profiles.MemberBegin(); it != profiles.MemberEnd(); ++it)
+    {
+        const Value & key = it->name;
+        const Value & value = it->value;
+       
+        CHECK_F(key.IsString(), "%s: all children of the 'profiles' object must have a "
+                   "string key", error_prefix.c_str());
+        
+        std::string profile_name = key.GetString();
+        
+        auto profile = Profile::from_json(profile_name, value, error_prefix, true, filename);
+        
+        CHECK_F(!exists(std::string(key.GetString())), "%s: duplication of profile name '%s'",
+                   error_prefix.c_str(), key.GetString());
+        
+        _profiles[std::string(key.GetString())] = profile;
+    }
+}
+const std::unordered_map<std::string, ProfilePtr> Profiles::profiles() const
+{
+    return _profiles;
+}
+ProfilePtr Profiles::operator[](const std::string &profile_name)
+{
+    auto mit = _profiles.find(profile_name);
+    CHECK_F(mit != _profiles.end(), "Cannot get profile '%s': it does not exist", profile_name.c_str());
+    CHECK_F(mit->second.get() != nullptr, "Cannot get profile '%s': it existed some time ago but is no longer accessible", profile_name.c_str());
+    return mit->second;
+}
+
+const ProfilePtr Profiles::operator[](const std::string &profile_name) const
+{
+    auto mit = _profiles.find(profile_name);
+    CHECK_F(mit != _profiles.end(), "Cannot get profile '%s': it does not exist", profile_name.c_str());
+    CHECK_F(mit->second.get() != nullptr, "Cannot get profile '%s': it existed some time ago but is no longer accessible", profile_name.c_str());
+    return mit->second;
+}
+ProfilePtr Profiles::at(const std::string & profile_name)
+{
+    return operator[](profile_name);
+}
+
+const ProfilePtr Profiles::at(const std::string & profile_name) const
+{
+    return operator[](profile_name);
+}
+int Profiles::nb_profiles() const
+{
+    return static_cast<int>(_profiles.size());
+}
+bool Profiles::exists(const std::string &profile_name) const
+{
+    auto mit = _profiles.find(profile_name);
+    return mit != _profiles.end();
+}
+Profiles::~Profiles()
+{
+    _profiles.clear();
+}
+void Profiles::remove_profile(const std::string & profile_name)
+{
+    auto mit = _profiles.find(profile_name);
+    CHECK_F(mit != _profiles.end(), "Bad Profiles::remove_profile call: Profile with name='%s' never existed in this workload.", profile_name.c_str());
+
+    // If the profile has aleady been removed, do nothing.
+    if (mit->second.get() == nullptr)
+    {
+        return;
+    }
+
+    // If the profile is composed, also remove links to subprofiles.
+    if (mit->second->type == ProfileType::SEQUENCE)
+    {
+        auto * profile_data = static_cast<SequenceProfileData*>(mit->second->data);
+        for (const auto & subprofile : profile_data->profile_sequence)
+        {
+            remove_profile(subprofile->name);
+        }
+    }
+
+    // Discard link to the profile (implicit memory clean-up)
+    mit->second = nullptr;
+}
+
+}
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_profile.hpp ./new_batsched/src/external/batsched_profile.hpp
--- ./batsched/src/external/batsched_profile.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_profile.hpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,222 @@
+#ifndef BATSCHED_PROFILE_HPP
+#define BATSCHED_PROFILE_HPP
+
+#include <string>
+#include <unordered_map>
+#include <vector>
+#include <memory>
+
+#include <rapidjson/document.h>
+
+#include "pointers.hpp"
+
+namespace myBatsched{
+
+enum class ProfileType
+{
+    UNSET
+    ,DELAY                                     //!< a delay. Its data is of type DelayProfileData
+    ,PARALLEL                                  //!< composed of a computation vector and a communication matrix. Its data is of type ParallelProfileData
+    ,PARALLEL_HOMOGENEOUS                      //!< a homogeneous parallel task that executes the given amounts of computation and communication on every node. Its data is of type ParallelHomogeneousProfileData
+    ,PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT         //!< a homogeneous parallel task that spreads the given amounts of computation and communication among all the nodes. Its data is of type ParallelHomogeneousTotalAmountProfileData
+    ,SMPI                                      //!< a SimGrid MPI time-independent trace. Its data is of type SmpiProfileData
+    ,SEQUENCE                                  //!< non-atomic: it is composed of a sequence of other profiles
+    ,PARALLEL_HOMOGENEOUS_PFS                  //!< Read and writes data to a PFS storage nodes. data type ParallelHomogeneousPFSProfileData
+    ,DATA_STAGING                              //!< for moving data between the pfs hosts. Its data is of type DataStagingProfileData
+    ,SCHEDULER_SEND                            //!< a profile simulating a message sent to the scheduler. Its data is of type SchedulerSendProfileData
+    ,SCHEDULER_RECV                            //!< receives a message from the scheduler and can execute a profile based on a value comparison of the message. Its data is of type SchedulerRecvProfileData
+};
+struct Profile{
+    Profile() = default;
+    ~Profile();
+    ProfileType type;
+    void * data;
+    std::string json_description;
+    std::string name;
+    int return_code=0;
+
+    
+    
+        /**
+     * @brief Creates a new-allocated Profile from a JSON description
+     * @param[in] profile_name The name of the profile
+     * @param[in] json_desc The JSON description
+     * @param[in] json_filename The JSON file name
+     * @param[in] is_from_a_file Whether the JSON job comes from a file
+     * @param[in] error_prefix The prefix to display when an error occurs
+     * @return The new-allocated Profile
+     * @pre The JSON description is valid
+     */
+    static ProfilePtr from_json(const std::string & profile_name,
+                               const rapidjson::Value & json_desc,
+                               const std::string & error_prefix = "Invalid JSON profile",
+                               bool is_from_a_file = true,
+                               const std::string & json_filename = "unset");
+
+    /**
+     * @brief Creates a new-allocated Profile from a JSON description
+     * @param[in] profile_name The name of the profile
+     * @param[in] json_str The JSON description (as a string)
+     * @param[in] error_prefix The prefix to display when an error occurs
+     * @return The new-allocated Profile
+     * @pre The JSON description is valid
+     */
+    static ProfilePtr from_json(const std::string & profile_name,
+                               const std::string & json_str,
+                               const std::string & error_prefix = "Invalid JSON profile");
+
+    bool is_parallel_task() const;
+};
+/**
+ * @brief The data associated to PARALLEL profiles
+ */
+struct ParallelProfileData
+{
+    ParallelProfileData() = default;
+
+    /**
+     * @brief Destroys a ParallelProfileData
+     * @details This method cleans the cpu and comm arrays from the memory if they are not set to nullptr
+     */
+    ~ParallelProfileData();
+
+    unsigned int nb_res;    //!< The number of resources
+    double * cpu = nullptr; //!< The computation vector
+    double * com = nullptr; //!< The communication matrix
+};
+
+/**
+ * @brief The data associated to PARALLEL_HOMOGENEOUS profiles
+ */
+struct ParallelHomogeneousProfileData
+{
+    double cpu; //!< The computation amount on each node
+    double com; //!< The communication amount between each pair of nodes
+
+    //CCU-LANL additions
+    double real_cpu; //!< The original amount of cpu (forward work)
+};
+
+/**
+ * @brief The data associated to PARALLEL_HOMOGENEOUS_TOTAL_AMOUNT profiles
+ */
+struct ParallelHomogeneousTotalAmountProfileData
+{
+    double cpu; //!< The computation amount to spread over the nodes
+    double com; //!< The communication amount to spread over each pair of nodes
+
+    //CCU-LANL additions
+    double real_cpu; //!< The original amount of cpu spread over the nodes (forward work)
+};
+/**
+ * @brief The data associated to DELAY profiles
+ */
+struct DelayProfileData
+{
+    double delay; //!< The time amount, in seconds, that the job is supposed to take
+    double real_delay;
+};
+
+/**
+ * @brief The data associated to SMPI profiles
+ */
+struct SmpiProfileData
+{
+    std::vector<std::string> trace_filenames; //!< all defined tracefiles
+};
+
+/**
+ * @brief The data associated to SEQUENCE profiles
+ */
+struct SequenceProfileData
+{
+    unsigned int repeat;  //!< The number of times the sequence must be repeated
+    std::vector<std::string> sequence; //!< The sequence of profile names, executed in this order
+    std::vector<ProfilePtr> profile_sequence; //!< The sequence of profiles, executed in this order
+};
+
+/**
+ * @brief The data associated to PARALLEL_HOMOGENEOUS_PFS profiles
+ */
+struct ParallelHomogeneousPFSProfileData
+{
+    double bytes_to_read = 0;             //!< The amount of bytes to reads from the PFS storage node for each nodes (default: 0)
+    double bytes_to_write = 0;            //!< The amount of bytes to writes to the PFS storage for each nodes (default: 0)
+    std::string storage_label = "pfs";    //!< A label that defines the PFS storage node (default: "pfs")
+};
+
+/**
+ * @brief The data associated to DATA_STAGING profiles
+ */
+struct DataStagingProfileData
+{
+    double nb_bytes;                  //!< The number of bytes to transfer between the two storage nodes
+    std::string from_storage_label ;  //!< The storage label where data comes from
+    std::string to_storage_label ;    //!< The storage label where data goes to
+};
+
+/**
+ * @brief The data associated to SCHEDULER_SEND profiles
+ */
+struct SchedulerSendProfileData
+{
+    rapidjson::Document message; //!< The message being sent to the scheduler
+    double sleeptime; //!< The time to sleep after sending the message.
+};
+
+/**
+ * @brief The data associated to SCHEDULER_RECV profiles
+ */
+struct SchedulerRecvProfileData
+{
+    std::string regex; //!< The regex which is tested for matching
+    std::string on_success; //!< The profile to execute if it matches
+    std::string on_failure; //!< The profile to execute if it does not match
+    std::string on_timeout; //!< The profile to execute if no message is in the buffer (i.e. the scheduler has not answered in time). Can be omitted which will result that the job will wait until its walltime is reached.
+    double polltime; //!< The time to sleep between polling if on_timeout is not set.
+};
+
+class Profiles
+{
+public:
+    
+    Profiles() = default;
+    ~Profiles();
+    void load_from_json(const rapidjson::Document & doc, const std::string & filename);
+    void add_profile(ProfilePtr profile);
+    ProfilePtr operator[](const std::string & profile_name);
+    const ProfilePtr operator[](const std::string & profile_name) const;
+    
+    bool exists(const std::string & profile_name) const;
+    void add_profile(const std::string & profile_name, ProfilePtr & profile);
+    void remove_profile(const std::string & profile_name);
+    /**
+     * @brief Remove all unreferenced profiles from a Profiles instance (but remembers the profiles existed at some point)
+     */
+    int nb_profiles() const;
+     /**
+     * @brief Accesses one profile thanks to its name
+     * @param[in] profile_name The name of the profile
+     * @return The profile whose name is profile_name
+     * @pre Such a profile exists
+     */
+    ProfilePtr at(const std::string & profile_name);
+    /**
+     * @brief Accesses one profile thanks to its name (const version)
+     * @param[in] profile_name The name of the profile
+     * @return The profile whose name is profile_name
+     * @pre Such a profile exists
+     */
+    const ProfilePtr at(const std::string & profile_name) const;
+     /**
+     * @brief Returns a copy of the internal std::map used in the Profiles
+     * @return A copy of the internal std::map used in the Profiles
+     */
+    const std::unordered_map<std::string, ProfilePtr> profiles() const;
+private:
+    std::unordered_map<std::string, ProfilePtr> _profiles; //!< Stores all the profiles, indexed by their names. Value can be nullptr, meaning that the profile is no longer in memory but existed in the past.
+};
+
+}
+
+#endif
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_workload.cpp ./new_batsched/src/external/batsched_workload.cpp
--- ./batsched/src/external/batsched_workload.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_workload.cpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,260 @@
+#include <loguru.hpp>
+#include <fstream>
+#include <streambuf>
+#include <string>
+#include <algorithm>
+#include <regex>
+
+#include <boost/algorithm/string.hpp>
+#include <boost/algorithm/string/join.hpp>
+
+#include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <rapidjson/stringbuffer.h>
+#include "batsched_workload.hpp"
+#include "batsched_profile.hpp"
+#include "batsched_job.hpp"
+
+using namespace rapidjson;
+namespace r = rapidjson;
+namespace myBatsched{
+
+Workload *Workload::new_static_workload(const std::string & workload_name,
+                                        const std::string & workload_file,
+                                        bool checkpointing_on
+                                       )
+{
+    Workload * workload = new Workload;
+
+    workload->jobs = new Jobs;
+    workload->profiles = new Profiles;
+
+    workload->jobs->set_profiles(workload->profiles);
+    workload->jobs->set_workload(workload);
+    workload->name = workload_name;
+    workload->file = workload_file;
+    workload->_checkpointing_on = checkpointing_on;
+    if (! (workload_file == "dynamic"))
+        workload->_is_static = true;
+    return workload;
+}
+
+Workload *Workload::new_dynamic_workload(const std::string & workload_name,bool checkpointing_on)
+{
+    Workload * workload = new_static_workload(workload_name, "dynamic",checkpointing_on);
+
+    workload->_is_static = false;
+    return workload;
+}
+
+void Workload::load_from_batsim(const std::string &json_filename, const r::Value & job_json, const r::Value & profile_json)
+{
+        LOG_F(INFO,"Loading batsim workload %s %s",name.c_str(),json_filename.c_str());
+        Document d;
+        Value jobs_array,profiles_array;
+        
+        jobs_array.CopyFrom(job_json,d.GetAllocator());
+        profiles_array.CopyFrom(profile_json,d.GetAllocator());
+        
+        d.SetObject();
+        d.AddMember("jobs",jobs_array,d.GetAllocator());
+        d.AddMember("profiles",profiles_array,d.GetAllocator());
+       
+        profiles->load_from_json(d,json_filename);
+       
+        jobs->load_from_json(d,json_filename);
+       
+        LOG_F(INFO,"JSON workload parsed sucessfully. Read %d jobs and %d profiles.",
+             jobs->nb_jobs(), profiles->nb_profiles());
+}
+
+void Workload::load_from_json(const std::string &json_filename)
+{
+    LOG_F(INFO,"Loading JSON workload '%s'...", json_filename.c_str());
+    // Let the file content be placed in a string
+    std::ifstream ifile(json_filename);
+    CHECK_F(ifile.is_open(), "Cannot read file '%s'", json_filename.c_str());
+    std::string content;
+
+    ifile.seekg(0, std::ios::end);
+    content.reserve(static_cast<unsigned long>(ifile.tellg()));
+    ifile.seekg(0, std::ios::beg);
+
+    content.assign((std::istreambuf_iterator<char>(ifile)),
+                std::istreambuf_iterator<char>());
+
+    // JSON document creation
+    Document doc;
+    doc.Parse(content.c_str());
+    CHECK_F(!doc.HasParseError(), "Invalid JSON file '%s': could not be parsed", json_filename.c_str());
+    CHECK_F(doc.IsObject(), "Invalid JSON file '%s': not a JSON object", json_filename.c_str());
+
+    // Let's try to read the number of machines in the JSON document
+    CHECK_F(doc.HasMember("nb_res"), "Invalid JSON file '%s': the 'nb_res' field is missing", json_filename.c_str());
+    const Value & nb_res_node = doc["nb_res"];
+    CHECK_F(nb_res_node.IsInt(), "Invalid JSON file '%s': the 'nb_res' field is not an integer", json_filename.c_str());
+    int nb_machines = nb_res_node.GetInt();
+    CHECK_F(nb_machines > 0, "Invalid JSON file '%s': the value of the 'nb_res' field is invalid (%d)",
+               json_filename.c_str(), nb_machines);
+
+    profiles->load_from_json(doc, json_filename);
+    jobs->load_from_json(doc, json_filename);
+
+    LOG_F(INFO,"JSON workload parsed sucessfully. Read %d jobs and %d profiles.",
+             jobs->nb_jobs(), profiles->nb_profiles());
+    LOG_F(INFO,"Checking workload validity...");
+    check_validity();
+    LOG_F(INFO,"Workload seems to be valid.");
+   
+}
+void Workload::check_validity()
+{
+    // Let's check that every SEQUENCE-typed profile points to existing profiles
+    // And update the refcounting of these profiles
+    for (auto mit : profiles->profiles())
+    {
+        ProfilePtr profile = mit.second;
+        if (profile->type == ProfileType::SEQUENCE)
+        {
+            auto * data = static_cast<SequenceProfileData *>(profile->data);
+            data->profile_sequence.reserve(data->sequence.size());
+            for (const auto & prof : data->sequence)
+            {
+                (void) prof; // Avoids a warning if assertions are ignored
+                CHECK_F(profiles->exists(prof),
+                           "Invalid composed profile '%s': the used profile '%s' does not exist",
+                           mit.first.c_str(), prof.c_str());
+                // Adds one to the refcounting for the profile 'prof'
+                data->profile_sequence.push_back(profiles->at(prof));
+            }
+        }
+    }
+
+    // TODO : check that there are no circular calls between composed profiles...
+    // TODO: compute the constraint of the profile number of resources, to check if it matches the jobs that use it
+
+    // Let's check the profile validity of each job
+    for (const auto & mit : jobs->jobs())
+    {
+        check_single_job_validity(mit.second);
+    }
+}
+
+void Workload::check_single_job_validity(const JobPtr job)
+{
+    //TODO This is already checked during creation of the job in Job::from_json
+    CHECK_F(profiles->exists(job->profile->name),
+               "Invalid job %s: the associated profile '%s' does not exist",
+               job->id.to_cstring(), job->profile->name.c_str());
+
+    if (job->profile->type == ProfileType::PARALLEL)
+    {
+        auto * data = static_cast<ParallelProfileData *>(job->profile->data);
+        (void) data; // Avoids a warning if assertions are ignored
+        CHECK_F(data->nb_res == job->requested_nb_res,
+                   "Invalid job %s: the requested number of resources (%d) do NOT match"
+                   " the number of resources of the associated profile '%s' (%d)",
+                   job->id.to_cstring(), job->requested_nb_res, job->profile->name.c_str(), data->nb_res);
+    }
+    /*else if (job->profile->type == ProfileType::SEQUENCE)
+    {
+        // TODO: check if the number of resources matches a resource-constrained composed profile
+    }*/
+}
+bool Workload::is_static() const
+{
+    return _is_static;
+}
+Workload::~Workload()
+{
+    delete jobs;
+    delete profiles;
+
+    jobs = nullptr;
+    profiles = nullptr;
+}
+Workloads::~Workloads()
+{
+    for (auto mit : _workloads)
+    {
+        Workload * workload = mit.second;
+        delete workload;
+    }
+    _workloads.clear();
+}
+Workload *Workloads::operator[](const std::string &workload_name)
+{
+    return at(workload_name);
+}
+Workload *Workloads::at(const std::string &workload_name)
+{
+    return _workloads.at(workload_name);
+}
+const Workload *Workloads::at(const std::string &workload_name) const
+{
+    return _workloads.at(workload_name);
+}
+unsigned int Workloads::nb_workloads() const
+{
+    return static_cast<unsigned int>(_workloads.size());
+}
+
+unsigned int Workloads::nb_static_workloads() const
+{
+    unsigned int count = 0;
+
+    for (auto mit : _workloads)
+    {
+        Workload * workload = mit.second;
+
+        count += static_cast<unsigned int>(workload->is_static());
+    }
+
+    return count;
+}
+JobPtr Workloads::job_at(const JobIdentifier &job_id)
+{
+    return at(job_id.workload_name())->jobs->at(job_id);
+}
+
+const JobPtr Workloads::job_at(const JobIdentifier &job_id) const
+{
+    return at(job_id.workload_name())->jobs->at(job_id);
+}
+void Workloads::delete_jobs(const std::vector<JobIdentifier> & job_ids,
+                            const bool & garbage_collect_profiles)
+{
+    for (const JobIdentifier & job_id : job_ids)
+    {
+        at(job_id.workload_name())->jobs->delete_job(job_id, garbage_collect_profiles);
+    }
+}
+bool Workloads::exists(const std::string &workload_name) const
+{
+    return _workloads.count(workload_name) == 1;
+}
+std::map<std::string, Workload *> &Workloads::workloads()
+{
+    return _workloads;
+}
+bool Workloads::job_is_registered(const JobIdentifier &job_id)
+{
+    return at(job_id.workload_name())->jobs->exists(job_id);
+}
+
+bool Workloads::job_profile_is_registered(const JobIdentifier &job_id)
+{
+    //TODO this could be improved/simplified
+    auto job = at(job_id.workload_name())->jobs->at(job_id);
+    return at(job_id.workload_name())->profiles->exists(job->profile->name);
+}
+void Workloads::insert_workload(const std::string &workload_name, Workload *workload)
+{
+    CHECK_F(!exists(workload_name));
+    CHECK_F(!exists(workload->name));
+
+    workload->name = workload_name;
+    _workloads[workload_name] = workload;
+}
+}
+
diff -burN '--exclude=.git*' ./batsched/src/external/batsched_workload.hpp ./new_batsched/src/external/batsched_workload.hpp
--- ./batsched/src/external/batsched_workload.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/batsched_workload.hpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,209 @@
+#ifndef BATSCHED_WORKLOAD_HPP
+#define BATSCHED_WORKLOAD_HPP
+
+#include <string>
+#include <vector>
+#include <map>
+#include "pointers.hpp"
+#include <rapidjson/document.h>
+
+namespace r = rapidjson;
+namespace myBatsched{
+class Jobs;
+struct Job;
+class Profiles;
+struct JobIdentifier;
+
+class Workload
+{
+   public:
+    /**
+     * @brief Builds an empty static Workload (via dynamic allocation)
+     * @details Static workloads correspond to Batsim input files (workloads or workflows)
+     * @param[in] workload_name The workload name
+     * @param[in] workload_file The workload file name
+     * @return The newly created workload
+     */
+    static Workload * new_static_workload(const std::string & workload_name,
+                                          const std::string & workload_file,
+                                          bool checkpointing_on = false
+                                         );
+
+    /**
+     * @brief Builds an empty dynamic Workload (via dynamic allocation)
+     * @details Dynamic workloads are created by the decision process
+     * @param[in] workload_name The workload name
+     * @return The newly created workload
+     */
+    static Workload * new_dynamic_workload(const std::string & workload_name,
+                                            bool checkpointing_on = false);
+    
+
+    /**
+     * @brief Destroys a Workload
+     */
+    ~Workload();
+ /**
+     * @brief Loads a static workload from a JSON filename
+     * @param[in] json_filename The name of the JSON file
+     * @param[out] nb_machines The number of machines described in the JSON file
+     */
+    void load_from_json(const std::string & json_filename);
+    
+    void load_from_batsim(const std::string& filename, const r::Value & job_json,const r::Value & profile_json);
+    /**
+     * @brief Returns whether the workload is static (corresponding to a Batsim input workload/workflow) or not
+     * @return Whether the workload is static or not
+     */
+    /**
+     * @brief Checks whether a Workload is valid
+     */
+    void check_validity();
+
+    /**
+     * @brief Checks whether a single job is valid
+     * @param[in] job The job to examine
+     */
+    void check_single_job_validity(const JobPtr job);
+
+     bool is_static() const;
+public:
+std::string name; //!< The Workload name
+    std::string file = ""; //!< The Workload file if it exists
+    Jobs * jobs = nullptr; //!< The Jobs of the Workload
+    Profiles * profiles = nullptr; //!< The Profiles associated to the Jobs of the Workload
+    bool _is_static = false; //!< Whether the workload is dynamic or not
+    bool _checkpointing_on = false;
+    bool _compute_checkpointing = false;
+    double _MTBF = -1.0;
+    double _SMTBF = -1.0;
+    double _repair_time = 0.0;
+    double _host_speed;
+
+};
+
+class Workloads
+{
+public:
+    Workloads() = default;
+    ~Workloads();
+    
+    /**
+     * @brief Allows to access a Workload thanks to its name
+     * @param[in] workload_name The name of the workload to access
+     * @return The workload associated with the given workload name
+     * @pre The workload exists
+     */
+    Workload * operator[](const std::string & workload_name);
+
+    /**
+     * @brief Allows to access a Workload thanks to its name
+     * @param[in] workload_name The name of the workload to access
+     * @return The workload associated with the given workload name
+     * @pre The workload exists
+     */
+    const Workload * operator[](const std::string & workload_name) const;
+
+    /**
+     * @brief Allows to access a Workload thanks to its name
+     * @param[in] workload_name The name of the workload to access
+     * @return The workload associated with the given workload name
+     * @pre The workload exists
+     */
+    Workload * at(const std::string & workload_name);
+
+    /**
+     * @brief Allows to access a Workload thanks to its name
+     * @param[in] workload_name The name of the workload to access
+     * @return The workload associated with the given workload name
+     * @pre The workload exists
+     */
+    const Workload * at(const std::string & workload_name) const;
+
+    /**
+     * @brief Returns the number of workloads
+     * @return The number of workloads
+     */
+    unsigned int nb_workloads() const;
+
+    /**
+     * @brief Returns the number of static workloads
+     * @details Static workloads are those corresponding to Batsim input files (input workloads or workflows)
+     * @return The number of static workloads
+     */
+    unsigned int nb_static_workloads() const;
+
+    /**
+     * @brief Allows to get a job from the Workloads
+     * @param[in] job_id The JobIdentifier
+     * @return The job which has been asked
+     * @pre The requested job exists
+     */
+    JobPtr job_at(const JobIdentifier & job_id);
+
+    /**
+     * @brief Allows to get a job from the Workloads (const version)
+     * @param[in] job_id The JobIdentifier
+     * @return The (const) job which has been asked
+     * @pre The requested job exists
+     */
+    const JobPtr job_at(const JobIdentifier & job_id) const;
+    
+    /**
+     * @brief Inserts a new Workload into a Workloads
+     * @param[in] workload_name The name of the new Workload to insert
+     * @param[in] workload The Workload to insert
+     * @pre There should be no existing Workload with the same name in the Workloads
+     */
+    void insert_workload(const std::string & workload_name,
+                         Workload * workload);
+    /**
+     * @brief Deletes jobs from the associated workloads
+     * @param[in] job_ids The vector of identifiers of the jobs to remove
+     * @param[in] garbage_collect_profiles Whether to remove profiles that are not used anymore
+     */
+    void delete_jobs(const std::vector<JobIdentifier> & job_ids,
+                     const bool & garbage_collect_profiles);
+    /**
+     * @brief Checks whether a Workload with the given name exist.
+     * @param[in] workload_name The name of the Workload whose existence is checked
+     * @return true if a Workload with the given name exists in the Workloads, false otherwise.
+     */
+    bool exists(const std::string & workload_name) const;
+        /**
+     * @brief Gets the internal map
+     * @return The internal map
+     */
+    std::map<std::string, Workload*> & workloads();
+     /**
+     * @brief Checks whether a job is registered in the associated workload
+     * @param[in] job_id The JobIdentifier
+     * @return True if the given is registered in the associated workload, false otherwise
+     */
+    bool job_is_registered(const JobIdentifier & job_id);
+      /**
+     * @brief Checks whether a job profile is registered in the workload it
+     * is attached to
+     * @param[in] job_id The JobIdentifier
+     * @return True if the given is registered in the associated workload, false otherwise
+     */
+    bool job_profile_is_registered(const JobIdentifier & job_id);
+public:
+        bool _checkpointing_on = false;
+        bool _compute_checkpointing = false;
+        double _MTBF = -1.0;
+        double _SMTBF = -1.0;
+        double _repair_time = 0.0;
+        double _fixed_failures = -1.0;
+        double _host_speed;
+private:
+    std::map<std::string, Workload*> _workloads; //!< Associates Workloads with their names
+
+
+
+};
+
+}
+
+
+#endif
diff -burN '--exclude=.git*' ./batsched/src/external/pointers.hpp ./new_batsched/src/external/pointers.hpp
--- ./batsched/src/external/pointers.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/external/pointers.hpp	2023-06-28 08:26:02.137166701 -0400
@@ -0,0 +1,11 @@
+#pragma once
+
+
+
+namespace myBatsched{
+    struct Job;
+struct Profile;
+typedef std::shared_ptr<Job> JobPtr; //!< A smart pointer towards a Job.
+typedef std::shared_ptr<Profile> ProfilePtr; //!< A smart pointer towards a Profile.
+
+}
diff -burN '--exclude=.git*' ./batsched/src/isalgorithm.cpp ./new_batsched/src/isalgorithm.cpp
--- ./batsched/src/isalgorithm.cpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/isalgorithm.cpp	2023-06-28 08:26:02.137166701 -0400
@@ -1,6 +1,7 @@
 #include "isalgorithm.hpp"
 
 #include "pempek_assert.hpp"
+#include "batsched_tools.hpp"
 
 using namespace std;
 
@@ -63,12 +64,13 @@
                                 job_ids.end());
 }
 
-void ISchedulingAlgorithm::on_job_killed(double date, const std::vector<string> &job_ids)
+
+
+void ISchedulingAlgorithm::on_job_killed(double date, const std::unordered_map<std::string,batsched_tools::Job_Message *> &job_msgs)
 {
     (void) date;
-    _jobs_killed_recently.insert(_jobs_killed_recently.end(),
-                                 job_ids.begin(),
-                                 job_ids.end());
+    _jobs_killed_recently.insert(job_msgs.begin(),
+                                 job_msgs.end());
 }
 
 void ISchedulingAlgorithm::on_machine_state_changed(double date, IntervalSet machines, int new_state)
@@ -81,7 +83,7 @@
         _machines_whose_pstate_changed_recently[new_state] += machines;
 }
 
-void ISchedulingAlgorithm::on_requested_call(double date)
+void ISchedulingAlgorithm::on_requested_call(double date,int id, batsched_tools::call_me_later_types forWhat)
 {
     (void) date;
     _nopped_recently = true;
@@ -111,13 +113,25 @@
     (void) date;
     _machines_that_became_available_recently += machines;
 }
+void ISchedulingAlgorithm::set_workloads(myBatsched::Workloads *w){
+    (void) w;
+}
+void ISchedulingAlgorithm::set_machines(Machines *m){
+    (void) m;
+}
 
 void ISchedulingAlgorithm::on_machine_unavailable_notify_event(double date, IntervalSet machines)
 {
     (void) date;
     _machines_that_became_unavailable_recently += machines;
 }
-
+void ISchedulingAlgorithm::on_job_fault_notify_event(double date, std::string job)  // ****************added
+{
+    (void) date;
+}
+void ISchedulingAlgorithm::on_myKillJob_notify_event(double date){
+    (void) date;
+}
 void ISchedulingAlgorithm::on_query_estimate_waiting_time(double date, const string &job_id)
 {
     (void) date;
diff -burN '--exclude=.git*' ./batsched/src/isalgorithm.hpp ./new_batsched/src/isalgorithm.hpp
--- ./batsched/src/isalgorithm.hpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/isalgorithm.hpp	2023-06-28 08:26:02.147166876 -0400
@@ -5,6 +5,9 @@
 
 #include "decision.hpp"
 #include "queue.hpp"
+#include "external/batsched_workload.hpp"
+#include "batsched_tools.hpp"
+#include "machine.hpp"
 
 /**
  * @brief The base abstract class of (scheduling & machine state) decision algorithms
@@ -62,7 +65,7 @@
      * @param[in] date The date at which the jobs have been killed
      * @param[in] job_ids The identifiers of the jobs which have been finished
      */
-    virtual void on_job_killed(double date, const std::vector<std::string> & job_ids);
+    virtual void on_job_killed(double date, const std::unordered_map<std::string,batsched_tools::Job_Message *> & job_msgs);
 
     /**
      * @brief This function is called when the power state of some machines have been changed
@@ -76,7 +79,7 @@
      * @brief This function is called when a REQUESTED_CALL message is received
      * @param[in] date The date at which the REQUESTED_CALL message have been received
      */
-    virtual void on_requested_call(double date);
+    virtual void on_requested_call(double date, int id, batsched_tools::call_me_later_types forWhat);
 
     /**
      * @brief This function is called when the no_more_static_job_to_submit
@@ -111,6 +114,8 @@
      */
     virtual void on_machine_unavailable_notify_event(double date, IntervalSet machines);
 
+    virtual void on_job_fault_notify_event(double date, std::string job);   //*********************added
+    virtual void on_myKillJob_notify_event(double date);
     /**
      * @brief This function is called when a QUERY message about estimating waiting time of potential jobs is received.
      * @param[in] date The date at which the QUERY message has been received
@@ -146,9 +151,14 @@
      * @details This function should be called between make_decisions calls!
      */
     void clear_recent_data_structures();
+    virtual void set_workloads(myBatsched::Workloads *w);
+    virtual void set_machines(Machines *m);
+    
 
 protected:
+    
     Workload * _workload;
+    Machines * _machines;
     SchedulingDecision * _decision;
     Queue * _queue;
     ResourceSelector * _selector;
@@ -162,7 +172,7 @@
 protected:
     std::vector<std::string> _jobs_released_recently;
     std::vector<std::string> _jobs_ended_recently;
-    std::vector<std::string> _jobs_killed_recently;
+    std::unordered_map<std::string, batsched_tools::Job_Message *> _jobs_killed_recently;
     std::vector<std::string> _jobs_whose_waiting_time_estimation_has_been_requested_recently;
     std::map<int, IntervalSet> _machines_whose_pstate_changed_recently;
     IntervalSet _machines_that_became_available_recently;
diff -burN '--exclude=.git*' ./batsched/src/json_workload.cpp ./new_batsched/src/json_workload.cpp
--- ./batsched/src/json_workload.cpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/json_workload.cpp	2023-06-28 08:26:02.143833485 -0400
@@ -4,8 +4,13 @@
 #include <fstream>
 #include <vector>
 #include <limits>
-
+#include <regex>
+#include <loguru.hpp>
+#include <boost/algorithm/string.hpp>
+#include <boost/algorithm/string/join.hpp>
 #include <rapidjson/document.h>
+#include <rapidjson/writer.h>
+#include <rapidjson/stringbuffer.h>
 
 #include "pempek_assert.hpp"
 
@@ -57,10 +62,11 @@
 
 void Workload::add_job_from_json_object(const Value &object, const string & job_id, double submission_time)
 {
-    Job * job = job_from_json_object(object);
+    Job * job = job_from_json_object(object["job"],object["profile"]);
     job->id = job_id;
     job->submission_time = submission_time;
 
+
     // Let's apply the RJMS delay on the job
     job->walltime += _rjms_delay;
 
@@ -139,11 +145,14 @@
     j->has_walltime = true;
     j->nb_requested_resources = object["res"].GetInt();
     j->unique_number = _job_number++;
+    j->checkpoint_interval = -1.0;
 
     if (object.HasMember("walltime"))
     {
         PPK_ASSERT_ERROR(object["walltime"].IsNumber(), "Invalid json object: 'walltime' member is not a number");
+        
         j->walltime = object["walltime"].GetDouble();
+        LOG_F(INFO,"walltime %g",(double)j->walltime);
     }
 
     PPK_ASSERT_ERROR(j->walltime == -1 || j->walltime > 0,
@@ -152,7 +161,64 @@
 
     if (j->walltime == -1)
         j->has_walltime = false;
+    if (object.HasMember("cores"))
+    {
+        PPK_ASSERT_ERROR(object["cores"].IsInt(), "Invalid json object: 'cores' member is not an integer");
+        j->cores = object["cores"].GetInt();
+    }
+    if (object.HasMember("purpose"))
+    {
+        PPK_ASSERT_ERROR(object["purpose"].IsString(), "Invalid json object: 'purpose' member is not a string");
+        j->purpose = object["purpose"].GetString();
+    }
+    if (object.HasMember("start"))
+    {
+        PPK_ASSERT_ERROR(object["start"].IsNumber(), "Invalid json object: 'start' member is not a number");
+        j->start = object["start"].GetDouble();
+    }
+    if (object.HasMember("profile"))
+    {
+
+    }
+    if (object.HasMember("alloc"))
+    {
+        PPK_ASSERT_ERROR(object["alloc"].IsString(), "Invalid json object: 'alloc' member is not a string");
+        j->future_allocations = IntervalSet::from_string_hyphen(object["alloc"].GetString()," ","-");
+    }
+    else
+        j->future_allocations = IntervalSet::empty_interval_set(); //make this empty if no allocation
+    
+    if (object.HasMember("submission_times"))
+    {
+        const Value & submission_times = object["submission_times"];
+        for (const auto& time : submission_times.GetArray())
+            j->submission_times.push_back(time.GetDouble());
+    }
+    if (object.HasMember("dumptime"))
+    {
+        j->dump_time = object["dumptime"].GetDouble();
+    }
+    if (object.HasMember("readtime"))
+    {
+        j->read_time = object["readtime"].GetDouble();
+    }
+    if (object.HasMember("checkpoint_interval"))
+    {
+        j->checkpoint_interval = object["checkpoint_interval"].GetDouble();
+    }
+    StringBuffer buffer;
+    rapidjson::Writer<StringBuffer> writer(buffer);
+    object.Accept(writer);
+
+    j->json_description = buffer.GetString();
+    
+    return j;
+}
+Job *Workload::job_from_json_object(const Value &job_object,const Value &profile_object)
+{
+    Job * j = job_from_json_object(job_object);
 
+    j->profile = myBatsched::Profile::from_json(j->id,profile_object);
     return j;
 }
 
diff -burN '--exclude=.git*' ./batsched/src/json_workload.hpp ./new_batsched/src/json_workload.hpp
--- ./batsched/src/json_workload.hpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/json_workload.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -7,6 +7,8 @@
 #include "exact_numbers.hpp"
 #include "data_storage.hpp"
 #include <intervalset.hpp>
+#include "./external/batsched_profile.hpp"
+
 
 struct JobAlloc;
 
@@ -18,10 +20,22 @@
     Rational walltime;
     bool has_walltime = true;
     double submission_time = 0;
+    std::vector<double> submission_times ;  //can possibly use for handling resubmitted jobs
     double completion_time = -1;
     mutable std::map<Rational, JobAlloc*> allocations;
+    int cores=1;
+    std::string purpose = "job";
+    IntervalSet future_allocations;
+    double start = -1;
+    myBatsched::ProfilePtr profile = nullptr;
+    std::string json_description;
+    double checkpoint_interval;
+    double dump_time;
+    double read_time;
+    
 };
 
+
 struct JobAlloc
 {
   Rational begin;
@@ -55,14 +69,28 @@
 
     Job * job_from_json_description_string(const std::string & json_string);
     Job * job_from_json_object(const rapidjson::Value & object);
+    Job * job_from_json_object(const rapidjson::Value & job_object, const rapidjson::Value & profile_object);
 
 private:
     void put_file_into_buffer(const std::string & filename);
     void deallocate();
-
+public:
+    bool _checkpointing_on = false;
+    bool _compute_checkpointing = false;
+    double _MTBF = -1.0;
+    double _SMTBF = -1.0;
+    double _repair_time = 0.0;
+    double _host_speed;
+    double _fixed_failures = -1.0;
+    double _checkpointing_interval = -1.0;
+    bool _seed_failures = false;
+    int _queue_depth = -1;
+    bool _subtract_progress_from_walltime = false;
 private:
     char * _fileContents = nullptr;
     std::map<std::string, Job*> _jobs;
     Rational _rjms_delay = 0;
     int _job_number = 0;
+   
 };
+
diff -burN '--exclude=.git*' ./batsched/src/locality.cpp ./new_batsched/src/locality.cpp
--- ./batsched/src/locality.cpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/locality.cpp	2023-06-28 08:26:02.143833485 -0400
@@ -37,7 +37,17 @@
 
     return false;
 }
+bool BasicResourceSelector::fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated)
+{
+    if (job->nb_requested_resources <= (int) available.size())
+    {
+        allocated = job->future_allocations;
+        PPK_ASSERT_ERROR(allocated.size() == (unsigned int)job->nb_requested_resources,"allocated size %d  requested %d",allocated.size(),(unsigned int)job->nb_requested_resources);
+        return true;
+    }
 
+    return false;
+}
 void BasicResourceSelector::select_resources_to_sedate(int nb_resources, const IntervalSet &available, const IntervalSet &potentially_sedated, IntervalSet &to_sedate)
 {
     (void) available;
@@ -90,6 +100,17 @@
 
     return false;
 }
+bool ContiguousResourceSelector::fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated)
+{
+    if (job->nb_requested_resources <= (int) available.size())
+    {
+        allocated = job->future_allocations;
+        PPK_ASSERT_ERROR(allocated.size() == (unsigned int)job->nb_requested_resources);
+        return true;
+    }
+
+    return false;
+}
 
 void ContiguousResourceSelector::select_resources_to_sedate(int nb_resources, const IntervalSet &available, const IntervalSet &potentially_sedated, IntervalSet &to_sedate)
 {
@@ -274,6 +295,17 @@
         PPK_ASSERT_ERROR(allocated.size() == (unsigned int)job->nb_requested_resources);
         return true;
     }
+
+    return false;
+}
+bool LimitedRangeResourceSelector::fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated)
+{
+    if (job->nb_requested_resources <= (int) available.size())
+    {
+        allocated = job->future_allocations;
+        PPK_ASSERT_ERROR(allocated.size() == (unsigned int)job->nb_requested_resources);
+        return true;
+    }
 
     return false;
 }
diff -burN '--exclude=.git*' ./batsched/src/locality.hpp ./new_batsched/src/locality.hpp
--- ./batsched/src/locality.hpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/locality.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -10,6 +10,7 @@
     virtual ~ResourceSelector();
 
     virtual bool fit(const Job * job, const IntervalSet & available, IntervalSet & allocated) = 0;
+    virtual bool fit_reservation(const Job * job, const IntervalSet & available, IntervalSet & allocated) = 0;
     virtual void select_resources_to_sedate(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_sedated, IntervalSet & to_sedate) = 0;
     virtual void select_resources_to_awaken(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken) = 0;
     virtual void select_resources_to_awaken_to_make_job_fit(const Job * job, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken) = 0;
@@ -22,6 +23,7 @@
     ~BasicResourceSelector();
 
     bool fit(const Job * job, const IntervalSet & available, IntervalSet & allocated);
+    bool fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated);
     void select_resources_to_sedate(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_sedated, IntervalSet & to_sedate);
     void select_resources_to_awaken(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
     void select_resources_to_awaken_to_make_job_fit(const Job * job, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
@@ -34,6 +36,7 @@
     ~ContiguousResourceSelector();
 
     bool fit(const Job * job, const IntervalSet & available, IntervalSet & allocated);
+    bool fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated);
     void select_resources_to_sedate(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_sedated, IntervalSet & to_sedate);
     void select_resources_to_awaken(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
     void select_resources_to_awaken_to_make_job_fit(const Job * job, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
@@ -47,6 +50,7 @@
     ~LimitedRangeResourceSelector();
 
     bool fit(const Job *job, const IntervalSet &available, IntervalSet &allocated);
+    bool fit_reservation(const Job *job, const IntervalSet &available, IntervalSet &allocated);
     void select_resources_to_sedate(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_sedated, IntervalSet & to_sedate);
     void select_resources_to_awaken(int nb_resources, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
     void select_resources_to_awaken_to_make_job_fit(const Job * job, const IntervalSet & available, const IntervalSet & potentially_awaken, IntervalSet & to_awaken);
diff -burN '--exclude=.git*' ./batsched/src/machine.cpp ./new_batsched/src/machine.cpp
--- ./batsched/src/machine.cpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/machine.cpp	2023-06-28 08:26:02.143833485 -0400
@@ -0,0 +1,77 @@
+#include "machine.hpp"
+#include "pempek_assert.hpp"
+#include <loguru.hpp>
+#include <regex>
+#include <string>
+
+Machines::~Machines(){
+
+}
+Machine * Machines::operator[](std::string machine_name){
+    PPK_ASSERT_ERROR(_machinesM.count(machine_name) == 1, "Machine '%s' does not exist", machine_name.c_str());
+    return _machinesM.at(machine_name);
+}
+Machine * Machines::operator[](int machine_number){
+    PPK_ASSERT_ERROR(machine_number < _machinesV.size(),"Machine with position '%d' does not exist",machine_number);
+    return _machinesV[machine_number];
+}
+void Machines::add_machine_from_json_object(const rapidjson::Value & object){
+    Machine* new_machine = new Machine;
+    
+    PPK_ASSERT_ERROR(object.HasMember("name"),"machine has no name");
+    new_machine->name = object["name"].GetString();
+    
+    std::regex r(".*[a-zA-Z]+([0-9]+)");//all characters then at least one letter, then capture all numbers
+    //matches m[0](m[1])[not matched]  a30b(109)  @d(309)   b(12)   ab(309)[bc] 
+    //non-matches [1089]  --no characters
+    //non-matches [bbb@], [ccbb]  --no numbers
+    
+    std::smatch m;
+    //std::regex_match(new_machine->name, m, r);
+    //new_machine->id = std::stoi(m.str(m.size()));
+    //new_machine->prefix = new_machine->name.substr(0,m.position(m.size()));
+    for(std::sregex_iterator i = std::sregex_iterator(new_machine->name.begin(), new_machine->name.end(), r);
+                            i != std::sregex_iterator();
+                            ++i )
+    {
+        m = *i;
+    }
+    PPK_ASSERT_ERROR(m.size()==2,"Machine name should be any characters followed by at least one letter followed by numbers.  This should generate a regex match of size 2.  "
+        "This is not the case with machine '%s'",new_machine->name.c_str());
+    new_machine->id = std::stoi(m[1]);
+    new_machine->prefix = new_machine->name.substr(0,m.position(1));
+    
+
+
+    PPK_ASSERT_ERROR(object.HasMember("core_count"),"machine %s has no core_count",new_machine->name.c_str());
+    new_machine->core_count = object["core_count"].GetInt();
+
+    PPK_ASSERT_ERROR(object.HasMember("speed"),"machine %s has no speed",new_machine->name.c_str());
+    new_machine->speed = object["speed"].GetDouble();
+
+    PPK_ASSERT_ERROR(object.HasMember("repair-time"),"machine %s has no repair-time",new_machine->name.c_str());
+    new_machine->repair_time = object["repair-time"].GetDouble();
+
+    _machinesM[new_machine->name] = new_machine; //all machines in a map.  Can get the machine if you know the machine name
+    _machinesV.push_back(new_machine);//all machines in a vector.  can get machines by index.
+    //_machinesByPrefix  // all machines separated by prefix name into maps separated by machine id.
+    //check if the prefix has already been made
+    if (_machinesByPrefix.count(new_machine->prefix) == 1)
+    {
+        //the prefix has already been made
+        //get the map associated with that prefix and add the machine
+        std::map<int,Machine *>* aMap=_machinesByPrefix.at(new_machine->prefix);
+        (*aMap)[new_machine->id]=new_machine;
+
+    }
+    else
+    {
+        //the prefix has not already been made
+        //make a new map and add the machine to that map
+        std::map<int,Machine *> * aMap = new std::map<int,Machine *>;
+        (*aMap)[new_machine->id]=new_machine;
+        _machinesByPrefix[new_machine->prefix]=aMap;
+
+    }
+}
+    
diff -burN '--exclude=.git*' ./batsched/src/machine.hpp ./new_batsched/src/machine.hpp
--- ./batsched/src/machine.hpp	1969-12-31 19:00:00.000000000 -0500
+++ ./new_batsched/src/machine.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -0,0 +1,35 @@
+
+#ifndef MACHINE_HPP
+#define MACHINE_HPP
+#include <map>
+#include <string>
+#include <vector>
+
+#include <rapidjson/document.h>
+
+
+
+struct Machine{
+    double speed;
+    double repair_time;
+    std::string name;
+    std::string prefix;
+    int id;
+    std::string role;
+    std::string core_count;
+    int cores_available;
+};
+class Machines{
+    public:
+            ~Machines();
+            Machine * operator[](std::string machine_name);
+            Machine * operator[](int machine_number);
+            void add_machine_from_json_object(const rapidjson::Value & object);
+    private:
+        std::map<std::string,Machine *> _machinesM;
+        std::map<std::string,std::map<int,Machine *> *> _machinesByPrefix;
+        std::vector<Machine *> _machinesV;
+
+};
+
+#endif
\ No newline at end of file
diff -burN '--exclude=.git*' ./batsched/src/main.cpp ./new_batsched/src/main.cpp
--- ./batsched/src/main.cpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/main.cpp	2023-06-28 08:26:02.140500092 -0400
@@ -1,7 +1,12 @@
 #include <stdio.h>
+#include <chrono>
+#include <thread>
+
 #include <vector>
+#include <unordered_map>
 #include <fstream>
 #include <set>
+#include <utility>
 
 #include <boost/program_options.hpp>
 #include <boost/algorithm/string.hpp>
@@ -9,20 +14,33 @@
 
 #include <rapidjson/document.h>
 
+#include <rapidjson/writer.h>
+
 #include <loguru.hpp>
 
 #include "external/taywee_args.hpp"
 
+// Added to get profiles into batsched but we get the whole workload
+#include "external/batsched_workload.hpp"
+#include "external/batsched_job.hpp"
+#include "external/batsched_profile.hpp"
+
+
 #include "isalgorithm.hpp"
 #include "decision.hpp"
 #include "network.hpp"
 #include "json_workload.hpp"
 #include "pempek_assert.hpp"
 #include "data_storage.hpp"
+#include "batsched_tools.hpp"
+#include "machine.hpp"
 
-#include "algo/conservative_bf.hpp"
+
+/*
 #include "algo/crasher.hpp"
+*/
 #include "algo/easy_bf.hpp"
+/*
 #include "algo/easy_bf_fast.hpp"
 #include "algo/easy_bf_plot_liquid_load_horizon.hpp"
 #include "algo/energy_bf.hpp"
@@ -33,7 +51,6 @@
 #include "algo/energy_bf_machine_subpart_sleeper.hpp"
 #include "algo/energy_watcher.hpp"
 #include "algo/filler.hpp"
-#include "algo/fcfs.hpp"
 #include "algo/fcfs_fast.hpp"
 #include "algo/killer.hpp"
 #include "algo/killer2.hpp"
@@ -43,10 +60,19 @@
 #include "algo/sequencer.hpp"
 #include "algo/submitter.hpp"
 #include "algo/wt_estimator.hpp"
+*/
+#include "algo/conservative_bf.hpp"
+#include "algo/easy_bf_fast2.hpp"
+#include "algo/easy_bf_fast2_holdback.hpp"
+#include "algo/fcfs_fast2.hpp"
+
+
 
 using namespace std;
 using namespace boost;
 
+namespace myB = myBatsched;
+
 namespace n = network;
 namespace r = rapidjson;
 
@@ -75,15 +101,17 @@
 int main(int argc, char ** argv)
 {
     const set<string> variants_set = {"conservative_bf", "crasher", "easy_bf", "easy_bf_fast",
+                                       "easy_bf_fast2","easy_bf_fast2_holdback",
                                       "easy_bf_plot_liquid_load_horizon",
                                       "energy_bf", "energy_bf_dicho", "energy_bf_idle_sleeper",
                                       "energy_bf_monitoring",
                                       "energy_bf_monitoring_inertial", "energy_bf_subpart_sleeper",
-                                      "energy_watcher", "fcfs", "fcfs_fast",
+                                      "energy_watcher", "fcfs_fast",
+                                      "fcfs_fast2",
                                       "filler", "killer", "killer2", "random", "rejecter",
                                       "sequencer", "sleeper", "submitter", "waiting_time_estimator"};
     const set<string> policies_set = {"basic", "contiguous"};
-    const set<string> queue_orders_set = {"fcfs", "lcfs", "desc_bounded_slowdown", "desc_slowdown",
+    const set<string> queue_orders_set = {"fcfs", "original_fcfs" ,"lcfs", "desc_bounded_slowdown", "desc_slowdown",
                                           "asc_size", "desc_size", "asc_walltime", "desc_walltime"};
     const set<string> verbosity_levels_set = {"debug", "info", "quiet", "silent"};
 
@@ -101,7 +129,7 @@
     args::HelpFlag flag_help(parser, "help", "Display this help menu", {'h', "help"});
     args::CompletionFlag completion(parser, {"complete"});
 
-    args::ValueFlag<double> flag_rjms_delay(parser, "delay", "Sets the expected time that the RJMS takes to do some things like killing a job", {'d', "rjms_delay"}, 5.0);
+    args::ValueFlag<double> flag_rjms_delay(parser, "delay", "Sets the expected time that the RJMS takes to do some things like killing a job", {'d', "rjms_delay"}, 0.0);
     args::ValueFlag<string> flag_selection_policy(parser, "policy", "Sets the resource selection policy. Available values are " + policies_string, {'p', "policy"}, "basic");
     args::ValueFlag<string> flag_socket_endpoint(parser, "endpoint", "Sets the socket endpoint.", {'s', "socket-endpoint"}, "tcp://*:28000");
     args::ValueFlag<string> flag_scheduling_variant(parser, "variant", "Sets the scheduling variant. Available values are " + variants_string, {'v', "variant"}, "filler");
@@ -109,6 +137,7 @@
     args::ValueFlag<string> flag_variant_options_filepath(parser, "options-filepath", "Sets the scheduling variant options as the content of the given filepath. Overrides the variant_options options.", {"variant_options_filepath"}, "");
     args::ValueFlag<string> flag_queue_order(parser, "order", "Sets the queue order. Available values are " + queue_orders_string, {'o', "queue_order"}, "fcfs");
     args::ValueFlag<string> flag_verbosity_level(parser, "verbosity-level", "Sets the verbosity level. Available values are " + verbosity_levels_string, {"verbosity"}, "info");
+    //args::ValueFlag<string> flag_svg_prefix(parser,"svg_prefix", "Sets the prefix for outputing svg files using Schedule.cpp",{"svg_prefix"},"/tmp/");
     args::ValueFlag<bool> flag_call_make_decisions_on_single_nop(parser, "flag", "If set to true, make_decisions will be called after single NOP messages.", {"call_make_decisions_on_single_nop"}, true);
     args::Flag flag_version(parser, "version", "Shows batsched version", {"version"});
 
@@ -174,6 +203,8 @@
     string variant_options = flag_variant_options.Get();
     string variant_options_filepath = flag_variant_options_filepath.Get();
     string verbosity_level = flag_verbosity_level.Get();
+    //string svg_prefix = flag_svg_prefix.Get();
+
     double rjms_delay = flag_rjms_delay.Get();
     bool call_make_decisions_on_single_nop = flag_call_make_decisions_on_single_nop.Get();
 
@@ -199,6 +230,8 @@
         // Queue order
         if (queue_order == "fcfs")
             order = new FCFSOrder;
+        else if (queue_order == "original_fcfs")
+            order = new OriginalFCFSOrder;
         else if (queue_order == "lcfs")
             order = new LCFSOrder;
         else if (queue_order == "desc_bounded_slowdown")
@@ -259,14 +292,15 @@
         LOG_F(1, "variant_options = '%s'", variant_options.c_str());
 
         // Scheduling variant
-        if (scheduling_variant == "filler")
+        /*if (scheduling_variant == "filler")
             algo = new Filler(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
-        else if (scheduling_variant == "conservative_bf")
-            algo = new ConservativeBackfilling(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
+        
         else if (scheduling_variant == "crasher")
             algo = new Crasher(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
-        else if (scheduling_variant == "easy_bf")
+        */
+        if (scheduling_variant == "easy_bf")
             algo = new EasyBackfilling(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
+        /*
         else if (scheduling_variant == "easy_bf_fast")
             algo = new EasyBackfillingFast(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
         else if (scheduling_variant == "easy_bf_plot_liquid_load_horizon")
@@ -289,6 +323,18 @@
             algo = new FCFS(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
         else if (scheduling_variant == "fcfs_fast")
             algo = new FCFSFast(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
+        */
+       
+        if (scheduling_variant == "fcfs_fast2")
+            algo = new FCFSFast2(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
+        else if (scheduling_variant == "easy_bf_fast2")
+            algo = new easy_bf_fast2(&w, &decision, queue, selector,rjms_delay, &json_doc_variant_options);
+        else if (scheduling_variant == "easy_bf_fast2_holdback")
+            algo = new easy_bf_fast2_holdback(&w, &decision, queue, selector,rjms_delay, &json_doc_variant_options);
+        else if (scheduling_variant == "conservative_bf")
+            algo = new ConservativeBackfilling(&w, &decision,queue,selector,rjms_delay,&json_doc_variant_options);
+            //algo = new ConservativeBackfilling(&w, &decision, queue, selector, rjms_delay, svg_prefix, &json_doc_variant_options);
+        /*
         else if (scheduling_variant == "killer")
             algo = new Killer(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
         else if (scheduling_variant == "killer2")
@@ -305,11 +351,11 @@
             algo = new Submitter(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
         else if (scheduling_variant == "waiting_time_estimator")
             algo = new WaitingTimeEstimator(&w, &decision, queue, selector, rjms_delay, &json_doc_variant_options);
-
-        // Network
+        */
+        bool success = false;
         Network n;
         n.bind(socket_endpoint);
-
+           LOG_F(1, "before run");
         // Run the simulation
         run(n, algo, decision, w, call_make_decisions_on_single_nop);
     }
@@ -347,40 +393,44 @@
 void run(Network & n, ISchedulingAlgorithm * algo, SchedulingDecision & d,
          Workload & workload, bool call_make_decisions_on_single_nop)
 {
+    LOG_F(INFO,"line 371 main.cpp");
     bool simulation_finished = false;
-
+    myB::Workloads myWorkloads;
     // Redis creation
     RedisStorage redis;
     bool redis_enabled = false;
     algo->set_redis(&redis);
-
+    //LOG_F(INFO,"line 378 main.cpp");
     while (!simulation_finished)
     {
+        LOG_F(INFO,"line 381 main.cpp");
         string received_message;
         n.read(received_message);
-
+        //LOG_F(INFO,"line 384 main.cpp");
         if (boost::trim_copy(received_message).empty())
             throw runtime_error("Empty message received (connection lost ?)");
 
         d.clear();
-
+        //LOG_F(INFO,"line 389 main.cpp");
         r::Document doc;
         doc.Parse(received_message.c_str());
 
         double message_date = doc["now"].GetDouble();
         double current_date = message_date;
         bool requested_callback_received = false;
-
+        //LOG_F(INFO,"line 396 main.cpp");
         // Let's handle all received events
         const r::Value & events_array = doc["events"];
 
         for (unsigned int event_i = 0; event_i < events_array.Size(); ++event_i)
         {
+            LOG_F(INFO,"line 400 main.cpp");
             const r::Value & event_object = events_array[event_i];
             const std::string event_type = event_object["type"].GetString();
             current_date = event_object["timestamp"].GetDouble();
             const r::Value & event_data = event_object["data"];
-
+            LOG_F(INFO,"DEBUG");
+            //LOG_F(INFO,"line 405 main.cpp");
             if (event_type == "SIMULATION_BEGINS")
             {
                 int nb_resources;
@@ -404,11 +454,69 @@
                     redis.connect_to_server(redis_hostname, redis_port, nullptr);
                     redis.set_instance_key_prefix(redis_prefix);
                 }
+                //get the workloads
+                
+                
+                for (auto &member : event_data["workloads"].GetObject())
+                {
+                        std::string workload_name = member.name.GetString();
+                        std::string workload_filename = member.value.GetString();
+                        myB::Workload * myWorkload= myB::Workload::new_static_workload(workload_name,event_data["workloads"][workload_name.c_str()].GetString());
+                        myWorkload->_checkpointing_on = event_data["config"]["checkpointing_on"].GetBool();
+                        myWorkload->_compute_checkpointing = event_data["config"]["compute_checkpointing"].GetBool();
+                        myWorkload->_MTBF = event_data["config"]["MTBF"].GetDouble();
+                        myWorkload->_SMTBF = event_data["config"]["SMTBF"].GetDouble();
+                        myWorkload->_repair_time = event_data["config"]["repair_time"].GetDouble();
 
+                        
+
+                        r::Document myCopy;
+                        myCopy.CopyFrom(event_data,myCopy.GetAllocator());
+                        r::Value & temp = myCopy["jobs"];
+                        r::Value & job_json = temp[workload_name.c_str()];
+                        r::Value & temp2 = myCopy["profiles"];
+                        r::Value &profile_json = temp2[workload_name.c_str()];
+                        myWorkload->load_from_batsim(workload_filename,
+                                                     job_json,
+                                                     profile_json);
+                        LOG_F(INFO,"line 468");
+                        myWorkload->_host_speed = event_data["compute_resources"][0]["speed"].GetDouble();
+                        myWorkloads.insert_workload(workload_name,myWorkload);
+                }
+                LOG_F(INFO,"line 472");
+                myWorkloads._checkpointing_on = event_data["config"]["checkpointing_on"].GetBool();
+                myWorkloads._compute_checkpointing = event_data["config"]["compute_checkpointing"].GetBool();
+                myWorkloads._MTBF = event_data["config"]["MTBF"].GetDouble();
+                myWorkloads._SMTBF = event_data["config"]["SMTBF"].GetDouble();
+                myWorkloads._repair_time = event_data["config"]["repair_time"].GetDouble();
+                myWorkloads._fixed_failures = event_data["config"]["fixed_failures"].GetDouble();
+                myWorkloads._host_speed = event_data["compute_resources"][0]["speed"].GetDouble();
+                
+                Machines * machines = new Machines;
+                LOG_F(INFO,"line 489");
+                for(const rapidjson::Value & resource : event_data["compute_resources"].GetArray())
+                {
+                    machines->add_machine_from_json_object(resource);
+                }
+                algo->set_machines(machines);
+                workload._checkpointing_on = event_data["config"]["checkpointing_on"].GetBool();
+                workload._compute_checkpointing = event_data["config"]["compute_checkpointing"].GetBool();
+                workload._checkpointing_interval = event_data["config"]["checkpointing_interval"].GetDouble();
+                workload._MTBF = event_data["config"]["MTBF"].GetDouble();
+                workload._SMTBF = event_data["config"]["SMTBF"].GetDouble();
+                workload._repair_time = event_data["config"]["repair_time"].GetDouble();
+                workload._fixed_failures = event_data["config"]["fixed_failures"].GetDouble();
+                workload._host_speed = event_data["compute_resources"][0]["speed"].GetDouble();
+                workload._seed_failures = event_data["config"]["seed-failures"].GetBool();
+                workload._queue_depth = event_data["config"]["scheduler-queue-depth"].GetInt();
+                workload._subtract_progress_from_walltime = event_data["config"]["subtract-progress-from-walltime"].GetBool();
+                LOG_F(INFO, "before set workloads");
+                algo->set_workloads(&myWorkloads);
+            LOG_F(INFO, "after set workloads");
                 d.set_redis(redis_enabled, &redis);
 
                 algo->set_nb_machines(nb_resources);
-                algo->on_simulation_start(current_date, event_data["config"]);
+                algo->on_simulation_start(current_date, event_data);
             }
             else if (event_type == "SIMULATION_ENDS")
             {
@@ -417,20 +525,26 @@
             }
             else if (event_type == "JOB_SUBMITTED")
             {
+                LOG_F(INFO,"DEBUG");
                 string job_id = event_data["job_id"].GetString();
-
+                 LOG_F(INFO,"DEBUG");
                 if (redis_enabled)
                     workload.add_job_from_redis(redis, job_id, current_date);
                 else
-                    workload.add_job_from_json_object(event_data["job"], job_id, current_date);
-
+                    workload.add_job_from_json_object(event_data,job_id,current_date);
+                 LOG_F(INFO,"DEBUG");
                 algo->on_job_release(current_date, {job_id});
+                 LOG_F(INFO,"DEBUG");
             }
             else if (event_type == "JOB_COMPLETED")
             {
+                //LOG_F(INFO,"line 486 main.cpp");
                 string job_id = event_data["job_id"].GetString();
+                //LOG_F(INFO,"line 488 main.cpp");
                 workload[job_id]->completion_time = current_date;
+                //LOG_F(INFO,"line 490 main.cpp");
                 algo->on_job_end(current_date, {job_id});
+                //LOG_F(INFO,"line 492 main.cpp");
             }
             else if (event_type == "RESOURCE_STATE_CHANGED")
             {
@@ -440,23 +554,52 @@
             }
             else if (event_type == "JOB_KILLED")
             {
-                const r::Value & job_ids_map = event_data["job_progress"];
-                PPK_ASSERT_ERROR(job_ids_map.GetType() == r::kObjectType);
-
-                vector<string> job_ids;
-
-                for (auto itr = job_ids_map.MemberBegin(); itr != job_ids_map.MemberEnd(); ++itr)
-                {
-                    string job_id = itr->name.GetString();
-                    job_ids.push_back(job_id);
+                LOG_F(INFO,"DEBUG");
+                const r::Value & job_msgs = event_data["job_msgs"];
+                PPK_ASSERT_ERROR(event_data["job_msgs"].IsArray());
+                LOG_F(INFO,"DEBUG");
+                std::unordered_map<std::string,batsched_tools::Job_Message *> job_msgs_map;
+
+                for (auto itr = job_msgs.Begin(); itr != job_msgs.End(); ++itr)
+                {
+                    LOG_F(INFO,"DEBUG");
+                    batsched_tools::Job_Message * msg = new batsched_tools::Job_Message;
+                    msg->id = (*itr)["id"].GetString();
+                    LOG_F(INFO,"DEBUG");
+                    msg->forWhat = static_cast<batsched_tools::KILL_TYPES>((*itr)["forWhat"].GetInt());
+                    const r::Value & job_progress = (*itr)["job_progress"];
+                    r::StringBuffer sb;
+                    r::Writer<r::StringBuffer> writer(sb);
+                    job_progress.Accept(writer);
+                    msg->progress_str = sb.GetString();
+                    
+                    
+                    LOG_F(INFO,"DEBUG");
+                    LOG_F(INFO,"DEBUG");
+                    //job_progress.CopyFrom( itr->value["job_progress"].,doc.GetAllocator());                    
+                    r::Document d;
+                    d.Parse(sb.GetString());
+                    LOG_F(INFO,"DEBUG");
+
+                    while( !(d.HasMember("progress")))
+                    {
+                        PPK_ASSERT_ERROR(d.HasMember("current_task"),"While traversing the job_progress rapidjson of a JOB_KILLED event there was no 'progress' or 'current_task'");
+                        d["current_task"].Accept(writer);
+                        
+                        d.Parse(sb.GetString());
+                    }
+                    LOG_F(INFO,"DEBUG");
+                    msg->progress = d["progress"].GetDouble();
+                    job_msgs_map.insert(std::make_pair(msg->id,msg));
                 }
 
-                algo->on_job_killed(current_date, job_ids);
+                algo->on_job_killed(current_date, job_msgs_map);
             }
             else if (event_type == "REQUESTED_CALL")
             {
+                LOG_F(INFO,"DEBUG");
                 requested_callback_received = true;
-                algo->on_requested_call(current_date);
+                algo->on_requested_call(current_date,event_data["id"].GetInt(),(batsched_tools::call_me_later_types)event_data["forWhat"].GetInt());
             }
             else if (event_type == "ANSWER")
             {
@@ -519,6 +662,29 @@
                     IntervalSet resources = IntervalSet::from_string_hyphen(event_data["resources"].GetString(), " ");
                     algo->on_machine_unavailable_notify_event(current_date, resources);
                 }
+                else if (notify_type == "myKillJob")
+                {
+                    
+                        algo->on_myKillJob_notify_event(current_date);
+                    
+                }
+                else if (notify_type == "job_fault")
+                {
+                    LOG_F(INFO,"main.cpp notify_type==jobfault");
+                    std::string job = event_data["job"].GetString();
+                    algo->on_job_fault_notify_event(current_date,job);
+                }
+                else if (notify_type == "batsim_metadata")
+                {
+                    
+                    std::string json_desc = event_data["metadata"].GetString();
+                    LOG_F(INFO,"batsim_meta: %s",json_desc.c_str());
+                    //LOG_F(INFO,"line 599 main.cpp");
+                }
+                else if (notify_type == "test")
+                {
+                        LOG_F(INFO,"test %f",current_date);
+                }
                 else
                 {
                     throw runtime_error("Unknown NOTIFY type received. Type = " + notify_type);
@@ -529,21 +695,24 @@
             {
                 throw runtime_error("Unknown event received. Type = " + event_type);
             }
+            //LOG_F(INFO,"line 615 main.cpp");
         }
 
         bool requested_callback_only = requested_callback_received && (events_array.Size() == 1);
-
+        //LOG_F(INFO,"line 621 main.cpp");
         // make_decisions is not called if (!call_make_decisions_on_single_nop && single_nop_received)
         if (!(!call_make_decisions_on_single_nop && requested_callback_only))
         {
             SortableJobOrder::UpdateInformation update_info(current_date);
+            LOG_F(1, "before make decisions");
             algo->make_decisions(message_date, &update_info, nullptr);
             algo->clear_recent_data_structures();
         }
-
+        //LOG_F(INFO,"line 629 main.cpp");
         message_date = max(message_date, d.last_date());
-
+        //LOG_F(INFO,"line 631 main.cpp");
         const string & message_to_send = d.content(message_date);
+        //LOG_F(INFO,"line 633 main.cpp");
         n.write(message_to_send);
     }
 }
diff -burN '--exclude=.git*' ./batsched/src/protocol.cpp ./new_batsched/src/protocol.cpp
--- ./batsched/src/protocol.cpp	2023-07-01 09:24:59.678835500 -0400
+++ ./new_batsched/src/protocol.cpp	2023-06-28 08:26:02.140500092 -0400
@@ -4,6 +4,7 @@
 #include <rapidjson/writer.h>
 
 #include "pempek_assert.hpp"
+#include "batsched_tools.hpp"
 
 using namespace rapidjson;
 using namespace std;
@@ -211,6 +212,7 @@
     _is_empty = false;
 
     Value data(rapidjson::kObjectType);
+   
     data.AddMember("job_id", Value().SetString(job_id.c_str(), _alloc), _alloc);
     data.AddMember("alloc", Value().SetString(allocated_resources.to_string_hyphen(" ", "-").c_str(), _alloc), _alloc);
 
@@ -261,26 +263,33 @@
     _events.PushBack(event, _alloc);
 }
 
-void JsonProtocolWriter::append_kill_job(const vector<string> &job_ids,
+void JsonProtocolWriter::append_kill_job(const vector<batsched_tools::Job_Message *> &job_msgs,
                                          double date)
 {
     /* {
       "timestamp": 10.0,
       "type": "KILL_JOB",
-      "data": {"job_ids": ["w0!1", "w0!2"]}
+      "data": {"job_ids": [{"id":"w0!1","forWhat": 1},{"id":"w0!2","forWhat": 3}]}
     } */
 
     PPK_ASSERT_ERROR(date >= _last_date, "Date inconsistency");
     _last_date = date;
     _is_empty = false;
 
-    Value job_ids_array(rapidjson::kArrayType);
-    job_ids_array.Reserve(job_ids.size(), _alloc);
-    for (const string & job_id : job_ids)
-        job_ids_array.PushBack(Value().SetString(job_id.c_str(), _alloc), _alloc);
+    Value job_msgs_array(rapidjson::kArrayType);
+    //not sure how this next line works, so not doing it
+    //job_ids_array.Reserve(job_msgs.size(), _alloc);
+    for (batsched_tools::Job_Message * job_msg : job_msgs)
+    {
+        Value job_msg_json(rapidjson::kObjectType);
+        job_msg_json.AddMember("id",Value().SetString(job_msg->id.c_str(),_alloc),_alloc);
+        job_msg_json.AddMember("forWhat",Value().SetInt(static_cast<int>(job_msg->forWhat)),_alloc);
+        job_msgs_array.PushBack(job_msg_json, _alloc);
+
+    }
 
     Value data(rapidjson::kObjectType);
-    data.AddMember("job_ids", job_ids_array, _alloc);
+    data.AddMember("job_msgs", job_msgs_array, _alloc);
 
     Value event(rapidjson::kObjectType);
     event.AddMember("timestamp", Value().SetDouble(date), _alloc);
@@ -345,13 +354,13 @@
     _events.PushBack(event, _alloc);
 }
 
-void JsonProtocolWriter::append_call_me_later(double future_date,
+void JsonProtocolWriter::append_call_me_later(batsched_tools::call_me_later_types forWhat,int id,double future_date,
                                               double date)
 {
     /* {
       "timestamp": 10.0,
       "type": "CALL_ME_LATER",
-      "data": {"timestamp": 25.5}
+      "data": {"timestamp": 25.5,"id":2,"forWhat":3}
     } */
 
     PPK_ASSERT_ERROR(date >= _last_date, "Date inconsistency");
@@ -360,6 +369,8 @@
 
     Value data(rapidjson::kObjectType);
     data.AddMember("timestamp", Value().SetDouble(future_date), _alloc);
+    data.AddMember("id", Value().SetInt(id), _alloc);
+    data.AddMember("forWhat", Value().SetInt((int)forWhat), _alloc);
 
     Value event(rapidjson::kObjectType);
     event.AddMember("timestamp", Value().SetDouble(date), _alloc);
@@ -368,6 +379,30 @@
 
     _events.PushBack(event, _alloc);
 }
+void JsonProtocolWriter::append_generic_notification(const std::string &type,const std::string &notify_data,double date)
+{
+  /* {
+      "timestamp": 42.0,
+      "type": "NOTIFY",
+      "data": { "type": "queue_size","data":"12" }
+    } */
+    PPK_ASSERT_ERROR(date >= _last_date, "Date inconsistency");
+    _last_date = date;
+    _is_empty = false;
+
+    Value data(rapidjson::kObjectType);
+    data.AddMember("type", Value().SetString(type.c_str(), _alloc), _alloc);
+    data.AddMember("data", Value().SetString(notify_data.c_str(), _alloc), _alloc);
+
+    Value event(rapidjson::kObjectType);
+    event.AddMember("timestamp", Value().SetDouble(date), _alloc);
+    event.AddMember("type", Value().SetString("NOTIFY"), _alloc);
+    event.AddMember("data", data, _alloc);
+
+    _events.PushBack(event, _alloc);
+
+
+}
 
 void JsonProtocolWriter::append_scheduler_finished_submitting_jobs(double date)
 {
@@ -386,6 +421,29 @@
 
     Value event(rapidjson::kObjectType);
     event.AddMember("timestamp", Value().SetDouble(date), _alloc);
+    event.AddMember("type", Value().SetString("NOTIFY"), _alloc);
+    event.AddMember("data", data, _alloc);
+
+    _events.PushBack(event, _alloc);
+}
+
+void JsonProtocolWriter::append_scheduler_continue_submitting_jobs(double date)
+{
+    /* {
+      "timestamp": 42.0,
+      "type": "NOTIFY",
+      "data": { "type": "continue_registration" }
+    } */
+
+    PPK_ASSERT_ERROR(date >= _last_date, "Date inconsistency");
+    _last_date = date;
+    _is_empty = false;
+
+    Value data(rapidjson::kObjectType);
+    data.AddMember("type", Value().SetString("continue_registration", _alloc), _alloc);
+
+    Value event(rapidjson::kObjectType);
+    event.AddMember("timestamp", Value().SetDouble(date), _alloc);
     event.AddMember("type", Value().SetString("NOTIFY"), _alloc);
     event.AddMember("data", data, _alloc);
 
diff -burN '--exclude=.git*' ./batsched/src/protocol.hpp ./new_batsched/src/protocol.hpp
--- ./batsched/src/protocol.hpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/protocol.hpp	2023-06-28 08:26:02.143833485 -0400
@@ -6,8 +6,8 @@
 #include <map>
 
 #include <rapidjson/document.h>
-
 #include <intervalset.hpp>
+#include "batsched_tools.hpp"
 
 struct BatsimContext;
 
@@ -60,6 +60,7 @@
                                       const std::string & profile_name,
                                       const std::string & profile_description,
                                       double date) = 0;
+    virtual void append_generic_notification(const std::string &type,const std::string &notify_data,double date) = 0;
 
     /**
      * @brief Appends an EXECUTE_JOB event.
@@ -77,6 +78,7 @@
                                     double date,
                                     const std::vector<int> & executor_to_allocated_resource_mapping = {}) = 0;
 
+
     /**
      * @brief Appends a REJECT_JOB event.
      * @param[in] job_id The job identifier. Must be known by Batsim. Must be in the SUBMITTED state.
@@ -91,7 +93,7 @@
      *                    Must be in the RUNNING state (COMPLETED jobs are ignored).
      * @param[in] date The event date. Must be greater than or equal to the previous event.
      */
-    virtual void append_kill_job(const std::vector<std::string> & job_ids,
+    virtual void append_kill_job(const std::vector<batsched_tools::Job_Message *> & job_msgs,
                                  double date) = 0;
 
     /**
@@ -120,7 +122,7 @@
      *            Must be greater than date.
      * @param[in] date The event date. Must be greater than or equal to the previous event.
      */
-    virtual void append_call_me_later(double future_date,
+    virtual void append_call_me_later(batsched_tools::call_me_later_types forWhat,int id, double future_date,
                                       double date) = 0;
 
     /**
@@ -129,6 +131,8 @@
      */
     virtual void append_scheduler_finished_submitting_jobs(double date) = 0;
 
+    virtual void append_scheduler_continue_submitting_jobs(double date) = 0;
+
 
     // Management functions
     /**
@@ -208,6 +212,7 @@
                            const std::string & job_description = "",
                            const std::string & profile_description = "",
                            bool send_profile = true);
+    void append_generic_notification(const std::string &type,const std::string &notify_data,double date);
 
     void append_register_profile(const std::string & workload_name,
                                           const std::string & profile_name,
@@ -244,7 +249,7 @@
      *                    Must be in the RUNNING state (COMPLETED jobs are ignored).
      * @param[in] date The event date. Must be greater than or equal to the previous event.
      */
-    void append_kill_job(const std::vector<std::string> & job_ids,
+    void append_kill_job(const std::vector<batsched_tools::Job_Message *> & job_msgs,
                          double date);
 
     /**
@@ -273,7 +278,7 @@
      *            Must be greater than date.
      * @param[in] date The event date. Must be greater than or equal to the previous event.
      */
-    void append_call_me_later(double future_date,
+    void append_call_me_later(batsched_tools::call_me_later_types forWhat, int id,double future_date,
                               double date);
 
     /**
@@ -282,6 +287,7 @@
      */
     void append_scheduler_finished_submitting_jobs(double date);
 
+    void append_scheduler_continue_submitting_jobs(double date);
     // Management functions
     /**
      * @brief Clears inner content. Should be called directly after generate_current_message.
diff -burN '--exclude=.git*' ./batsched/src/queue.cpp ./new_batsched/src/queue.cpp
--- ./batsched/src/queue.cpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/queue.cpp	2023-06-28 08:26:02.140500092 -0400
@@ -19,6 +19,7 @@
 
 }
 
+
 SortableJobOrder::~SortableJobOrder()
 {
 
@@ -39,6 +40,10 @@
 {
 
 }
+OriginalFCFSOrder::~OriginalFCFSOrder()
+{
+
+}
 
 bool FCFSOrder::compare(const SortableJob *j1, const SortableJob *j2, const SortableJobOrder::CompareInformation *info) const
 {
@@ -55,6 +60,21 @@
     (void) job;
     (void) info;
 }
+bool OriginalFCFSOrder::compare(const SortableJob *j1, const SortableJob *j2, const SortableJobOrder::CompareInformation *info) const
+{
+    (void) info;
+
+    if (j1->release_dates[0] == j2->release_dates[0])
+        return j1->job->id < j2->job->id;
+    else
+        return j1->release_dates[0] < j2->release_dates[0];
+}
+
+void OriginalFCFSOrder::updateJob(SortableJob *job, const SortableJobOrder::UpdateInformation *info) const
+{
+    (void) job;
+    (void) info;
+}
 
 
 LCFSOrder::~LCFSOrder()
@@ -235,6 +255,7 @@
 {
     SortableJob * sjob = new SortableJob;
     sjob->job = job;
+    sjob->release_dates = job->submission_times;
     sjob->release_date = update_info->current_date;
 
     _jobs.push_back(sjob);
@@ -353,4 +374,17 @@
 {
     return _jobs.end();
 }
+Queue& Queue::operator=(const Queue&  other){
+    _order = other._order;
+    _jobs = other._jobs;
+    return *this;
+    
+}
+
+//this function was meant for our conservative_bf using reservations
+//we added an OriginalFCFSOrder instead
+void Queue::set_release_date_on_job(std::list<SortableJob *>::iterator job_it,Rational release_date){
+    SortableJob * sjob = *job_it;
+    sjob->release_date = release_date;
+}
 
diff -burN '--exclude=.git*' ./batsched/src/queue.hpp ./new_batsched/src/queue.hpp
--- ./batsched/src/queue.hpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/queue.hpp	2023-06-28 08:26:02.140500092 -0400
@@ -10,6 +10,7 @@
 {
     const Job * job;
     Rational release_date;
+    std::vector<double> release_dates;
     Rational slowdown;
     Rational bounded_slowdown;
 
@@ -20,6 +21,7 @@
 class SortableJobOrder
 {
 public:
+    
     struct CompareInformation
     {
         virtual ~CompareInformation() = 0;
@@ -46,6 +48,13 @@
     bool compare(const SortableJob * j1, const SortableJob * j2, const CompareInformation * info = nullptr) const;
     void updateJob(SortableJob * job, const UpdateInformation * info = nullptr) const;
 };
+class OriginalFCFSOrder : public SortableJobOrder
+{
+public:
+    ~OriginalFCFSOrder();
+    bool compare(const SortableJob * j1, const SortableJob * j2, const CompareInformation * info = nullptr) const;
+    void updateJob(SortableJob * job, const UpdateInformation * info = nullptr) const;
+};
 
 class LCFSOrder : public SortableJobOrder
 {
@@ -117,7 +126,7 @@
     std::list<SortableJob *>::iterator remove_job(const Job * job);
     std::list<SortableJob *>::iterator remove_job(std::list<SortableJob *>::iterator job_it);
     void sort_queue(SortableJobOrder::UpdateInformation * update_info, SortableJobOrder::CompareInformation * compare_info = nullptr);
-
+    void set_release_date_on_job(std::list<SortableJob *>::iterator job_it ,Rational release_date);
     const Job * first_job() const;
     const Job * first_job_or_nullptr() const;
     bool contains_job(const Job * job) const;
@@ -133,6 +142,7 @@
 
     std::list<SortableJob *>::const_iterator begin() const;
     std::list<SortableJob *>::const_iterator end() const;
+    Queue &operator=(const Queue& other);
 
 private:
     std::list<SortableJob *> _jobs;
diff -burN '--exclude=.git*' ./batsched/src/schedule.cpp ./new_batsched/src/schedule.cpp
--- ./batsched/src/schedule.cpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/schedule.cpp	2023-06-28 08:26:02.140500092 -0400
@@ -1,4 +1,5 @@
 #include "schedule.hpp"
+#include <cstdlib>
 
 #include <boost/algorithm/string/join.hpp>
 #include <fstream>
@@ -7,10 +8,18 @@
 #include <loguru.hpp>
 
 #include "pempek_assert.hpp"
+#if __has_include(<filesystem>)
+#include <filesystem>
+namespace fs = std::filesystem;
+#elif __has_include(<experimental/filesystem>)
+#include <experimental/filesystem>
+namespace fs = std::experimental::filesystem;
+#endif
+
 
 using namespace std;
 
-Schedule::Schedule(int nb_machines, Rational initial_time)
+Schedule::Schedule(int nb_machines,Rational initial_time)
 {
     PPK_ASSERT_ERROR(nb_machines > 0);
     _nb_machines = nb_machines;
@@ -26,13 +35,310 @@
     _profile.push_back(slice);
 
     generate_colors();
+    _svg_highlight_machines = IntervalSet::empty_interval_set();
+    _repair_machines.empty_interval_set();
 }
 
+
 Schedule::Schedule(const Schedule &other)
 {
     *this = other;
 }
+void Schedule::set_svg_prefix(std::string svg_prefix){
+    _svg_prefix = svg_prefix;
+    fs::create_directories(_svg_prefix);
+    
+}
+void Schedule::set_now(Rational now){
+    if (_now != now)
+    {
+        ofstream f(_svg_prefix + "/time_frames.txt",std::ios_base::app);
+
+    if (f.is_open())
+        f << setw(10)<<now <<"\t\t"<<setw(10)<<_output_number<< "\n";
+
+    f.close();
+    
+    _now = now;
+    }
+}
+void Schedule::set_smallest_and_largest_time_slice_length(Rational length){
+    //first set the smallest and largest to init values
 
+    if (_smallest_time_slice_length == 0 && _largest_time_slice_length == 1e19)
+    {        
+        _smallest_time_slice_length = length;
+        _largest_time_slice_length = length;
+        return;
+    }
+    else
+    {
+        //ok _smallest is no longer 0 and _largest is no longer 1e19
+        if (length < _smallest_time_slice_length && length != 0)
+            _smallest_time_slice_length = length;
+        if (length > _largest_time_slice_length && length < 3.1536e7) // length must be less than a year's seconds, ie not the last time slice
+            _largest_time_slice_length = length;
+        return;
+            
+    }
+    
+    
+}
+Rational Schedule::get_smallest_time_slice_length(){
+    return _smallest_time_slice_length;
+}
+Rational Schedule::get_largest_time_slice_length()
+{
+    return _largest_time_slice_length;
+}
+void Schedule::set_output_svg(std::string output_svg){
+    _output_svg = output_svg;
+    if(_output_svg == "none")
+        _debug = _short_debug = false;
+    else if(_output_svg == "all"){
+        LOG_F(INFO,"setting debug to true svgs");
+        _debug = true;
+        _short_debug = false;
+    }
+    else if(_output_svg == "short"){
+        _debug = false;
+        _short_debug = true;
+    }
+}
+void Schedule::set_svg_frame_and_output_start_and_end(long frame_start, long frame_end,long output_start,long output_end){
+    _svg_frame_start = frame_start;
+    _svg_frame_end = frame_end;
+    _svg_output_start = output_start;
+    _svg_output_end = output_end;
+}
+void Schedule::set_policies(RESCHEDULE_POLICY r_policy,IMPACT_POLICY i_policy){
+    _reschedule_policy = r_policy;
+    _impact_policy = i_policy;
+}
+
+void Schedule::convert_policy(std::string policy, RESCHEDULE_POLICY & variable){
+    if (policy == "RESCHEDULE_AFFECTED")
+        variable = RESCHEDULE_POLICY::AFFECTED ;
+    else if (policy == "RESCHEDULE_ALL")
+        variable = RESCHEDULE_POLICY::ALL;
+    else
+        variable = RESCHEDULE_POLICY::NONE;
+    return;
+}
+void Schedule::convert_policy(std::string policy, IMPACT_POLICY & variable){
+    if (policy == "LEAST_KILLING_LARGEST_FIRST")
+        variable = IMPACT_POLICY::LEAST_KILLING_LARGEST_FIRST;
+    else if (policy == "LEAST_KILLING_SMALLEST_FIRST")
+        variable = IMPACT_POLICY::LEAST_KILLING_SMALLEST_FIRST;
+    else if (policy == "LEAST_RESCHEDULING")
+        variable = IMPACT_POLICY::LEAST_RESCHEDULING;
+    else
+        variable = IMPACT_POLICY::NONE;
+    return;
+}
+void Schedule::add_svg_highlight_machines(IntervalSet machines)
+{
+    _svg_highlight_machines += machines;
+}
+bool Schedule::remove_svg_highlight_machines(IntervalSet machines)
+{
+    if (machines.is_subset_of(_svg_highlight_machines))
+    {
+        _svg_highlight_machines -= machines;
+        return true;
+    }
+    else
+        return false;
+}
+IntervalSet Schedule::add_repair_machines(IntervalSet machines){
+    //first add the repair machines to our IntervalSet
+    IntervalSet added = machines - _repair_machines;
+    int number_added = added.size();
+    _repair_machines+=machines;
+    if(!added.is_empty())
+    {
+        //ok so we added some machines
+        //lets take them away from the time_slices
+        for (auto slice_it = _profile.begin();slice_it!=_profile.end();++slice_it)
+        {
+            slice_it->nb_available_machines-=number_added;
+            slice_it->available_machines -=added;
+        }
+    }
+    return added;
+
+}
+//This function will remove the given machines that are in _repair_machines
+//It will also add back those machines that are not allocated to each time slice
+IntervalSet Schedule::remove_repair_machines(IntervalSet machines){
+    IntervalSet removed = _repair_machines & machines;
+    _repair_machines-=machines;
+    int number_removed = removed.size();
+    if (!removed.is_empty())
+    {
+        for (auto slice_it = _profile.begin();slice_it!=_profile.end();++slice_it)
+        {
+            //we don't want to add machines that are already being used
+            //normally they shouldn't be in _repair_machines if there are
+            //jobs using them but if the _repair_machine was added and the jobs using
+            //that machine were not removed then this can be the case
+                IntervalSet allocated = which_machines_are_allocated_in_time_slice(slice_it,removed);                                    
+                slice_it->nb_available_machines+=(number_removed-allocated.size());
+                slice_it->available_machines +=(removed-allocated);
+            
+        }
+    }
+    return removed;
+
+}
+//This function will return the intersection of machines that are allocated
+//in the time slice with the machines that you give it.  Pass it all machines to find out
+//all machines used in time slice
+IntervalSet Schedule::which_machines_are_allocated_in_time_slice(TimeSliceIterator slice, IntervalSet machines)
+{
+    IntervalSet machines_allocated = IntervalSet::empty_interval_set();
+    for(auto job_interval_pair : slice->allocated_jobs)
+    {
+        machines_allocated +=(job_interval_pair.second & machines);
+    }
+    return machines_allocated;
+}
+int Schedule::get_number_of_running_jobs(){
+    return _profile.begin()->allocated_jobs.size();
+}
+int Schedule::get_number_of_running_machines(){
+    return int(_nb_machines - _profile.begin()->nb_available_machines );
+}
+double Schedule::get_utilization(){
+    return double(get_number_of_running_machines()) / double(_nb_machines);
+}
+double Schedule::get_utilization_no_resv(){
+    //if first slice has reservations take those machines out of the equation
+    if (_profile.begin()->has_reservation){
+        int resv_machines = get_machines_running_reservations().size();
+        return double(get_number_of_running_machines()-resv_machines)/double(_nb_machines);
+    }
+    else
+        return -1;
+}
+
+void Schedule::get_jobs_running_on_machines(IntervalSet machines,std::vector<std::string>& jobs_running_on_machines){
+    for (auto job_interval_pair : _profile.begin()->allocated_jobs)
+    {
+        //is there an intersection between this job in the first slice and the machines in question?
+        if (!(job_interval_pair.second & machines).is_empty())
+        {
+            //yes there is an intersection, add the job id
+            if (job_interval_pair.first->purpose != "reservation")
+                jobs_running_on_machines.push_back(job_interval_pair.first->id);
+
+        }
+    }
+    return;
+}
+
+void Schedule::get_jobs_running_on_machines(IntervalSet machines,std::map< const Job *,IntervalSet>& jobs_running_on_machines){
+
+    for (auto job_interval_pair : _profile.begin()->allocated_jobs)
+    {
+        //is there an intersection between this job in the first slice and the machines in question?
+        if (!(job_interval_pair.second & machines).is_empty())
+        {
+            //yes there is an intersection, add the job id
+            if (job_interval_pair.first->purpose != "reservation")
+                jobs_running_on_machines[job_interval_pair.first]=job_interval_pair.second;
+
+        }
+    }
+    return;
+}
+void Schedule::get_jobs_affected_on_machines(IntervalSet machines, std::vector<std::string>& jobs_affected_on_machines){
+    std::map<const Job*,IntervalSet> jobs_running_on_machines;
+    std::map<const Job *,IntervalSet> jobs_affected;
+    get_jobs_running_on_machines(machines,jobs_running_on_machines);
+    auto slice_it = _profile.begin();
+    ++slice_it;
+    //go through all time slices after the first to see what is affected by machines
+    for (;slice_it!=_profile.end();++slice_it){
+        //go through each {job,allocation} pair to see what is affected
+        for( auto job_interval_pair : slice_it->allocated_jobs)
+        {   
+            //first check that it's not a reservation
+            if (job_interval_pair.first->purpose != "reservation")
+            {
+                //ok it's not a reservation
+                //check if there is an intersection of machines and the job's machines
+                //then make sure it is not running
+                if (!(job_interval_pair.second & machines).is_empty() && jobs_running_on_machines.count(job_interval_pair.first)==0)
+                {
+                    //yes there is an intersection and no it is not running
+                    //add the job to a map first so we don't add it more than once
+                    jobs_affected[job_interval_pair.first]=job_interval_pair.second;
+                }
+            }
+        }
+    }
+    //now convert the map to a simple vector of strings
+    for(auto job_interval_pair : jobs_affected)
+    {
+        jobs_affected_on_machines.push_back(job_interval_pair.first->id);
+    }
+    
+}
+void Schedule::get_jobs_affected_on_machines(IntervalSet machines, std::map<const Job *,IntervalSet>& jobs_affected_on_machines){
+    std::map<const Job*,IntervalSet> jobs_running_on_machines;
+    get_jobs_running_on_machines(machines,jobs_running_on_machines);
+    auto slice_it = _profile.begin();
+    ++slice_it;
+    //go through all time slices after the first to see what is affected by machines
+    for (;slice_it!=_profile.end();++slice_it){
+        //go through each {job,allocation} pair to see what is affected
+        for( auto job_interval_pair : slice_it->allocated_jobs)
+        {   
+            //first check that it's not a reservation
+            if (job_interval_pair.first->purpose != "reservation")
+            {
+                //ok it's not a reservation
+                //check if there is an intersection of machines and the job's machines
+                //then make sure it is not running
+                if (!(job_interval_pair.second & machines).is_empty() && jobs_running_on_machines.count(job_interval_pair.first)==0)
+                {
+                    //yes there is an intersection and no it is not running
+                    //add the job to the map
+                    jobs_affected_on_machines[job_interval_pair.first]=job_interval_pair.second;
+                }
+            }
+        }
+    }
+    
+}
+std::vector<std::string> Schedule::get_reservations_running_on_machines(IntervalSet machines){
+    std::vector<std::string> reservations_running_on_machines;
+    for (auto job_interval_pair : _profile.begin()->allocated_jobs)
+    {
+        //is there an intersection between this job in the first slice and the machines in question?
+        if (!(job_interval_pair.second & machines).is_empty())
+        {
+            //yes there is an intersection, add the job id
+            if (job_interval_pair.first->purpose == "reservation")
+                reservations_running_on_machines.push_back(job_interval_pair.first->id);
+
+        }
+    }
+    return reservations_running_on_machines;
+}
+IntervalSet Schedule::get_machines_running_reservations(){
+    return get_machines_running_reservations_on_slice(_profile.begin());
+}
+IntervalSet Schedule::get_machines_running_reservations_on_slice(TimeSliceIterator slice){
+    IntervalSet machines;
+    for (auto job_interval_pair : slice->allocated_jobs)
+    {
+            if (job_interval_pair.first->purpose == "reservation")
+                machines+=job_interval_pair.second;
+    }
+    return machines;
+}
 Schedule &Schedule::operator=(const Schedule &other)
 {
     _profile = other._profile;
@@ -45,16 +351,20 @@
 
 void Schedule::update_first_slice(Rational current_time)
 {
+    
+    
+    double epsilon = 1e-4;
     auto slice = _profile.begin();
 
     PPK_ASSERT_ERROR(
-        current_time >= slice->begin, "current_time=%g, slice->begin=%g", (double)current_time, (double)slice->begin);
+        (current_time + epsilon)>= slice->begin, "current_time=%g, slice->begin=%g", (double)current_time+epsilon, (double)slice->begin);
     PPK_ASSERT_ERROR(
-        current_time <= slice->end, "current_time=%g, slice->end=%g", (double)current_time, (double)slice->end);
+        current_time <= (slice->end+epsilon), "current_time=%g, slice->end=%g", (double)current_time, (double)slice->end+epsilon);
 
     Rational old_time = slice->begin;
     slice->begin = current_time;
     slice->length = slice->end - slice->begin;
+
     for (auto it = slice->allocated_jobs.begin(); it != slice->allocated_jobs.end(); ++it)
     {
         const Job *job_ref = (it->first);
@@ -83,6 +393,16 @@
     slice->length = slice->end - slice->begin;
 }
 
+int Schedule::size(){
+    return _size;
+}
+int Schedule::nb_jobs_size(){
+    return _nb_jobs_size;
+}
+int Schedule::nb_reservations_size(){
+    return _nb_reservations_size;
+}
+
 void Schedule::remove_job(const Job *job)
 {
     remove_job_first_occurence(job);
@@ -140,17 +460,583 @@
 
     return add_job_first_fit_after_time_slice(job, _profile.begin(), selector, assert_insertion_successful);
 }
+void Schedule::find_least_impactful_fit(JobAlloc* alloc,TimeSliceIterator begin_slice, TimeSliceIterator end_slice, IMPACT_POLICY policy){
+    
+    LOG_F(INFO,"find_least_impactful_fit");
+    const Job * job = alloc->job;
+    //we will want to use at least these machines
+    IntervalSet amdp = available_machines_during_period(begin_slice->begin,end_slice->end);
+    LOG_F(INFO,"amdp %s",amdp.to_string_hyphen().c_str());
+    //if the available machines encompass all the requested resources then take a chunk from that and return
+    if(amdp.size() >= job->nb_requested_resources){
+        alloc->used_machines = amdp.left(job->nb_requested_resources);
+        return;
+    }
+    //get all the machines and subtract those that we are definitely going to use
+    IntervalSet all_machines = IntervalSet::ClosedInterval(0, _nb_machines - 1);
+    all_machines -= amdp;
+
+    int still_needed = job->nb_requested_resources - amdp.size();
+    if(policy==IMPACT_POLICY::LEAST_KILLING_LARGEST_FIRST || policy == IMPACT_POLICY::LEAST_KILLING_SMALLEST_FIRST)
+    {
+        //get the jobs that are in the begin_slice
+        std::vector<const Job *> jobs;
+        for(std::pair<const Job*,IntervalSet> job_map : begin_slice->allocated_jobs)
+        {
+            jobs.push_back(job_map.first);
+        }
+        //get the jobs that are in the first time slice and begin_slice, ie running
+        //also get their allocated machines
+        std::vector<const Job *> jobs_running;
+        IntervalSet running_machines = IntervalSet::empty_interval_set();
+        for ( auto job : jobs)
+        {
+
+            if (_profile.begin()->contains_job(job))
+            {
+                jobs_running.push_back(job);
+                running_machines+= begin_slice->allocated_jobs[job];
+            }
+        }
+        //now check for reservation conflicts
+        auto slice_after_next = end_slice;
+        slice_after_next++;
+        IntervalSet reservation_machines = IntervalSet::empty_interval_set();
+        for (auto it = begin_slice;it!=slice_after_next;++it)
+        {
+            for (auto job_map : it->allocated_jobs)
+            {
+                if(job_map.first->purpose == "reservation"){
+                    LOG_F(INFO,"job reservation %s",job_map.first->id.c_str());
+                    reservation_machines += it->allocated_jobs[job_map.first];
+                }
+            }
+        }
+        //can we reserve based on all_machines - running_machines - reservation_machines?
+        all_machines -=running_machines;
+        all_machines -=reservation_machines;
+        if (all_machines.size() >= still_needed )
+        {
+            alloc->used_machines = all_machines.left(still_needed) + amdp;
+            return;
+        }
+        //ok, it looks like some jobs are going to have to be killed
+        //do we want smallest first or largest first to be killed?
+        
+        if (policy==IMPACT_POLICY::LEAST_KILLING_LARGEST_FIRST)
+        {
+            auto sortRuleLambda = [] (const Job * j1, const Job * j2) -> bool
+            {
+                //we want them sorted highest to lowest so j1 should be greater than j2
+                return j1->nb_requested_resources > j2->nb_requested_resources;
+
+            };
+            std::sort(jobs_running.begin(), jobs_running.end(), sortRuleLambda);
+
+        }
+        if (policy==IMPACT_POLICY::LEAST_KILLING_SMALLEST_FIRST)
+        {
+            auto sortRuleLambda = [] (const Job * j1, const Job * j2) -> bool
+            {
+                //we want them sorted lowest to highest so j1 should be less than j2
+                return j1->nb_requested_resources < j2->nb_requested_resources;
+
+            };
+            std::sort(jobs_running.begin(), jobs_running.end(), sortRuleLambda);
+
+        }        
+        
+        //now incrementally add the resources from running jobs
+        for (auto job : jobs_running)
+        {
+            if(job->purpose != "reservation")
+                all_machines+=begin_slice->allocated_jobs[job];
+            if (all_machines.size() >= still_needed)
+            {
+                alloc->used_machines = all_machines.left(still_needed) + amdp;
+                return;
+            }
+                
+        }
+        return;
+
+    }
+    else if(policy==IMPACT_POLICY::LEAST_RESCHEDULING)
+    {
+        //TODO
+    }
+}
+Schedule::ReservedTimeSlice Schedule::reserve_time_slice(const Job* job){
+    if (_debug)
+        output_to_svg("top reserve_time_slice " + job->id);
+    
+    // Let's create the job allocation
+    Schedule::JobAlloc *alloc = new Schedule::JobAlloc;
+         
+        //find insertion slice
+        auto slice_begin = _profile.begin();
+        bool first_slice_is_suspect = false;
+        if (_profile.begin()->begin == _profile.begin()->end)
+        {
+            first_slice_is_suspect = true;
+            slice_begin++;
+        }
+        for(;slice_begin!=_profile.end();slice_begin++)
+        {
+            //we are at the right slice if it's beginning = the reservation start or the slice ends at a greater point than the reservation start
+            if (slice_begin->begin == job->start || slice_begin->end > job->start)
+                break;
+            
+
+        }
+        
+        //PPK_ASSERT_ERROR(slice_begin == _profile.end(), "When inserting reservation '%s', the beginning time slice hit the end of the profile",job->id.c_str());
+        
+        
+        LOG_F(INFO,"DEBUG line 298");
+        //slice_begin should point to the correct time slice to insert the job
+        //do we need to slice it to start with?
+        //if so second_slice_after_split will point to the new slice
+        TimeSliceIterator first_slice_after_split;
+        TimeSliceIterator second_slice_after_split;
+        Rational split_date = job->start;
+        if(_debug)
+            output_to_svg("Before split slice " + job->id);
+        split_slice(slice_begin,split_date,first_slice_after_split,second_slice_after_split);
+        if (_debug)
+            output_to_svg("After split slice " + job->id);
+        LOG_F(INFO,"DEBUG line 306");
+        slice_begin=second_slice_after_split;
+
+        //now make an allocation
+        Rational beginning = job->start;
+        alloc->begin = beginning;
+        alloc->end = alloc->begin + job->walltime;
+        alloc->started_in_first_slice = (slice_begin == _profile.begin()) ? true : false;
+        alloc->job = job;
+        alloc->used_machines = job->future_allocations;
+
+        //now find the end slice
+        auto slice_end = second_slice_after_split;
+        Rational end_time = job->start + job->walltime;
+        //find ending slice
+        for (;slice_end!=_profile.end();slice_end++)
+        {
+            if (end_time <= slice_end->end)
+                break;
+        }
+        //PPK_ASSERT_ERROR(slice_end == _profile.end(), "When inserting reservation '%s', the ending time slice hit the end of the profile",job->id.c_str());
+        
+        //now split the slice if needed based on the reservation's end
+        split_date = job->start+job->walltime;
+        if (_debug)
+            output_to_svg("Before split slice "+job->id);
+        split_slice(slice_end,split_date,first_slice_after_split,second_slice_after_split);
+        if(_debug)
+            output_to_svg("After split slice "+job->id);
+        LOG_F(INFO,"DEBUG line 322");
+        slice_end = first_slice_after_split;
+        auto slice_end_next = first_slice_after_split;
+        slice_end_next++;
+        //now we know what slices will be affected, namely from slice_begin to slice_end
+        //if this reservation does not already know what nodes to use then alloc->used_machines is empty
+        //we need to get an allocation
+        if(alloc->used_machines.is_empty())
+            find_least_impactful_fit(alloc, slice_begin, slice_end, IMPACT_POLICY::LEAST_KILLING_LARGEST_FIRST); // ok it is empty, get the least_impactful fit
+        
+LOG_F(INFO,"DEBUG line 331 %s",alloc->used_machines.to_string_hyphen().c_str());
+        //now gather jobs affected
+        //first iterate through all the time slices this reservation is temporarily taking up
+        std::vector<const Job *> jobs_affected;
+        for(auto slice_it = slice_begin;slice_it !=slice_end_next;slice_it++)
+        {
+            //for each allocated job:intervalset mapping
+            for(auto job_map : slice_it->allocated_jobs)
+            {
+                //if there is an intersection of any job's used machines and the reservation's used machines
+                //then add it to affected jobs
+                if(!(job_map.second & alloc->used_machines).is_empty())
+                {
+                     if (std::find(jobs_affected.begin(), jobs_affected.end(), job_map.first) == jobs_affected.end())
+                     {
+                         //ok it did not find it, push it
+                        jobs_affected.push_back(job_map.first);
+                     }
+                }
+            }
+        }
+        Schedule::ReservedTimeSlice * reserved = new Schedule::ReservedTimeSlice;
+        //affected_jobs now holds all affected_jobs
+        //find if any affected_jobs are running
+        //right now just looking if any are in the first slice
+        std::vector<const Job *> jobs_needed_to_be_killed;
+        std::vector<const Job *> jobs_to_reschedule;
+        for (auto job : jobs_affected)
+        {
+                if (_profile.begin()->contains_job(job))
+                {
+                    if (job->purpose == "reservation")
+                    {
+                        if (!first_slice_is_suspect || (job->walltime != _profile.begin()->end))
+                        {
+                            reserved->success = false;
+                            return *reserved;
+                        }
+                        else
+                            continue;
+                    }
+                    
+                    //this needs to be looked over.  Batsim doesn't always send the completed jobs
+                    //in the same message as submitted jobs 
+                    jobs_needed_to_be_killed.push_back(job);
+                    
+                }
+                else
+                    jobs_to_reschedule.push_back(job);
+            
+        }
+    //LOG_F(INFO,"DEBUG line 367");
+        reserved->alloc = alloc;
+    //LOG_F(INFO,"DEBUG line 369");
+        reserved->jobs_affected = jobs_affected;
+        reserved->jobs_needed_to_be_killed = jobs_needed_to_be_killed;
+        reserved->jobs_to_reschedule = jobs_to_reschedule;
+      //  LOG_F(INFO,"DEBUG line 373");
+        reserved->slice_begin = slice_begin;
+        reserved->slice_end = slice_end;
+        reserved->success = true;
+        if (alloc->used_machines.is_empty())
+            reserved->success = false;
+        
+        reserved->job = job;
+
+        //now return the reserved time slice
+        //will need to act on the object to make it part of the schedule
+        //LOG_F(INFO,"DEBUG line 380");
+        if (_debug)
+            output_to_svg("bottom reserve_time_slice "+job->id);
+        return *reserved;
+}
+void Schedule::add_reservation(ReservedTimeSlice reservation){
+    
+        if (_debug)
+            output_to_svg("top add_reservation "+reservation.job->id);
+        
+        _size++;
+        _nb_reservations_size++;
+        //LOG_F(INFO,"sched_size++ %d",_size);
+        const Job * job = reservation.alloc->job;
+        //now update all slices between slice_begin and slice_end
+        auto slice_end_next = reservation.slice_end;
+        ++slice_end_next;
+        //LOG_F(INFO,"DEBUG line 395 job id %s",job->id.c_str());
+        for (auto slice_it = reservation.slice_begin; slice_it != slice_end_next; ++slice_it)
+        {
+          //  LOG_F(INFO,"DEBUG line 398");
+            //LOG_F(INFO,"used machines %s",reservation.alloc->used_machines.to_string_hyphen().c_str());
+            slice_it->available_machines -= reservation.alloc->used_machines;
+            //LOG_F(INFO,"DEBUG line 399+1");
+            slice_it->nb_available_machines -= job->nb_requested_resources;
+            slice_it->allocated_jobs[job] = reservation.alloc->used_machines;
+            //LOG_F(INFO,"DEBUG line 402+1");
+            slice_it->has_reservation = true;
+            //LOG_F(INFO,"DEBUG line 404+1");
+            (slice_it->nb_reservations)++;
+            //LOG_F(INFO,"DEBUG line 406+1");
+        }
+          if (_debug)
+            output_to_svg("bottom add_reservation "+reservation.job->id);
+}
+
+/* old code for adding reservation
+        if (job->future_allocations.is_subset_of(pit->available_machines))
+        {   //first make new time slice
+            TimeSliceIterator first_slice_after_split;
+            TimeSliceIterator second_slice_after_split;
+            Rational split_date = pit->begin + job->start;
+            LOG_F(INFO,"Split date: %g",(double)split_date);
+            split_slice(pit,split_date,first_slice_after_split,second_slice_after_split);
+            pit=second_slice_after_split;
+            
+            //now make an allocation
+            Rational beginning = job->start;
+            alloc->begin = beginning;
+            alloc->end = alloc->begin + job->walltime;
+            alloc->started_in_first_slice = (pit == _profile.begin()) ? true : false;
+            alloc->job = job;
+            alloc->used_machines = job->future_allocations;
+            
+            split_date = pit->begin + job->walltime;
+            LOG_F(INFO,"Split date: %g",(double)split_date);
+            LOG_F(INFO,"pit->begin: %g  job->walltime: %g",(double) pit->begin, (double) job->walltime);
+            LOG_F(INFO,"pit==begin:%d ,pit==next:%d pit==end:%d",pit==_profile.begin(),pit==(_profile.begin()++),pit==_profile.end());
+            split_slice(pit, split_date, first_slice_after_split, second_slice_after_split);
+            // Let's remove the allocated machines from the available machines of the time slice
+            first_slice_after_split->available_machines.remove(alloc->used_machines);
+            first_slice_after_split->nb_available_machines -= job->nb_requested_resources;
+            first_slice_after_split->allocated_jobs[job] = alloc->used_machines;
+            if (first_slice_after_split->has_reservation == true)
+                first_slice_after_split->nb_reservations +=1;
+            else
+            {
+                first_slice_after_split->has_reservation = true;
+                first_slice_after_split->nb_reservations = 1;
+            }
+            
+            return *alloc;
+
+        }
+        if (_debug)
+            output_to_svg();
+}
+
+*/
+Schedule::JobAlloc Schedule::add_current_reservation(const Job * job, ResourceSelector * selector,bool assert_insertion_successful)
+{
+     PPK_ASSERT_ERROR(!contains_job(job),
+        "Invalid Schedule::add_current_reservation call: Cannot add "
+        "job '%s' because it is already in the schedule. %s",
+        job->id.c_str(), to_string().c_str());
+    return add_current_reservation_after_time_slice(job, _profile.begin(),selector,assert_insertion_successful);
+}
+
+Schedule::JobAlloc Schedule::add_current_reservation_after_time_slice(const Job *job,
+    std::list<TimeSlice>::iterator first_time_slice, ResourceSelector *selector, bool assert_insertion_successful)
+{
+    _size++;
+    //LOG_F(INFO,"sched_size++ %d",_size);
+    PPK_ASSERT_ERROR(job->purpose=="reservation","You tried to add a non reservation job, job: '%s' via add_current_reservation, consider add_job_first_fit",job->id.c_str());
+    
+    if (_debug)
+    {
+      //  LOG_F(1, "Adding job '%s' (size=%d, walltime=%g). Output number %d. %s",
+       //     job->id.c_str(), job->nb_requested_resources, (double)job->walltime,
+        //    _output_number, to_string().c_str());
+        output_to_svg("top add_current_reservation_after_time_slice "+job->id);
+    }
+
+    // Let's scan the profile for an anchor point.
+    // An anchor point is a point where enough processors are available to run this job
+    for (auto pit = _profile.begin(); pit != _profile.end(); ++pit)
+    {
+        // If the current time slice is an anchor point
+        
+        IntervalSet available_machines = pit->available_machines;
+        available_machines+=_repair_machines;
+        if ((int)available_machines.size() >= job->nb_requested_resources)
+        {
+            // Let's continue to scan the profile to ascertain that
+            // the machines remain available until the job's expected termination
+
+            // If the job has no walltime, its size will be "infinite"
+            if (!job->has_walltime)
+            {
+                // TODO: remove this ugly const_cast?
+                const_cast<Job *>(job)->walltime = infinite_horizon() - pit->begin;
+            }
+
+            int availableMachinesCount = available_machines.size();
+            Rational totalTime = pit->length;
+
+            // If the job fits in the current time slice (temporarily speaking)
+            if (totalTime >= job->walltime)
+            {
+                // Let's create the job allocation
+                Schedule::JobAlloc *alloc = new Schedule::JobAlloc;
+
+                // If the job fits in the current time slice (according to the fitting function)
+                if (selector->fit_reservation(job, available_machines, alloc->used_machines))
+                {
+                    Rational beginning = pit->begin;
+                    alloc->begin = beginning;
+                    alloc->end = alloc->begin + job->walltime;
+                    alloc->started_in_first_slice = (pit == _profile.begin()) ? true : false;
+                    alloc->job = job;
+                    job->allocations[beginning] = alloc;
+
+                    // Let's split the current time slice if needed
+                    TimeSliceIterator first_slice_after_split;
+                    TimeSliceIterator second_slice_after_split;
+                    Rational split_date = pit->begin + job->walltime;
+                    split_slice(pit, split_date, first_slice_after_split, second_slice_after_split);
+                    
+                    // Let's remove the allocated machines from the available machines of the time slice
+                    first_slice_after_split->available_machines.remove(alloc->used_machines);
+                    first_slice_after_split->nb_available_machines -= job->nb_requested_resources;
+                    first_slice_after_split->allocated_jobs[job] = alloc->used_machines;
+                    first_slice_after_split->nb_reservations++;
+                    if (first_slice_after_split->nb_reservations == 1)
+                        first_slice_after_split->has_reservation = true;
+                    if (_debug)
+                    {
+        //                LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
+         //                   job->nb_requested_resources, (double)job->walltime, _output_number, to_string().c_str());
+                        output_to_svg("bottom add_current_reservation_after_time_slice "+job->id);
+                    }
+
+                    // The job has been placed, we can leave this function
+                    return *alloc;
+                }
+            }
+            else
+            {
+                // TODO : merge this big else with its if, as the "else" is a more general case of the "if"
+                // The job does not fit in the current time slice (temporarily speaking)
+                auto availableMachines = pit->available_machines;
+                availableMachines += _repair_machines;
+
+                auto pit2 = pit;
+                ++pit2;
+
+                for (; (pit2 != _profile.end()) && ((int)pit2->nb_available_machines >= job->nb_requested_resources);
+                     ++pit2)
+                {
+                    availableMachines &= pit2->available_machines;
+                    availableMachinesCount = (int)availableMachines.size();
+                    totalTime += pit2->length;
+
+                    if (availableMachinesCount < job->nb_requested_resources) // We don't have enough machines to run the job
+                        break;
+                    else if (totalTime >= job->walltime) // The job fits in the slices [pit, pit2[ (temporarily speaking)
+                    {
+                        // Let's create the job allocation
+                        JobAlloc *alloc = new JobAlloc;
+
+                        // If the job fits in the current time slice (according to the fitting function)
+                        if (selector->fit_reservation(job, availableMachines, alloc->used_machines))
+                        {
+                            alloc->begin = pit->begin;
+                            alloc->end = alloc->begin + job->walltime;
+                            alloc->started_in_first_slice = (pit == _profile.begin()) ? true : false;
+                            alloc->job = job;
+                            job->allocations[alloc->begin] = alloc;
+
+                            // Let's remove the used machines from the slices before pit2
+                            auto pit3 = pit;
+                            for (; pit3 != pit2; ++pit3)
+                            {
+                                //if some of the machines are repair machines then they won't be in available machines
+                                //the intersection of available_machines and used machines tells us how many machines to subtract from nb_available_machines
+                                int subtract = (pit3->available_machines & alloc->used_machines).size();
+                                pit3->available_machines -= alloc->used_machines;
+                                pit3->nb_available_machines -= subtract;
+                                pit3->allocated_jobs[job] = alloc->used_machines;
+                                pit3->nb_reservations++;
+                            if (pit3->nb_reservations == 1)//means a reservation has been added
+                                pit3->has_reservation = true;
+                            }
+
+                            // Let's split the current time slice if needed
+                            TimeSliceIterator first_slice_after_split;
+                            TimeSliceIterator second_slice_after_split;
+                            Rational split_date = pit->begin + job->walltime;
+                            split_slice(pit2, split_date, first_slice_after_split, second_slice_after_split);
+
+                            // Let's remove the allocated machines from the available machines of the time slice
+                            int subtract = (first_slice_after_split->available_machines & alloc->used_machines).size();
+                            first_slice_after_split->available_machines -= alloc->used_machines;
+                            first_slice_after_split->nb_available_machines -= subtract;
+                            first_slice_after_split->allocated_jobs[job] = alloc->used_machines;
+
+                            if (_debug)
+                            {
+          //                      LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
+          //                          job->nb_requested_resources, (double)job->walltime, _output_number,
+            //                        to_string().c_str());
+                                output_to_svg("bottom else add_current_reservation_after_time_slice " +job->id);
+                            }
+
+                            // The job has been placed, we can leave this function
+                            return *alloc;
+                        }
+                    }
+                }
+            }
+        }
+    }
+
+    if (assert_insertion_successful)
+        PPK_ASSERT_ERROR(false, "Error in Schedule::add_job_first_fit: could not add job '%s' into %s", job->id.c_str(),
+            to_string().c_str());
+
+    JobAlloc failed_alloc;
+    failed_alloc.has_been_inserted = false;
+    return failed_alloc;
+
+}
+bool Schedule::remove_reservations_if_ready(std::vector<const Job *>& jobs_removed)
+{
+    //first check if next timeslice has a reservation
+    auto slice = _profile.begin();
+    ++slice;
+    if (slice == _profile.end())
+        return false;
+    //LOG_F(INFO,"line 634");
+    bool ready = false;
+    if (slice->has_reservation)
+    {
+        //ok the next timeslice does have a reservation
+        //check if it is ready to copy over to the first slice
+      //  LOG_F(INFO,"line 640");
+      Rational epsilon =1e-4;
+        if (abs(_profile.begin()->begin - slice->begin)<=epsilon)
+        {
+            ready = true;
+            //ok they are equal, remove the reservations
+        //    LOG_F(INFO,"line 645");
+            for (auto it = slice->allocated_jobs.begin();it != slice->allocated_jobs.end();++it)
+            {
+                
+                const Job* job = it->first;
+                //first make sure it's a reservation and not currently running (ie in the first slice)
+                if (job->purpose == "reservation" && !_profile.begin()->contains_job(job))
+                    {
+                        //ok it is a reservation and not currently running
+                        //now make sure the resources are available
+                        IntervalSet available_machines = _profile.begin()->available_machines;
+                        //we add repair_machines since a reservation takes precedence over such things
+                            available_machines+=_repair_machines;
+                        if ( !(it->second.is_subset_of(available_machines)))
+                            return false;
+                        if (slice->nb_reservations > 0)
+                            slice->nb_reservations--;
+          //              LOG_F(INFO,"line 670");
+                        jobs_removed.push_back(job);
+            //            LOG_F(INFO,"line 672");
+                                              
+                    }
+
+            }
+            for (auto job : jobs_removed)
+                remove_job_if_exists(job);
+            return true;   
+        }
+
+    }
+    return false;
+}
 
 Schedule::JobAlloc Schedule::add_job_first_fit_after_time_slice(const Job *job,
     std::list<TimeSlice>::iterator first_time_slice, ResourceSelector *selector, bool assert_insertion_successful)
 {
+
     if (_debug)
     {
-        LOG_F(1, "Adding job '%s' (size=%d, walltime=%g). Output number %d. %s",
-            job->id.c_str(), job->nb_requested_resources, (double)job->walltime,
-            _output_number, to_string().c_str());
-        output_to_svg();
+        //LOG_F(1, "Adding job '%s' (size=%d, walltime=%g). Output number %d. %s",
+        //    job->id.c_str(), job->nb_requested_resources, (double)job->walltime,
+        //    _output_number, to_string().c_str());
+        output_to_svg("top add_job_first_fit_after_time_slice "+job->id);
+    }
+    _size++;
+    _nb_jobs_size++;
+    //LOG_F(INFO,"sched_size++ %d",_size);
+    /*
+    if (!_repair_machines.is_empty())
+    {
+        _profile.begin()->nb_available_machines -= _repair_machines.size();
+        _profile.begin()->available_machines -= _repair_machines;
     }
+    */
 
     // Let's scan the profile for an anchor point.
     // An anchor point is a point where enough processors are available to run this job
@@ -183,7 +1069,6 @@
                 {
                     Rational beginning = pit->begin;
                     alloc->begin = beginning;
-                    alloc->end = alloc->begin + job->walltime;
                     alloc->started_in_first_slice = (pit == _profile.begin()) ? true : false;
                     alloc->job = job;
                     job->allocations[beginning] = alloc;
@@ -201,12 +1086,19 @@
 
                     if (_debug)
                     {
-                        LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
-                            job->nb_requested_resources, (double)job->walltime, _output_number, to_string().c_str());
-                        output_to_svg();
+      //                  LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
+      //                      job->nb_requested_resources, (double)job->walltime, _output_number, to_string().c_str());
+                        output_to_svg("bottom add_job_first_fit_after_time_slice "+job->id);
                     }
 
                     // The job has been placed, we can leave this function
+                    /*
+                    if (!_repair_machines.is_empty())
+                    {
+                        _profile.begin()->nb_available_machines += _repair_machines.size();
+                        _profile.begin()->available_machines += _repair_machines;
+                    }
+                    */
                     return *alloc;
                 }
             }
@@ -266,13 +1158,20 @@
 
                             if (_debug)
                             {
-                                LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
-                                    job->nb_requested_resources, (double)job->walltime, _output_number,
-                                    to_string().c_str());
-                                output_to_svg();
+              //                  LOG_F(1, "Added job '%s' (size=%d, walltime=%g). Output number %d. %s", job->id.c_str(),
+                //                    job->nb_requested_resources, (double)job->walltime, _output_number,
+                  //                  to_string().c_str());
+                                output_to_svg("bottom else add_job_first_fit_after_time_slice "+job->id);
                             }
 
                             // The job has been placed, we can leave this function
+                            /*
+                            if (!_repair_machines.is_empty())
+                            {
+                                _profile.begin()->nb_available_machines += _repair_machines.size();
+                                _profile.begin()->available_machines += _repair_machines;
+                            }
+                            */
                             return *alloc;
                         }
                     }
@@ -287,6 +1186,8 @@
 
     JobAlloc failed_alloc;
     failed_alloc.has_been_inserted = false;
+    _size--;
+    _nb_jobs_size--;
     return failed_alloc;
 }
 
@@ -297,7 +1198,7 @@
     {
         LOG_F(1, "Adding job '%s' (size=%d, walltime=%g) after date %g. Output number %d. %s", job->id.c_str(),
             job->nb_requested_resources, (double)job->walltime, (double)date, _output_number, to_string().c_str());
-        output_to_svg();
+        output_to_svg("top add_job_first_fit_after_time "+job->id);
     }
 
     // Let's first search at each time slice the job should be added
@@ -397,6 +1298,7 @@
     return -1;
 }
 
+
 Rational Schedule::first_slice_begin() const
 {
     PPK_ASSERT_ERROR(_profile.size() > 0);
@@ -506,11 +1408,13 @@
 
         new_slice.begin = date;
         new_slice.length = new_slice.end - new_slice.begin;
+        set_smallest_and_largest_time_slice_length(new_slice.length);
         PPK_ASSERT_ERROR(new_slice.length > 0);
 
         // Let's reduce the existing slice length
         slice_to_split->end = date;
         slice_to_split->length = slice_to_split->end - slice_to_split->begin;
+        set_smallest_and_largest_time_slice_length(slice_to_split->length);
         PPK_ASSERT_ERROR(slice_to_split->length > 0);
 
         // Let's insert the new_slice just after slice_to_split
@@ -629,7 +1533,7 @@
 
         if (slice.begin <= date)
             return slice_it;
-
+ IntervalSet _repair_machines;
     } while (slice_it != _profile.begin());
 
     if (assert_not_found)
@@ -751,9 +1655,20 @@
 
     return res;
 }
+void Schedule::add_reservation_for_svg_outline(const ReservedTimeSlice & reservation_to_be ){
+    _svg_reservations.push_back(reservation_to_be);
 
-string Schedule::to_svg() const
+}
+bool Schedule::ReservedTimeSlice::operator==(const ReservedTimeSlice & r)const {
+    return job->id == r.job->id;
+}
+void Schedule::remove_reservation_for_svg_outline(const ReservedTimeSlice & reservation_to_be){
+    _svg_reservations.remove(reservation_to_be);
+}
+
+string Schedule::to_svg(const std::string& message, const std::list<ReservedTimeSlice> & svg_reservations) const
 {
+    //LOG_F(INFO,"line 1311");
     Rational x0, x1, y0, y1;
     x0 = y0 = std::numeric_limits<double>::max();
     x1 = y1 = std::numeric_limits<double>::min();
@@ -763,8 +1678,17 @@
     auto last_finite_slice = _profile.end();
     --last_finite_slice;
 
-    const Rational second_width = 10;
-    const Rational machine_height = 10;
+    Rational second_width = 8;
+    const Rational smallest_length = _smallest_time_slice_length;
+    const Rational total_seconds = last_finite_slice->begin - _profile.begin()->begin;
+    if ((total_seconds* second_width) > 4000)
+        second_width = 8.0/smallest_length;
+    if ((total_seconds * second_width) > 10000)
+        second_width = 10000.0/total_seconds;
+    Rational machine_height = 10;
+    if ((_nb_machines * machine_height) > 4000){
+        machine_height = 3;
+    }
     const Rational space_between_machines_ratio(1, 8);
     PPK_ASSERT_ERROR(space_between_machines_ratio >= 0 && space_between_machines_ratio <= 1);
 
@@ -773,22 +1697,42 @@
 
     y0 = 0 * machine_height;
     y1 = _nb_machines * machine_height;
-
     const Rational width = x1 - x0 + 10;
     const Rational height = y1 - y0;
 
     const int buf_size = 4096;
     char *buf = new char[buf_size];
-
+    Rational img_width = width;
+    if (img_width < 240)
+        img_width = 240;
     // header
+    Rational sim_time = _now;
+    //if(_profile.size() == 1 && _profile.begin()->allocated_jobs.empty() )
+    //    sim_time=_previous_time_end;
     snprintf(buf, buf_size,
         "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n"
         "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"%g\" height=\"%g\">\n"
-        "<title>Schedule</title>\n",
-        (double)width, (double)height);
+        "<title>Schedule</title>\n"
+        "<!-- %g-->\n"
+        "<text x=\"5\" y=\"5\" font-size=\"1pt\" fill=\"black\">Frame: %d</text>\n"
+        "<text x=\"50\" y=\"5\" font-size=\"1pt\" fill=\"black\">Output: %d</text>\n"
+        "<text x=\"100\" y=\"5\" font-size=\"1pt\" fill=\"black\">Sim Time: %g seconds</text>\n"
+        "<text x=\"150\" y=\"5\" font-size=\"1pt\" fill=\"black\">%s</text>\n",
+        (double)img_width, (double)height+20,(double)smallest_length,_frame_number,_output_number,(double)sim_time,message.c_str());
+
 
     string res = buf;
+    for (auto slice_it = _profile.begin(); slice_it != _profile.end(); ++slice_it){
+        Rational line_x0 = slice_it->begin * second_width -x0;
+        snprintf(buf,buf_size,
+        "<line x1=\"%g\" y1=\"8\" x2=\"%g\" y2=\"13\" stroke=\"black\" stroke-width=\".1\"/>\n"
+        "<text x=\"%g\" y=\"11\" font-size=\"1pt\" fill=\"black\">%.2f</text>\n",
+        (double)line_x0,(double)line_x0,((double)line_x0)+1,(double)slice_it->begin);
 
+        res+=buf;
+        
+    }
+    res+="<g  transform=\"translate(0,13)\">";
     // machines background color
     for (int i = 0; i < _nb_machines; ++i)
     {
@@ -800,13 +1744,14 @@
             machine_color = "#DDDDDD";
 
         snprintf(buf, buf_size,
-            "  <rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" style=\"stroke:none; fill:%s;\"/>\n", (double)0,
+            "  <rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" stroke=\"none\" fill=\"%s\"/>\n" , (double)0,
             (double)(i * machine_height), (double)width, (double)machine_height, machine_color.c_str());
         res += buf;
     }
 
     map<const Job *, Rational> jobs_starting_times;
     set<const Job *> current_jobs;
+    //first slice are current jobs
     for (auto mit : _profile.begin()->allocated_jobs)
     {
         const Job *allocated_job = mit.first;
@@ -817,6 +1762,7 @@
     // Let's traverse the profile to find the beginning of each job
     for (auto slice_it = _profile.begin(); slice_it != _profile.end(); ++slice_it)
     {
+        
         const TimeSlice &slice = *slice_it;
         set<const Job *> allocated_jobs;
         for (auto mit : slice.allocated_jobs)
@@ -840,7 +1786,13 @@
             PPK_ASSERT_ERROR(slice_it != _profile.begin());
             auto previous_slice_it = slice_it;
             --previous_slice_it;
-
+            std::string job_id = job->id;
+            job_id = job_id.substr(job_id.find("!")+1,job_id.size());
+             if (job->purpose=="reservation")
+                {
+                    job_id+=" R";
+                    rect_color = _reservation_colors[job->unique_number %(int)_reservation_colors.size()];
+                }
             IntervalSet job_machines = previous_slice_it->allocated_jobs.at(job);
 
             // Let's create a rectangle for each contiguous part of the allocation
@@ -852,16 +1804,21 @@
                     - (space_between_machines_ratio * machine_height) - y0;
                 Rational rect_height = rect_y1 - rect_y0;
 
+                double stroke_width = (double)std::min(std::max((Rational)(std::min(second_width, machine_height) / 10),(Rational)0.1),(Rational)0.5);//nothing less than 0.1, nothing greater than 0.5
+                    
                 snprintf(buf, buf_size,
-                    "  <rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" style=\"stroke:black; stroke-width=%g; "
-                    "fill:%s;\"/>\n",
+                    "  <rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" stroke=\"black\" stroke-width=\"%g\" "
+                    "fill=\"%s\"/>\n"
+                    " <text x=\"%g\" y=\"%g\" font-size=\"%dpx\">%s</text>\n",
                     (double)rect_x0, (double)rect_y0, (double)rect_width, (double)rect_height,
-                    (double)(std::min(second_width, machine_height) / 10), rect_color.c_str());
+                    stroke_width, rect_color.c_str(),(double)(rect_x0+1),(double)(rect_y0+2),(int)2,job_id.c_str());
 
                 res += buf;
             }
         }
 
+
+
         set<const Job *> new_jobs;
         set_difference(allocated_jobs.begin(), allocated_jobs.end(), current_jobs.begin(), current_jobs.end(),
             std::inserter(new_jobs, new_jobs.end()));
@@ -877,34 +1834,114 @@
         for (const Job *job : new_jobs)
             current_jobs.insert(job);
     }
+    //LOG_F(INFO,"line 1461");
+    for (const ReservedTimeSlice reservation : svg_reservations)
+    {   
+        
+        const Job * job = reservation.job;
+        const double start = job->start;
+        const Rational walltime = job->walltime;
+        Rational rect_x0 = start * second_width - x0;
+        Rational rect_x1 = (start+walltime) * second_width - x0;
+        Rational rect_width = rect_x1 - rect_x0;
+        std::string rect_color = _reservation_colors[job->unique_number % (int)_reservation_colors.size()];
+        for (auto it = reservation.alloc->used_machines.intervals_begin(); it != reservation.alloc->used_machines.intervals_end(); ++it)
+        {
+            PPK_ASSERT_ERROR(it->lower() <= it->upper());
+            Rational rect_y0 = it->lower() * machine_height - y0;
+            Rational rect_y1 = ((it->upper() + Rational(1)) * machine_height)
+                - (space_between_machines_ratio * machine_height) - y0;
+            Rational rect_height = rect_y1 - rect_y0;
+            std::string job_id = job->id;
+            job_id = job_id.substr(job_id.find("!")+1);
+            
+            if (job->purpose=="reservation")
+                job_id+=" R";
+            snprintf(buf, buf_size,
+                "  <rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" stroke-width=\".3\" stroke-dasharray=\"3,3\" " 
+                "stroke=\"black\" fill=\"%s\" fill-opacity=\"0.4\"/>\n"
+                " <text x=\"%g\" y=\"%g\" font-size=\"%dpx\">%s</text>\n",
+                (double)rect_x0, (double)rect_y0, (double)rect_width, (double)rect_height,
+                rect_color.c_str(),(double)(rect_x0+1),(double)(rect_y0+2),(int)2,job_id.c_str()); 
+            res += buf;
+        }
 
-    res += "</svg>";
+    }
+    for (auto it = _svg_highlight_machines.elements_begin(); it != _svg_highlight_machines.elements_end(); ++it)
+    {
+      //  LOG_F(INFO,"DEBUG");
+        // Use operator* to retrieve the element value
+        
+        int i = *it;
+//        LOG_F(INFO,"DEBUG");
+        snprintf(buf, buf_size,
+            "<rect x=\"%g\" y=\"%g\" width=\"%g\" height=\"%g\" stroke-width=\".3\" stroke-dasharray=\"10,10,5,5,5,10\" " 
+                "stroke=\"black\" fill=\"%s\" fill-opacity=\"0.6\"/>\n"
+                " <text x=\"%g\" y=\"%g\" font-size=\"%dpx\">%s</text>\n", (double)0,
+            (double)(i * machine_height), (double)width, (double)machine_height, "#ce7000",
+            ((double)width)/2 - 10,(double)(i*machine_height)+(double)((machine_height/2.0)+(machine_height/4.0)),(int)(machine_height/2),("m "+std::to_string(i)).c_str());
+        res += buf;
+  //      LOG_F(INFO,"DEBUG");
+
+    }
+    res += "</g></svg>";
 
     delete[] buf;
     return res;
 }
 
-void Schedule::write_svg_to_file(const string &filename) const
+void Schedule::write_svg_to_file(const string &filename,
+                                const std::string& message,
+                                const std::list<ReservedTimeSlice> & svg_reservations) const
 {
     ofstream f(filename);
 
     if (f.is_open())
-        f << to_svg() << "\n";
+        f << to_svg(message,svg_reservations) << "\n";
 
     f.close();
 }
 
-void Schedule::output_to_svg(const string &filename_prefix)
+void Schedule::output_to_svg(const std::string &message)
 {
+    if (_frame_number >= _svg_frame_start && (_frame_number <= _svg_frame_end || _svg_frame_end == -1)){
+        if (_output_number >= _svg_output_start && (_output_number < _svg_output_end || _svg_output_end == -1)){
     const int bufsize = 4096;
     char *buf = new char[bufsize];
+            char *buf2 = new char[bufsize];
 
-    snprintf(buf, bufsize, "%s%06d.svg", filename_prefix.c_str(), _output_number);
-    ++_output_number %= 10000000;
 
-    write_svg_to_file(buf);
+            snprintf(buf, bufsize, "%s%06d.svg", _svg_prefix.c_str(), _output_number);
+            snprintf(buf2,bufsize, "%s%06d.txt",_svg_prefix.c_str(),_output_number);
+            
+            ofstream f(buf2);
+            auto first_slice = _profile.begin();
+            if (f.is_open())
+                f << first_slice->begin;
+            f.close();
+            
+            const std::list<ReservedTimeSlice> svg_reservations = _svg_reservations;
+            LOG_F(INFO,"Frame: %06d Output: %06d Sec: %.1f Msg: %s \n %s",_frame_number, _output_number,(double)_profile.begin()->begin,message.c_str(),to_string().c_str());
+        
+            write_svg_to_file(buf,message,svg_reservations);
+            if (_profile.size()>1)
+            {
+                auto slice = _profile.end();
+                slice--;
+                slice--;
+                Rational end = slice->end;
+                if (end > 0 && end != 1e19)
+                    _previous_time_end = end;
+            }
+            
 
     delete[] buf;
+        }
+    }
+    if (message=="make_decisions")
+        ++_frame_number %=1000000000;
+    ++_output_number %= 1000000000;
+
 }
 
 void Schedule::dump_to_batsim_jobs_file(const string &filename) const
@@ -1006,8 +2043,10 @@
 {
     PPK_ASSERT_ERROR(nb_colors > 0);
     _colors.reserve(nb_colors);
+    _reservation_colors.reserve(nb_colors);
 
     double h, s = 1, v = 1, r, g, b;
+    double h2,s2 =1,v2 =1,r2,g2,b2;
     const int color_bufsize = 16;
     char color_buf[color_bufsize];
 
@@ -1017,14 +2056,35 @@
         h = i * hue_fraction;
         hsvToRgb(h, s, v, r, g, b);
 
-        unsigned int red = std::max(0, std::min((int)(floor(256 * r)), 255));
-        unsigned int green = std::max(0, std::min((int)(floor(256 * g)), 255));
-        unsigned int blue = std::max(0, std::min((int)(floor(256 * g)), 255));
+        unsigned int red = std::max(50, std::min((int)(floor(256 * r)), 255));
+        unsigned int green = std::max(20, std::min((int)(floor(256 * g)), 255));
+        unsigned int blue = std::max(20, std::min((int)(floor(256 * g)), 255));
 
         snprintf(color_buf, color_bufsize, "#%02x%02x%02x", red, green, blue);
         _colors.push_back(color_buf);
     }
+    double value_fraction =  1 / (double)(nb_colors); //keep the value higher so we can see it
+    double saturation_fraction = 1 /(double)(nb_colors);
+    h2 = 270; //purple hue
+    for (int i = 0; i < nb_colors; ++i)
+    {
+        v2 = i * value_fraction;
+        LOG_F(INFO,"nb_colors: %d i: %d top: %d value_frac: %g v2: %g",nb_colors,i,(nb_colors -1 +i),value_fraction,v2);
+        s2 = (double)(nb_colors-i) * saturation_fraction;
+        if (s2 < .2)
+            s2=.2;
+        hsvToRgb(h2, s2, v2, r2, g2, b2);
+        
+        unsigned int red = std::max(20, std::min((int)(floor(256 * r2)), 255));
+        unsigned int green = std::max(20, std::min((int)(floor(256 * g2)), 255));
+        unsigned int blue = std::max(20, std::min((int)(floor(256 * b2)), 255));
+
+        snprintf(color_buf, color_bufsize, "#%02x%02x%02x", red, green, blue);
+        _reservation_colors.push_back(color_buf);
+    }
+
 
+    random_shuffle(_reservation_colors.begin(),_reservation_colors.end());
     random_shuffle(_colors.begin(), _colors.end());
 }
 
@@ -1033,11 +2093,31 @@
     // Let's retrieve the machines used by the job
     PPK_ASSERT_ERROR(removal_point->allocated_jobs.count(job) == 1);
     IntervalSet job_machines = removal_point->allocated_jobs.at(job);
-
+    //LOG_F(INFO," current allocated machines %s \n current repair machines inside remove_job_internal %s",
+      //      job_machines.to_string_hyphen().c_str(),
+        //    _repair_machines.to_string_hyphen().c_str());
+    job_machines-=_repair_machines;
+    //LOG_F(INFO,"removing job %s",job->id.c_str());
+    //LOG_F(INFO,"adding back %s",job_machines.to_string_hyphen().c_str());
+    
+    _size--;
+    if (job->purpose!="reservation")
+        _nb_jobs_size--;
+    else
+        _nb_reservations_size--;
+    //LOG_F(INFO,"sched_size-- %d",_size);
+    /*
+    //Doing this in the add_repair_machines() function so no longer needed
+    if (!_repair_machines.is_empty())
+    {
+        _profile.begin()->nb_available_machines -= _repair_machines.size();
+        _profile.begin()->available_machines -= _repair_machines;
+    }
+    */
     if (_debug)
     {
-        LOG_F(1, "Removing job '%s'. Output number %d. %s", job->id.c_str(), _output_number, to_string().c_str());
-        output_to_svg();
+      //  LOG_F(INFO, "Removing job '%s'. Output number %d. %s", job->id.c_str(), _output_number, to_string().c_str());
+        output_to_svg("top remove_job_internal "+job->id);
     }
 
     // Let's iterate the time slices until the job is found
@@ -1047,7 +2127,13 @@
         if (pit->allocated_jobs.erase(job) == 1)
         {
             pit->available_machines.insert(job_machines);
-            pit->nb_available_machines += job->nb_requested_resources;
+            pit->nb_available_machines += job_machines.size();
+            if (job->purpose == "reservation")
+            {
+                pit->nb_reservations--;
+                if (pit->nb_reservations == 0)
+                    pit->has_reservation = false;
+            }
 
             // If the slice is not the first one, let's try to merge it with its preceding slice
             if (pit != _profile.begin())
@@ -1065,6 +2151,8 @@
 
                     pit->begin = previous->begin;
                     pit->length = pit->end - pit->begin;
+                    set_smallest_and_largest_time_slice_length(pit->length);
+                    
 
                     // pit is updated to ensure --pit points to a valid location after erasure
                     pit = _profile.erase(previous);
@@ -1075,7 +2163,13 @@
             for (++pit; pit != _profile.end() && pit->allocated_jobs.erase(job) == 1; ++pit)
             {
                 pit->available_machines.insert(job_machines);
-                pit->nb_available_machines += job->nb_requested_resources;
+                pit->nb_available_machines += job_machines.size();
+                if (job->purpose == "reservation")
+                {
+                    pit->nb_reservations--;
+                    if (pit->nb_reservations == 0)
+                        pit->has_reservation = false;
+                }
 
                 // If the slice is not the first one, let's try to merge it with its preceding slice
                 if (pit != _profile.begin())
@@ -1093,6 +2187,7 @@
 
                         pit->begin = previous->begin;
                         pit->length = pit->end - pit->begin;
+                        set_smallest_and_largest_time_slice_length(pit->length);
 
                         // pit is updated to ensure --pit points to a valid location after erasure
                         pit = _profile.erase(previous);
@@ -1119,6 +2214,7 @@
 
                         pit->begin = previous->begin;
                         pit->length = pit->end - pit->begin;
+                        set_smallest_and_largest_time_slice_length(pit->length);
 
                         // pit is updated to ensure --pit points to a valid location after erasure
                         pit = _profile.erase(previous);
@@ -1129,8 +2225,16 @@
             if (_debug)
             {
                 LOG_F(1, "Removed job '%s'. Output number %d. %s", job->id.c_str(), _output_number, to_string().c_str());
-                output_to_svg();
+                output_to_svg("bottom remove_job_internal "+job->id);
+            }
+            /*
+            //no longer needed
+            if (!_repair_machines.is_empty())
+            {
+                _profile.begin()->nb_available_machines -= _repair_machines.size();
+                _profile.begin()->available_machines -= _repair_machines;
             }
+            */
 
             return;
         }
diff -burN '--exclude=.git*' ./batsched/src/schedule.hpp ./new_batsched/src/schedule.hpp
--- ./batsched/src/schedule.hpp	2023-07-01 09:20:31.854175526 -0400
+++ ./new_batsched/src/schedule.hpp	2023-06-28 08:26:02.143833485 -0400
@@ -16,10 +16,13 @@
         Rational begin;
         Rational end;
         Rational length;
+        bool has_reservation = false;
+        int nb_reservations = 0;
 
         IntervalSet available_machines;
         int nb_available_machines;
         std::map<const Job *, IntervalSet, JobComparator> allocated_jobs;
+        //std::map<const Job *, IntervalSet, JobComparator> allocated_reservations;
 
         bool contains_job(const Job * job) const;
         bool contains_matching_job(std::function<bool(const Job *)> matching_function) const;
@@ -29,17 +32,37 @@
         std::string to_string_allocated_jobs() const;
         std::string to_string(int initial_indent = 0, int indent = 2) const;
     };
+    enum class RESCHEDULE_POLICY{NONE,AFFECTED,ALL};
+    enum class IMPACT_POLICY{NONE,LEAST_KILLING_LARGEST_FIRST,LEAST_KILLING_SMALLEST_FIRST,LEAST_RESCHEDULING};
+    
+    
+    static void convert_policy(std::string policy,RESCHEDULE_POLICY& variable);
+    static void convert_policy(std::string policy, IMPACT_POLICY& variable);
+    
 
     typedef std::list<TimeSlice>::iterator TimeSliceIterator;
     typedef std::list<TimeSlice>::const_iterator TimeSliceConstIterator;
 
     typedef struct JobAlloc JobAlloc;
 
+    struct ReservedTimeSlice{
+        bool operator==(const ReservedTimeSlice & r) const;
+        bool success = false;
+        std::vector<const Job*> jobs_affected;
+        std::vector<const Job*> jobs_needed_to_be_killed;
+        std::vector<const Job*> jobs_to_reschedule;
+        TimeSliceIterator slice_begin;
+        TimeSliceIterator slice_end;
+        JobAlloc* alloc;
+        const Job * job;
+    };
+
 public:
     Schedule(int nb_machines = 1, Rational initial_time = 0);
     Schedule(const Schedule & other);
 
     Schedule & operator=(const Schedule & other);
+    void set_now(Rational now);
 
     void update_first_slice(Rational current_time);
     void update_first_slice_removing_remaining_jobs(Rational current_time);
@@ -49,8 +72,20 @@
     void remove_job_all_occurences(const Job * job);
     void remove_job_first_occurence(const Job * job);
     void remove_job_last_occurence(const Job * job);
+   
+    
     JobAlloc add_job_first_fit(const Job * job, ResourceSelector * selector,
                                bool assert_insertion_successful = true);
+    
+    
+    
+    //CCU-LANL additions start
+    
+    IntervalSet add_repair_machines(IntervalSet machines);
+    IntervalSet remove_repair_machines(IntervalSet machines);
+    ReservedTimeSlice reserve_time_slice(const Job * job);
+    void add_reservation(ReservedTimeSlice reservation);
+    void find_least_impactful_fit(JobAlloc * alloc, TimeSliceIterator begin_slice, TimeSliceIterator end_slice,IMPACT_POLICY policy);
     JobAlloc add_job_first_fit_after_time_slice(const Job * job,
                                                 std::list<TimeSlice>::iterator first_time_slice,
                                                 ResourceSelector * selector,
@@ -59,6 +94,40 @@
                                           Rational date,
                                           ResourceSelector * selector,
                                           bool assert_insertion_successful = true);
+    void add_reservation_for_svg_outline(const ReservedTimeSlice & reservation_to_be );
+    void remove_reservation_for_svg_outline(const ReservedTimeSlice & reservation_to_be);
+    void set_output_svg(std::string output_svg);
+    void set_svg_prefix(std::string svg_prefix);
+    void set_svg_frame_and_output_start_and_end(long frame_start, long frame_end,long output_start,long output_end);
+    void set_policies(RESCHEDULE_POLICY r_policy, IMPACT_POLICY i_policy);
+    void add_svg_highlight_machines(IntervalSet machines);
+    bool remove_svg_highlight_machines(IntervalSet machines);
+    bool remove_reservations_if_ready(std::vector<const Job*>& jobs_removed);
+
+    JobAlloc add_current_reservation(const Job * job, ResourceSelector * selector,
+                               bool assert_insertion_successful = true);
+    JobAlloc add_current_reservation_after_time_slice(const Job * job,
+                                                std::list<TimeSlice>::iterator first_time_slice,
+                                                ResourceSelector * selector,
+                                                bool assert_insertion_successful = true);
+    int get_number_of_running_jobs();
+    void get_jobs_running_on_machines(IntervalSet machines, std::vector<std::string>& jobs_running_on_machines);
+    void get_jobs_running_on_machines(IntervalSet machines, std::map<const Job*,IntervalSet>& jobs_running_on_machines);
+    void get_jobs_affected_on_machines(IntervalSet machines, std::vector<std::string>& jobs_affected_on_machines);
+    void get_jobs_affected_on_machines(IntervalSet machines, std::map<const Job*,IntervalSet>& jobs_affected_on_machines);
+    Rational get_smallest_time_slice_length();
+    Rational get_largest_time_slice_length();
+    int get_number_of_running_machines();
+    double get_utilization();
+    double get_utilization_no_resv();
+    IntervalSet get_machines_running_reservations();
+    IntervalSet get_machines_running_reservations_on_slice(TimeSliceIterator slice);
+    void set_smallest_and_largest_time_slice_length(Rational length);
+    IntervalSet which_machines_are_allocated_in_time_slice(TimeSliceIterator slice,IntervalSet machine);
+    std::vector<std::string> get_reservations_running_on_machines(IntervalSet machines);
+
+    //CCU-LANL additions end
+
 
   // The coveted query_wait method, bringing an answer (as a double, defined as
   // time away from now) to the question "when will I be able to schedule a job
@@ -93,13 +162,18 @@
     std::list<TimeSlice>::iterator end();
     std::list<TimeSlice>::const_iterator begin() const;
     std::list<TimeSlice>::const_iterator end() const;
+    int size();
+    int nb_reservations_size();
+    int nb_jobs_size();
 
     int nb_slices() const;
 
     std::string to_string() const;
-    std::string to_svg() const;
-    void write_svg_to_file(const std::string & filename) const;
-    void output_to_svg(const std::string & filename_prefix = "/tmp/schedule");
+    std::string to_svg(const std::string &message, const std::list<ReservedTimeSlice> & svg_reservations) const;
+    void write_svg_to_file(const std::string & filename, 
+                        const std::string & message,
+                        const std::list<ReservedTimeSlice> & svg_reservations) const;
+    void output_to_svg(const std::string & message);
 
     void dump_to_batsim_jobs_file(const std::string & filename) const;
     void incremental_dump_as_batsim_jobs_file(const std::string & filename_prefix = "/tmp/schedule");
@@ -111,13 +185,34 @@
     void remove_job_internal(const Job * job, TimeSliceIterator removal_point);
 
 private:
+    
+    Rational _now = 0;
     // The profile is a list of timeslices and a set of job allocations
     std::list<TimeSlice> _profile;
+    int _size = 0;
+    int _nb_reservations_size = 0;
+    int _nb_jobs_size = 0;
     int _nb_machines;
     bool _debug = false;
-
-    unsigned int _output_number = 0;
+    bool _short_debug = false; //make svg's less frequently than _debug
+    std::string _output_svg = "none"; //(none||all||short)  affects _debug and _short_debug
+    std::string _svg_prefix; //the output path of the svg's output when _debug/_short_debug are true
+    RESCHEDULE_POLICY _reschedule_policy = RESCHEDULE_POLICY::AFFECTED;  //whether to reschedule only affected jobs or all the jobs after a reservation addition
+    IMPACT_POLICY _impact_policy = IMPACT_POLICY::LEAST_KILLING_LARGEST_FIRST;
+    unsigned int _output_number = 1;
+    unsigned int _frame_number = 1;
+    Rational _previous_time_end = 0;
+    std::list<ReservedTimeSlice> _svg_reservations;
+    IntervalSet _svg_highlight_machines;
     std::vector<std::string> _colors;
+    std::vector<std::string> _reservation_colors;
+    IntervalSet _repair_machines;
+    Rational _smallest_time_slice_length=0;
+    Rational _largest_time_slice_length=1e19;
+    long _svg_frame_start = 1;
+    long _svg_frame_end = -1;
+    long _svg_output_start = 1;
+    long _svg_output_end = -1;
 };
 
 /**
